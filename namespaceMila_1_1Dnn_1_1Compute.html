<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Mila: Mila::Dnn::Compute Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Mila
   </div>
   <div id="projectbrief">Deep Neural Network Library</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('namespaceMila_1_1Dnn_1_1Compute.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#namespaces">Namespaces</a> &#124;
<a href="#nested-classes">Classes</a> &#124;
<a href="#concepts">Concepts</a> &#124;
<a href="#typedef-members">Typedefs</a> &#124;
<a href="#enum-members">Enumerations</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">Mila::Dnn::Compute Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="namespaces" name="namespaces"></a>
Namespaces</h2></td></tr>
<tr class="memitem:namespaceMila_1_1Dnn_1_1Compute_1_1Detail" id="r_namespaceMila_1_1Dnn_1_1Compute_1_1Detail"><td class="memItemLeft" align="right" valign="top">namespace &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute_1_1Detail.html">Detail</a></td></tr>
<tr class="memdesc:namespaceMila_1_1Dnn_1_1Compute_1_1Detail"><td class="mdescLeft">&#160;</td><td class="mdescRight">Namespace for CUDA layer normalization implementation details. <br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1AMPConfig.html">AMPConfig</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1BinaryOperation.html">BinaryOperation</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Abstract class for binary operations in the neural network framework.  <a href="classMila_1_1Dnn_1_1Compute_1_1BinaryOperation.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1ComputeDevice.html">ComputeDevice</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Abstract interface for compute devices (CPU, CUDA, etc.).  <a href="classMila_1_1Dnn_1_1Compute_1_1ComputeDevice.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1ComputePrecision.html">ComputePrecision</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Controls automatic mixed precision behavior for neural network operations.  <a href="classMila_1_1Dnn_1_1Compute_1_1ComputePrecision.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1ComputeResource.html">ComputeResource</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Abstract base class for compute resources.  <a href="classMila_1_1Dnn_1_1Compute_1_1ComputeResource.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuCrossEntropyOp.html">CpuCrossEntropyOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">CPU implementation of the cross entropy loss operation for neural networks.  <a href="classMila_1_1Dnn_1_1Compute_1_1CpuCrossEntropyOp.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuCrossEntropyOpRegistrar.html">CpuCrossEntropyOpRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class responsible for registering the <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuCrossEntropyOp.html" title="CPU implementation of the cross entropy loss operation for neural networks.">CpuCrossEntropyOp</a> operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CpuCrossEntropyOpRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuDevice.html">CpuDevice</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class representing a CPU compute device.  <a href="classMila_1_1Dnn_1_1Compute_1_1CpuDevice.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuEncoderOp.html">CpuEncoderOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">CPU implementation of the encoder operation for neural networks.  <a href="classMila_1_1Dnn_1_1Compute_1_1CpuEncoderOp.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuEncoderOpRegistrar.html">CpuEncoderOpRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class responsible for registering the <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuEncoderOp.html" title="CPU implementation of the encoder operation for neural networks.">CpuEncoderOp</a> operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CpuEncoderOpRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuGeluOp.html">CpuGeluOp</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuGeluOpRegistrar.html">CpuGeluOpRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class responsible for registering the <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuGeluOp.html">CpuGeluOp</a> operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CpuGeluOpRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuLayerNormOp.html">CpuLayerNormOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">CPU implementation of the Layer Normalization operation for neural networks.  <a href="classMila_1_1Dnn_1_1Compute_1_1CpuLayerNormOp.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuLayerNormOpRegistrar.html">CpuLayerNormOpRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class responsible for registering the <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuLayerNormOp.html" title="CPU implementation of the Layer Normalization operation for neural networks.">CpuLayerNormOp</a> operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CpuLayerNormOpRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuLinearOp.html">CpuLinearOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">CPU implementation of the Fully Connected operation for neural networks.  <a href="classMila_1_1Dnn_1_1Compute_1_1CpuLinearOp.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuLinearOpRegistrar.html">CpuLinearOpRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class responsible for registering the <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuLinearOp.html" title="CPU implementation of the Fully Connected operation for neural networks.">CpuLinearOp</a> operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CpuLinearOpRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuMemoryResource.html">CpuMemoryResource</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">A memory resource for CPU memory allocation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CpuMemoryResource.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuMultiHeadAttentionOp.html">CpuMultiHeadAttentionOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">CPU implementation of the Multi-Head Attention operation for neural networks.  <a href="classMila_1_1Dnn_1_1Compute_1_1CpuMultiHeadAttentionOp.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuMultiHeadAttentionOpRegistrar.html">CpuMultiHeadAttentionOpRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class responsible for registering the CpuMultiHeadAttention operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CpuMultiHeadAttentionOpRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuResidualOp.html">CpuResidualOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">CPU implementation of the residual operation for neural networks.  <a href="classMila_1_1Dnn_1_1Compute_1_1CpuResidualOp.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuResidualOpRegistrar.html">CpuResidualOpRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class responsible for registering the <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuResidualOp.html" title="CPU implementation of the residual operation for neural networks.">CpuResidualOp</a> operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CpuResidualOpRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuSoftmaxOp.html">CpuSoftmaxOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">CPU implementation of the softmax operation for neural networks.  <a href="classMila_1_1Dnn_1_1Compute_1_1CpuSoftmaxOp.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuSoftmaxOpRegistrar.html">CpuSoftmaxOpRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class responsible for registering the <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuSoftmaxOp.html" title="CPU implementation of the softmax operation for neural networks.">CpuSoftmaxOp</a> operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CpuSoftmaxOpRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CublasLtError.html">CublasLtError</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaBadAlloc.html">CudaBadAlloc</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaComputeResource.html">CudaComputeResource</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structMila_1_1Dnn_1_1Compute_1_1CudaDataTypeMap.html">CudaDataTypeMap</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Helper struct to map C++ types to CUDA data types for cuBLASLt.  <a href="structMila_1_1Dnn_1_1Compute_1_1CudaDataTypeMap.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structMila_1_1Dnn_1_1Compute_1_1CudaDataTypeMap_3_01____nv__bfloat16_01_4.html">CudaDataTypeMap&lt; __nv_bfloat16 &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structMila_1_1Dnn_1_1Compute_1_1CudaDataTypeMap_3_01float_01_4.html">CudaDataTypeMap&lt; float &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structMila_1_1Dnn_1_1Compute_1_1CudaDataTypeMap_3_01half_01_4.html">CudaDataTypeMap&lt; half &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaDevice.html">CudaDevice</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class representing a CUDA compute device.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaDevice.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaEncoderOp.html">CudaEncoderOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">CUDA implementation of the <a class="el" href="classMila_1_1Dnn_1_1Encoder.html" title="An encoder module that provides token and positional embeddings.">Encoder</a> operation for transformer models.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaEncoderOp.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaEncoderOpRegistrar.html">CudaEncoderOpRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class responsible for registering the <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaEncoderOp.html" title="CUDA implementation of the Encoder operation for transformer models.">CudaEncoderOp</a> operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaEncoderOpRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaError.html">CudaError</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Exception class for CUDA runtime errors.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaError.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaGeluOp.html">CudaGeluOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">CUDA implementation of the GELU activation function for neural networks.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaGeluOp.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaGeluOpRegistrar.html">CudaGeluOpRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class responsible for registering the <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaGeluOp.html" title="CUDA implementation of the GELU activation function for neural networks.">CudaGeluOp</a> operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaGeluOpRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaLayerNormOp.html">CudaLayerNormOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">CUDA implementation of the Layer Normalization operation for neural networks.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaLayerNormOp.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaLayerNormOpRegistrar.html">CudaLayerNormOpRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class responsible for registering the <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaLayerNormOp.html" title="CUDA implementation of the Layer Normalization operation for neural networks.">CudaLayerNormOp</a> operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaLayerNormOpRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaLinearOp.html">CudaLinearOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">CUDA implementation of the Fully Connected operation for neural networks.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaLinearOp.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaLinearOpRegistrar.html">CudaLinearOpRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class responsible for registering the <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaLinearOp.html" title="CUDA implementation of the Fully Connected operation for neural networks.">CudaLinearOp</a> operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaLinearOpRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaManagedMemoryResource.html">CudaManagedMemoryResource</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">A memory resource that uses CUDA managed memory.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaManagedMemoryResource.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMatMulBiasGeluOp.html">CudaMatMulBiasGeluOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">CUDA implementation of the fused MatMul-Bias-GELU operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaMatMulBiasGeluOp.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMatMulBiasGeluOpRegistrar.html">CudaMatMulBiasGeluOpRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class responsible for registering the <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMatMulBiasGeluOp.html" title="CUDA implementation of the fused MatMul-Bias-GELU operation.">CudaMatMulBiasGeluOp</a> operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaMatMulBiasGeluOpRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMemoryResource.html">CudaMemoryResource</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">A memory resource that allocates memory on a CUDA device.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaMemoryResource.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html">CudaMultiHeadAttentionOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">CUDA implementation of the Multi-Head Attention operation for transformer models.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOpRegistrar.html">CudaMultiHeadAttentionOpRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class responsible for registering the <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html" title="CUDA implementation of the Multi-Head Attention operation for transformer models.">CudaMultiHeadAttentionOp</a> operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOpRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaPinnedMemoryResource.html">CudaPinnedMemoryResource</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">A memory resource that allocates pinned (page-locked) memory using CUDA.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaPinnedMemoryResource.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaResidualOp.html">CudaResidualOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">CUDA implementation of the residual operation for neural networks.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaResidualOp.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaResidualOpRegistrar.html">CudaResidualOpRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class responsible for registering the <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaResidualOp.html" title="CUDA implementation of the residual operation for neural networks.">CudaResidualOp</a> operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaResidualOpRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaSoftmaxOp.html">CudaSoftmaxOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">CUDA implementation of the softmax operation for neural networks.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaSoftmaxOp.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaSoftmaxOpRegistrar.html">CudaSoftmaxOpRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class responsible for registering the <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaSoftmaxOp.html" title="CUDA implementation of the softmax operation for neural networks.">CudaSoftmaxOp</a> operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1CudaSoftmaxOpRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structMila_1_1Dnn_1_1Compute_1_1DeviceAccessible.html">DeviceAccessible</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html">DeviceContext</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">The <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html" title="The DeviceContext class manages device contexts for module and tensor computations.">DeviceContext</a> class manages device contexts for module and tensor computations.  <a href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceProps.html">DeviceProps</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceRegistrar.html">DeviceRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class to manage compute device initialization.  <a href="classMila_1_1Dnn_1_1Compute_1_1DeviceRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceRegistry.html">DeviceRegistry</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Registry for compute device creation and management.  <a href="classMila_1_1Dnn_1_1Compute_1_1DeviceRegistry.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DynamicMemoryResource.html">DynamicMemoryResource</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">A class that represents a dynamically-determined memory resource.  <a href="classMila_1_1Dnn_1_1Compute_1_1DynamicMemoryResource.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structMila_1_1Dnn_1_1Compute_1_1FusedOpMeta.html">FusedOpMeta</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metadata for fused operations in the neural network.  <a href="structMila_1_1Dnn_1_1Compute_1_1FusedOpMeta.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1FusedSoftmaxCrossEntropyOp.html">FusedSoftmaxCrossEntropyOp</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">CUDA implementation of the fused softmax and cross entropy operation for neural networks.  <a href="classMila_1_1Dnn_1_1Compute_1_1FusedSoftmaxCrossEntropyOp.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1FusedSoftmaxCrossEntropyOpRegistrar.html">FusedSoftmaxCrossEntropyOpRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class responsible for registering the <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1FusedSoftmaxCrossEntropyOp.html" title="CUDA implementation of the fused softmax and cross entropy operation for neural networks.">FusedSoftmaxCrossEntropyOp</a> operation.  <a href="classMila_1_1Dnn_1_1Compute_1_1FusedSoftmaxCrossEntropyOpRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structMila_1_1Dnn_1_1Compute_1_1HostAccessible.html">HostAccessible</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1HostComputeResource.html">HostComputeResource</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structMila_1_1Dnn_1_1Compute_1_1MemoryStats.html">MemoryStats</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Global memory statistics for all <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1TrackedMemoryResource.html" title="A memory resource wrapper that tracks allocation and deallocation statistics.">TrackedMemoryResource</a> instances.  <a href="structMila_1_1Dnn_1_1Compute_1_1MemoryStats.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structMila_1_1Dnn_1_1Compute_1_1OperationAttributes.html">OperationAttributes</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Common attributes for neural network operations.  <a href="structMila_1_1Dnn_1_1Compute_1_1OperationAttributes.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1OperationBase.html">OperationBase</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Base class for all compute operations in the <a class="el" href="namespaceMila.html">Mila</a> neural network framework.  <a href="classMila_1_1Dnn_1_1Compute_1_1OperationBase.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1OperationRegistry.html">OperationRegistry</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">A registry for operations that can be created based on operation names, type information, and device type.  <a href="classMila_1_1Dnn_1_1Compute_1_1OperationRegistry.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1OperationsRegistrar.html">OperationsRegistrar</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Class to manage compute operations initialization.  <a href="classMila_1_1Dnn_1_1Compute_1_1OperationsRegistrar.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1TrackedMemoryResource.html">TrackedMemoryResource</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">A memory resource wrapper that tracks allocation and deallocation statistics.  <a href="classMila_1_1Dnn_1_1Compute_1_1TrackedMemoryResource.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html">UnaryOperation</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Abstract base class for unary operations in the compute framework.  <a href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="concepts" name="concepts"></a>
Concepts</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">concept &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="conceptMila_1_1Dnn_1_1Compute_1_1IsCpuComputeResource.html">IsCpuComputeResource</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">concept &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="conceptMila_1_1Dnn_1_1Compute_1_1IsCudaComputeResource.html">IsCudaComputeResource</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="typedef-members" name="typedef-members"></a>
Typedefs</h2></td></tr>
<tr class="memitem:aed36c27e30be3933dc64c610eebc4f41" id="r_aed36c27e30be3933dc64c610eebc4f41"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#aed36c27e30be3933dc64c610eebc4f41">Mila::Dnn::Compute::DeviceMemoryResource</a> = <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMemoryResource.html">CudaMemoryResource</a></td></tr>
<tr class="memdesc:aed36c27e30be3933dc64c610eebc4f41"><td class="mdescLeft">&#160;</td><td class="mdescRight">Alias for <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMemoryResource.html" title="A memory resource that allocates memory on a CUDA device.">CudaMemoryResource</a> that represents device-accessible memory.  <br /></td></tr>
<tr class="separator:aed36c27e30be3933dc64c610eebc4f41"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8c32f3f7cc6e4ef70be850a0cf5b9a62" id="r_a8c32f3f7cc6e4ef70be850a0cf5b9a62"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a8c32f3f7cc6e4ef70be850a0cf5b9a62">Mila::Dnn::Compute::HostMemoryResource</a> = <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuMemoryResource.html">CpuMemoryResource</a></td></tr>
<tr class="memdesc:a8c32f3f7cc6e4ef70be850a0cf5b9a62"><td class="mdescLeft">&#160;</td><td class="mdescRight">Alias for <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuMemoryResource.html" title="A memory resource for CPU memory allocation.">CpuMemoryResource</a> that represents host-accessible memory.  <br /></td></tr>
<tr class="separator:a8c32f3f7cc6e4ef70be850a0cf5b9a62"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b8ae76f48eea1ab92fc10a619f1b666" id="r_a7b8ae76f48eea1ab92fc10a619f1b666"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a7b8ae76f48eea1ab92fc10a619f1b666">Mila::Dnn::Compute::MemoryResource</a> = std::pmr::memory_resource</td></tr>
<tr class="memdesc:a7b8ae76f48eea1ab92fc10a619f1b666"><td class="mdescLeft">&#160;</td><td class="mdescRight">An alias for the standard polymorphic memory resource.  <br /></td></tr>
<tr class="separator:a7b8ae76f48eea1ab92fc10a619f1b666"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="enum-members" name="enum-members"></a>
Enumerations</h2></td></tr>
<tr class="memitem:a393d2d886886aa0215f25b307e4f71f4" id="r_a393d2d886886aa0215f25b307e4f71f4"><td class="memItemLeft" align="right" valign="top">enum class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">Mila::Dnn::Compute::DeviceType</a> { <a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4a54c82ef76ecbbd4c2293e09bae01b54e">Cpu</a>
, <a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4a8b95dcff7397d0693c03e394af5552aa">Cuda</a>
 }</td></tr>
<tr class="memdesc:a393d2d886886aa0215f25b307e4f71f4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Enumeration of supported compute device types.  <a href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">More...</a><br /></td></tr>
<tr class="separator:a393d2d886886aa0215f25b307e4f71f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe9b0f279fe9c233b4b5d795cb0ade11" id="r_afe9b0f279fe9c233b4b5d795cb0ade11"><td class="memItemLeft" align="right" valign="top">enum class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11">Mila::Dnn::Compute::OperationType</a> { <br />
&#160;&#160;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11a746c5a2f065fb98c8db5b62f88012ee2">CrossEntropyOp</a>
, <a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11a278a0c36099e2f403c47c2791940b701">EncoderOp</a>
, <a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11a0681a1f7650431f366f8f71062793c8f">FusedOp</a>
, <a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11a0acfa5da2fd5707d6476d71dde5cfbf5">LinearOp</a>
, <br />
&#160;&#160;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11ac7a14b21eeb427f4799ca8cb99b3e526">GeluOp</a>
, <a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11a9abe4333afd363f5778830afa47a50d1">LayerNormOp</a>
, <a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11a753dee665dd7674150f555815d471f5f">MultiHeadAttentionOp</a>
, <a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11a35d8ea1936b14a4aabff8f268d50e737">ResidualOp</a>
, <br />
&#160;&#160;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11ab7aea4f7d4e55ce130b5cca0a345f8f1">SoftmaxOp</a>
<br />
 }</td></tr>
<tr class="memdesc:afe9b0f279fe9c233b4b5d795cb0ade11"><td class="mdescLeft">&#160;</td><td class="mdescRight">Enumeration of all supported neural network operation types.  <a href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11">More...</a><br /></td></tr>
<tr class="separator:afe9b0f279fe9c233b4b5d795cb0ade11"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:aa0711964e9fee40a967d47ce110040a9" id="r_aa0711964e9fee40a967d47ce110040a9"><td class="memItemLeft" align="right" valign="top">constexpr int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#aa0711964e9fee40a967d47ce110040a9">Mila::Dnn::Compute::ceil_div</a> (int M, int N)</td></tr>
<tr class="memdesc:aa0711964e9fee40a967d47ce110040a9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculates ceiling division for kernel grid/block dimensions.  <br /></td></tr>
<tr class="separator:aa0711964e9fee40a967d47ce110040a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96ecd0d5401f97858e0a936ad10d59a6" id="r_a96ecd0d5401f97858e0a936ad10d59a6"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a96ecd0d5401f97858e0a936ad10d59a6">Mila::Dnn::Compute::checkDevice</a> (int deviceId)</td></tr>
<tr class="memdesc:a96ecd0d5401f97858e0a936ad10d59a6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Validates that a device ID is valid and available.  <br /></td></tr>
<tr class="separator:a96ecd0d5401f97858e0a936ad10d59a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aabb558ed498e925008cd96a0b6ca224e" id="r_aabb558ed498e925008cd96a0b6ca224e"><td class="memTemplParams" colspan="2">template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType&gt; </td></tr>
<tr class="memitem:aabb558ed498e925008cd96a0b6ca224e"><td class="memTemplItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html">DeviceContext</a> &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#aabb558ed498e925008cd96a0b6ca224e">Mila::Dnn::Compute::CreateCompatibleContext</a> ()</td></tr>
<tr class="memdesc:aabb558ed498e925008cd96a0b6ca224e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates a device context compatible with the specified device type.  <br /></td></tr>
<tr class="separator:aabb558ed498e925008cd96a0b6ca224e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add162bc95a4a4f23ca4e4ba91ff9f662" id="r_add162bc95a4a4f23ca4e4ba91ff9f662"><td class="memTemplParams" colspan="2">template&lt;typename TDataType , typename TCompute  = float&gt; <br />
requires std::is_same_v&lt;TDataType, float&gt; || std::is_same_v&lt;TDataType, half&gt; || std::is_same_v&lt;TDataType, __nv_bfloat16&gt; || std::is_same_v&lt;TDataType, __nv_fp8_e4m3&gt;</td></tr>
<tr class="memitem:add162bc95a4a4f23ca4e4ba91ff9f662"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#add162bc95a4a4f23ca4e4ba91ff9f662">Mila::Dnn::Compute::cublaslt_matmul_forward</a> (TDataType *Y, const TDataType *X, const TDataType *weight, const TDataType *bias, int outer_size, int C, int OC, cudaStream_t stream, cublasLtHandle_t cublasLtHandle)</td></tr>
<tr class="memdesc:add162bc95a4a4f23ca4e4ba91ff9f662"><td class="mdescLeft">&#160;</td><td class="mdescRight">cuBLASLt implementation of matrix multiplication with bias addition  <br /></td></tr>
<tr class="separator:add162bc95a4a4f23ca4e4ba91ff9f662"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afbbce0b872aa390e8b90d8d913bc1559" id="r_afbbce0b872aa390e8b90d8d913bc1559"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afbbce0b872aa390e8b90d8d913bc1559">Mila::Dnn::Compute::cublasLtCheckStatus</a> (cublasStatus_t status, const std::source_location &amp;location=std::source_location::current())</td></tr>
<tr class="memdesc:afbbce0b872aa390e8b90d8d913bc1559"><td class="mdescLeft">&#160;</td><td class="mdescRight">Checks the status of a cuBLASLt operation and throws if an error occurred.  <br /></td></tr>
<tr class="separator:afbbce0b872aa390e8b90d8d913bc1559"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a366addef6857c5a70c4ca32041783fa0" id="r_a366addef6857c5a70c4ca32041783fa0"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a366addef6857c5a70c4ca32041783fa0">cuda_encoder_forward_fp16</a> (half *Y, const int *X, const half *wte, const half *wpe, int B, int T, int C, cudaStream_t stream)</td></tr>
<tr class="separator:a366addef6857c5a70c4ca32041783fa0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c868f9b0924d1fa480221776b7985c2" id="r_a3c868f9b0924d1fa480221776b7985c2"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a3c868f9b0924d1fa480221776b7985c2">cuda_encoder_forward_fp32</a> (float *Y, const int *X, const float *wte, const float *wpe, int B, int T, int C, cudaStream_t stream)</td></tr>
<tr class="separator:a3c868f9b0924d1fa480221776b7985c2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42a835f0a5a11bc570716119a4765704" id="r_a42a835f0a5a11bc570716119a4765704"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a42a835f0a5a11bc570716119a4765704">cuda_gelu_backward_fp16</a> (half *dX, const half *X, const half *dY, const int N, cudaStream_t stream)</td></tr>
<tr class="separator:a42a835f0a5a11bc570716119a4765704"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3e8dcac0f2ac5c24a627fbe2b9be9671" id="r_a3e8dcac0f2ac5c24a627fbe2b9be9671"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a3e8dcac0f2ac5c24a627fbe2b9be9671">cuda_gelu_backward_fp32</a> (float *dX, const float *X, const float *dY, const int N, cudaStream_t stream)</td></tr>
<tr class="separator:a3e8dcac0f2ac5c24a627fbe2b9be9671"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2bd00e832a92926319daf2f0984e5fd7" id="r_a2bd00e832a92926319daf2f0984e5fd7"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a2bd00e832a92926319daf2f0984e5fd7">cuda_gelu_forward_fp16</a> (half *Y, const half *X, int N, cudaStream_t stream)</td></tr>
<tr class="separator:a2bd00e832a92926319daf2f0984e5fd7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a053c82c575baebe18906be8ef85b5d1a" id="r_a053c82c575baebe18906be8ef85b5d1a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a053c82c575baebe18906be8ef85b5d1a">cuda_gelu_forward_fp32</a> (float *Y, const float *X, int N, cudaStream_t stream)</td></tr>
<tr class="separator:a053c82c575baebe18906be8ef85b5d1a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a015e542888fbd38e2048df219fd4665c" id="r_a015e542888fbd38e2048df219fd4665c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a015e542888fbd38e2048df219fd4665c">cuda_layernorm_forward_fp16</a> (half *Y, half *mean, half *rstd, const half *X, const half *weight, const half *bias, int B, int T, int C, float epsilon, cudaStream_t stream)</td></tr>
<tr class="separator:a015e542888fbd38e2048df219fd4665c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a810f32be785c810b2d8738290c33eb" id="r_a9a810f32be785c810b2d8738290c33eb"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a9a810f32be785c810b2d8738290c33eb">cuda_layernorm_forward_fp32</a> (float *Y, float *mean, float *rstd, const float *X, const float *weight, const float *bias, int B, int T, int C, float epsilon, cudaStream_t stream)</td></tr>
<tr class="separator:a9a810f32be785c810b2d8738290c33eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a60405d0daed6cb8d910a3d4da2795f9f" id="r_a60405d0daed6cb8d910a3d4da2795f9f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a60405d0daed6cb8d910a3d4da2795f9f">cuda_matmul_forward_fp16</a> (half *Y, const half *X, const half *weight, const half *bias, int outer_size, int C, int OC, cudaStream_t stream)</td></tr>
<tr class="separator:a60405d0daed6cb8d910a3d4da2795f9f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6eda598cf61e803efbe42800f7d3bf9d" id="r_a6eda598cf61e803efbe42800f7d3bf9d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a6eda598cf61e803efbe42800f7d3bf9d">cuda_matmul_forward_fp32</a> (float *Y, const float *X, const float *weight, const float *bias, int outer_size, int C, int OC, cudaStream_t stream)</td></tr>
<tr class="separator:a6eda598cf61e803efbe42800f7d3bf9d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac47dfe5123c2b0b33c17a037c47d2a13" id="r_ac47dfe5123c2b0b33c17a037c47d2a13"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#ac47dfe5123c2b0b33c17a037c47d2a13">cuda_mha_forward_fp16</a> (half *Y, half *qkvr, half *att, const half *X, int B, int T, int C, int NH, cudaStream_t stream)</td></tr>
<tr class="separator:ac47dfe5123c2b0b33c17a037c47d2a13"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a375d72038d6d1326b6b595096e76a5ed" id="r_a375d72038d6d1326b6b595096e76a5ed"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a375d72038d6d1326b6b595096e76a5ed">cuda_mha_forward_fp32</a> (float *Y, float *qkvr, float *att, const float *X, int B, int T, int C, int NH, cudaStream_t stream)</td></tr>
<tr class="separator:a375d72038d6d1326b6b595096e76a5ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac16d74cbeabd3e400f948789cf3336bc" id="r_ac16d74cbeabd3e400f948789cf3336bc"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#ac16d74cbeabd3e400f948789cf3336bc">cuda_residual_forward_fp16</a> (half *Y, const half *X1, const half *X2, int N, cudaStream_t stream)</td></tr>
<tr class="separator:ac16d74cbeabd3e400f948789cf3336bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa80d55b23db037fa0d11e200342133fe" id="r_aa80d55b23db037fa0d11e200342133fe"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#aa80d55b23db037fa0d11e200342133fe">cuda_residual_forward_fp32</a> (float *Y, const float *X1, const float *X2, int N, cudaStream_t stream)</td></tr>
<tr class="separator:aa80d55b23db037fa0d11e200342133fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c99f562b010b1d7c93b19e81aa07054" id="r_a6c99f562b010b1d7c93b19e81aa07054"><td class="memTemplParams" colspan="2">template&lt;typename TPrecision &gt; </td></tr>
<tr class="memitem:a6c99f562b010b1d7c93b19e81aa07054"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a6c99f562b010b1d7c93b19e81aa07054">cuda_softmax_crossentropy_backward</a> (TPrecision *dlogits, const TPrecision *dlosses, const TPrecision *probs, const int *targets, int batch_size, int seq_len, int vocab_size, cudaStream_t stream)</td></tr>
<tr class="separator:a6c99f562b010b1d7c93b19e81aa07054"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abdd81adcc543bffda394b5ef6742cb32" id="r_abdd81adcc543bffda394b5ef6742cb32"><td class="memTemplParams" colspan="2">template&lt;typename TPrecision &gt; </td></tr>
<tr class="memitem:abdd81adcc543bffda394b5ef6742cb32"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#abdd81adcc543bffda394b5ef6742cb32">cuda_softmax_crossentropy_forward</a> (TPrecision *losses, TPrecision *probs, const TPrecision *logits, const int *targets, int batch_size, int seq_len, int vocab_size, cudaStream_t stream)</td></tr>
<tr class="separator:abdd81adcc543bffda394b5ef6742cb32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8f94ddbf4b181078f079c0cf49f01256" id="r_a8f94ddbf4b181078f079c0cf49f01256"><td class="memTemplParams" colspan="2">template&lt;typename TPrecision &gt; </td></tr>
<tr class="memitem:a8f94ddbf4b181078f079c0cf49f01256"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a8f94ddbf4b181078f079c0cf49f01256">cuda_softmax_forward</a> (TPrecision *Y, const TPrecision *X, int N, int C, cudaStream_t stream)</td></tr>
<tr class="separator:a8f94ddbf4b181078f079c0cf49f01256"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a4587581d8fb126179468a0af8e3075" id="r_a3a4587581d8fb126179468a0af8e3075"><td class="memTemplParams" colspan="2">template&lt;typename TPrecision &gt; </td></tr>
<tr class="memitem:a3a4587581d8fb126179468a0af8e3075"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a3a4587581d8fb126179468a0af8e3075">cuda_softmax_forward_general</a> (TPrecision *Y, const TPrecision *X, int outer_size, int dim_size, int inner_size, cudaStream_t stream)</td></tr>
<tr class="separator:a3a4587581d8fb126179468a0af8e3075"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab06697660f29cc1d553a3ce26951d6d5" id="r_ab06697660f29cc1d553a3ce26951d6d5"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#ab06697660f29cc1d553a3ce26951d6d5">Mila::Dnn::Compute::cudaCheckLastError</a> (const std::source_location &amp;location=std::source_location::current())</td></tr>
<tr class="memdesc:ab06697660f29cc1d553a3ce26951d6d5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Checks the last CUDA error and throws if an error occurred.  <br /></td></tr>
<tr class="separator:ab06697660f29cc1d553a3ce26951d6d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af02152a475c650f6a64e0f2c67c1aaf5" id="r_af02152a475c650f6a64e0f2c67c1aaf5"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#af02152a475c650f6a64e0f2c67c1aaf5">Mila::Dnn::Compute::cudaCheckStatus</a> (cudaError_t status, const std::source_location &amp;location=std::source_location::current())</td></tr>
<tr class="memdesc:af02152a475c650f6a64e0f2c67c1aaf5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Checks the status of a CUDA operation and throws if an error occurred.  <br /></td></tr>
<tr class="separator:af02152a475c650f6a64e0f2c67c1aaf5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc57784bcbd77f21ea2524f0161e7e4f" id="r_abc57784bcbd77f21ea2524f0161e7e4f"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#abc57784bcbd77f21ea2524f0161e7e4f">Mila::Dnn::Compute::deviceToString</a> (<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> device_type)</td></tr>
<tr class="memdesc:abc57784bcbd77f21ea2524f0161e7e4f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Converts a DeviceType to its string representation.  <br /></td></tr>
<tr class="separator:abc57784bcbd77f21ea2524f0161e7e4f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a58d62f6f183335114f9dd89dfefd0dad" id="r_a58d62f6f183335114f9dd89dfefd0dad"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a58d62f6f183335114f9dd89dfefd0dad">Mila::Dnn::Compute::findCudaDevice</a> (int deviceId=-1, bool preferMemory=false)</td></tr>
<tr class="memdesc:a58d62f6f183335114f9dd89dfefd0dad"><td class="mdescLeft">&#160;</td><td class="mdescRight">Finds the most appropriate CUDA device for computation.  <br /></td></tr>
<tr class="separator:a58d62f6f183335114f9dd89dfefd0dad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae1d32d7cbc15006084fde71c7f8d9fe1" id="r_ae1d32d7cbc15006084fde71c7f8d9fe1"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#ae1d32d7cbc15006084fde71c7f8d9fe1">getBestDevice</a> (<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> type, bool preferMemory=false)</td></tr>
<tr class="memdesc:ae1d32d7cbc15006084fde71c7f8d9fe1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the best device of a specific type based on performance characteristics.  <br /></td></tr>
<tr class="separator:ae1d32d7cbc15006084fde71c7f8d9fe1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9b44f2af3eb466afccacc8dedc589421" id="r_a9b44f2af3eb466afccacc8dedc589421"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a9b44f2af3eb466afccacc8dedc589421">Mila::Dnn::Compute::getBestDeviceId</a> (bool preferMemory=false)</td></tr>
<tr class="memdesc:a9b44f2af3eb466afccacc8dedc589421"><td class="mdescLeft">&#160;</td><td class="mdescRight">Identifies the best CUDA device based on performance characteristics.  <br /></td></tr>
<tr class="separator:a9b44f2af3eb466afccacc8dedc589421"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b2b00e63f2d2af850acece5227c63cd" id="r_a8b2b00e63f2d2af850acece5227c63cd"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a8b2b00e63f2d2af850acece5227c63cd">Mila::Dnn::Compute::getDeviceCount</a> ()</td></tr>
<tr class="memdesc:a8b2b00e63f2d2af850acece5227c63cd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the number of available CUDA devices.  <br /></td></tr>
<tr class="separator:a8b2b00e63f2d2af850acece5227c63cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3fda490e9b40a00ee92bfdb94b61a1f3" id="r_a3fda490e9b40a00ee92bfdb94b61a1f3"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a3fda490e9b40a00ee92bfdb94b61a1f3">Mila::Dnn::Compute::getDriverVersion</a> ()</td></tr>
<tr class="memdesc:a3fda490e9b40a00ee92bfdb94b61a1f3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the installed CUDA driver version.  <br /></td></tr>
<tr class="separator:a3fda490e9b40a00ee92bfdb94b61a1f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba323577eb42d9d2cb1043649db8018d" id="r_aba323577eb42d9d2cb1043649db8018d"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#aba323577eb42d9d2cb1043649db8018d">Mila::Dnn::Compute::getRuntimeVersion</a> ()</td></tr>
<tr class="memdesc:aba323577eb42d9d2cb1043649db8018d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the installed CUDA runtime version.  <br /></td></tr>
<tr class="separator:aba323577eb42d9d2cb1043649db8018d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af19cbe36b1fbdf2c0c9b63951e00e587" id="r_af19cbe36b1fbdf2c0c9b63951e00e587"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#af19cbe36b1fbdf2c0c9b63951e00e587">Mila::Dnn::Compute::isDeviceAvailable</a> (const std::string &amp;device_name)</td></tr>
<tr class="memdesc:af19cbe36b1fbdf2c0c9b63951e00e587"><td class="mdescLeft">&#160;</td><td class="mdescRight">Checks if a specific device is available.  <br /></td></tr>
<tr class="separator:af19cbe36b1fbdf2c0c9b63951e00e587"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a259f89c596b838487dc1d70e93c84a28" id="r_a259f89c596b838487dc1d70e93c84a28"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::string &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a259f89c596b838487dc1d70e93c84a28">Mila::Dnn::Compute::listDevices</a> ()</td></tr>
<tr class="memdesc:a259f89c596b838487dc1d70e93c84a28"><td class="mdescLeft">&#160;</td><td class="mdescRight">Lists all available compute devices.  <br /></td></tr>
<tr class="separator:a259f89c596b838487dc1d70e93c84a28"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab56e16e838f04b07ad1bf746bc75c635" id="r_ab56e16e838f04b07ad1bf746bc75c635"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::string &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#ab56e16e838f04b07ad1bf746bc75c635">Mila::Dnn::Compute::listDevicesByType</a> (<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> type)</td></tr>
<tr class="memdesc:ab56e16e838f04b07ad1bf746bc75c635"><td class="mdescLeft">&#160;</td><td class="mdescRight">Lists compute devices of a specific type.  <br /></td></tr>
<tr class="separator:ab56e16e838f04b07ad1bf746bc75c635"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0fd8b0110b79e4bbc96ba4fbecb3fc96" id="r_a0fd8b0110b79e4bbc96ba4fbecb3fc96"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a0fd8b0110b79e4bbc96ba4fbecb3fc96">Mila::Dnn::Compute::operationTypeToString</a> (<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11">OperationType</a> op)</td></tr>
<tr class="memdesc:a0fd8b0110b79e4bbc96ba4fbecb3fc96"><td class="mdescLeft">&#160;</td><td class="mdescRight">Converts an operation type to its string representation.  <br /></td></tr>
<tr class="separator:a0fd8b0110b79e4bbc96ba4fbecb3fc96"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a472a51381e39e5ea4fd7ecb9a1f74ba7" id="r_a472a51381e39e5ea4fd7ecb9a1f74ba7"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a472a51381e39e5ea4fd7ecb9a1f74ba7">Mila::Dnn::Compute::toDeviceType</a> (std::string device_type)</td></tr>
<tr class="memdesc:a472a51381e39e5ea4fd7ecb9a1f74ba7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Converts a string to the corresponding DeviceType.  <br /></td></tr>
<tr class="separator:a472a51381e39e5ea4fd7ecb9a1f74ba7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a66f85c884cd3dca53943bcc9242e1b9e" id="r_a66f85c884cd3dca53943bcc9242e1b9e"><td class="memTemplParams" colspan="2">template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType&gt; </td></tr>
<tr class="memitem:a66f85c884cd3dca53943bcc9242e1b9e"><td class="memTemplItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html">DeviceContext</a> &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a66f85c884cd3dca53943bcc9242e1b9e">Mila::Dnn::Compute::ValidateContext</a> (std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html">DeviceContext</a> &gt; context)</td></tr>
<tr class="memdesc:a66f85c884cd3dca53943bcc9242e1b9e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Validates that the provided context is compatible with the specified device type.  <br /></td></tr>
<tr class="separator:a66f85c884cd3dca53943bcc9242e1b9e"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a2d5ac5775f485e941cfbf70a8cc2ce12" id="r_a2d5ac5775f485e941cfbf70a8cc2ce12"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a2d5ac5775f485e941cfbf70a8cc2ce12"><td class="memTemplItemLeft" align="right" valign="top">constexpr bool&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a2d5ac5775f485e941cfbf70a8cc2ce12">always_false</a> = false</td></tr>
<tr class="separator:a2d5ac5775f485e941cfbf70a8cc2ce12"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd986c72b7e6ee39abc90c3668e385a5" id="r_acd986c72b7e6ee39abc90c3668e385a5"><td class="memItemLeft" align="right" valign="top">const float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#acd986c72b7e6ee39abc90c3668e385a5">GELU_SCALING_FACTOR</a> = sqrtf( 2.0f / M_PI )</td></tr>
<tr class="separator:acd986c72b7e6ee39abc90c3668e385a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Typedef Documentation</h2>
<a id="aed36c27e30be3933dc64c610eebc4f41" name="aed36c27e30be3933dc64c610eebc4f41"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aed36c27e30be3933dc64c610eebc4f41">&#9670;&#160;</a></span>DeviceMemoryResource</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#aed36c27e30be3933dc64c610eebc4f41">Mila::Dnn::Compute::DeviceMemoryResource</a> = typedef <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMemoryResource.html">CudaMemoryResource</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Alias for <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMemoryResource.html" title="A memory resource that allocates memory on a CUDA device.">CudaMemoryResource</a> that represents device-accessible memory. </p>
<p>This alias provides a semantic name that describes the memory's accessibility characteristics rather than its implementation details. Use DeviceMemoryResource when you need memory that can be accessed by CUDA device code and operations.</p>
<p>This naming follows CUDA conventions where "device" refers to GPU memory, while maintaining consistency with the architecture's naming pattern.</p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMemoryResource.html" title="A memory resource that allocates memory on a CUDA device.">CudaMemoryResource</a> </dd></dl>

</div>
</div>
<a id="a8c32f3f7cc6e4ef70be850a0cf5b9a62" name="a8c32f3f7cc6e4ef70be850a0cf5b9a62"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8c32f3f7cc6e4ef70be850a0cf5b9a62">&#9670;&#160;</a></span>HostMemoryResource</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a8c32f3f7cc6e4ef70be850a0cf5b9a62">Mila::Dnn::Compute::HostMemoryResource</a> = typedef <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuMemoryResource.html">CpuMemoryResource</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Alias for <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuMemoryResource.html" title="A memory resource for CPU memory allocation.">CpuMemoryResource</a> that represents host-accessible memory. </p>
<p>This alias provides a semantic name that describes the memory's accessibility characteristics rather than its implementation details. Use HostMemoryResource when you need memory that can be directly accessed from host (CPU) code.</p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuMemoryResource.html" title="A memory resource for CPU memory allocation.">CpuMemoryResource</a> </dd></dl>

</div>
</div>
<a id="a7b8ae76f48eea1ab92fc10a619f1b666" name="a7b8ae76f48eea1ab92fc10a619f1b666"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b8ae76f48eea1ab92fc10a619f1b666">&#9670;&#160;</a></span>MemoryResource</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a7b8ae76f48eea1ab92fc10a619f1b666">Mila::Dnn::Compute::MemoryResource</a> = typedef std::pmr::memory_resource</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>An alias for the standard polymorphic memory resource. </p>
<p>This provides a common abstraction for memory allocation and management across different compute devices and memory types. The memory_resource is the foundation for all memory allocations within the compute framework and can be extended for specific devices (CPU, CUDA, etc.).</p>
<dl class="section see"><dt>See also</dt><dd>std::pmr::memory_resource </dd>
<dd>
<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a8c32f3f7cc6e4ef70be850a0cf5b9a62" title="Alias for CpuMemoryResource that represents host-accessible memory.">HostMemoryResource</a> </dd>
<dd>
<a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMemoryResource.html" title="A memory resource that allocates memory on a CUDA device.">CudaMemoryResource</a> </dd></dl>

</div>
</div>
<h2 class="groupheader">Enumeration Type Documentation</h2>
<a id="a393d2d886886aa0215f25b307e4f71f4" name="a393d2d886886aa0215f25b307e4f71f4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a393d2d886886aa0215f25b307e4f71f4">&#9670;&#160;</a></span>DeviceType</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">enum class <a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">Mila::Dnn::Compute::DeviceType</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span><span class="mlabel">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Enumeration of supported compute device types. </p>
<p>Defines the types of compute devices that can be used for tensor operations and neural network computations. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="a393d2d886886aa0215f25b307e4f71f4a54c82ef76ecbbd4c2293e09bae01b54e" name="a393d2d886886aa0215f25b307e4f71f4a54c82ef76ecbbd4c2293e09bae01b54e"></a>Cpu&#160;</td><td class="fielddoc"><p>CPU device type. </p>
</td></tr>
<tr><td class="fieldname"><a id="a393d2d886886aa0215f25b307e4f71f4a8b95dcff7397d0693c03e394af5552aa" name="a393d2d886886aa0215f25b307e4f71f4a8b95dcff7397d0693c03e394af5552aa"></a>Cuda&#160;</td><td class="fielddoc"><p>CUDA GPU device type. </p>
</td></tr>
</table>

</div>
</div>
<a id="afe9b0f279fe9c233b4b5d795cb0ade11" name="afe9b0f279fe9c233b4b5d795cb0ade11"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afe9b0f279fe9c233b4b5d795cb0ade11">&#9670;&#160;</a></span>OperationType</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">enum class <a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11">Mila::Dnn::Compute::OperationType</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span><span class="mlabel">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Enumeration of all supported neural network operation types. </p>
<p>This enumeration defines the different types of operations that can be executed by the compute framework. Each operation type corresponds to a specific neural network function or layer. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="afe9b0f279fe9c233b4b5d795cb0ade11a746c5a2f065fb98c8db5b62f88012ee2" name="afe9b0f279fe9c233b4b5d795cb0ade11a746c5a2f065fb98c8db5b62f88012ee2"></a>CrossEntropyOp&#160;</td><td class="fielddoc"><p>Cross entropy loss operation. </p>
</td></tr>
<tr><td class="fieldname"><a id="afe9b0f279fe9c233b4b5d795cb0ade11a278a0c36099e2f403c47c2791940b701" name="afe9b0f279fe9c233b4b5d795cb0ade11a278a0c36099e2f403c47c2791940b701"></a>EncoderOp&#160;</td><td class="fielddoc"><p><a class="el" href="classMila_1_1Dnn_1_1Encoder.html" title="An encoder module that provides token and positional embeddings.">Encoder</a> operation for transformer architecture. </p>
</td></tr>
<tr><td class="fieldname"><a id="afe9b0f279fe9c233b4b5d795cb0ade11a0681a1f7650431f366f8f71062793c8f" name="afe9b0f279fe9c233b4b5d795cb0ade11a0681a1f7650431f366f8f71062793c8f"></a>FusedOp&#160;</td><td class="fielddoc"><p>Fused operation combining multiple operations for performance optimization. </p>
</td></tr>
<tr><td class="fieldname"><a id="afe9b0f279fe9c233b4b5d795cb0ade11a0acfa5da2fd5707d6476d71dde5cfbf5" name="afe9b0f279fe9c233b4b5d795cb0ade11a0acfa5da2fd5707d6476d71dde5cfbf5"></a>LinearOp&#160;</td><td class="fielddoc"><p><a class="el" href="classMila_1_1Dnn_1_1Linear.html" title="A class representing a linear transformation module.">Linear</a> (fully connected/dense) layer operation. </p>
</td></tr>
<tr><td class="fieldname"><a id="afe9b0f279fe9c233b4b5d795cb0ade11ac7a14b21eeb427f4799ca8cb99b3e526" name="afe9b0f279fe9c233b4b5d795cb0ade11ac7a14b21eeb427f4799ca8cb99b3e526"></a>GeluOp&#160;</td><td class="fielddoc"><p>Gaussian Error <a class="el" href="classMila_1_1Dnn_1_1Linear.html" title="A class representing a linear transformation module.">Linear</a> Unit activation function. </p>
</td></tr>
<tr><td class="fieldname"><a id="afe9b0f279fe9c233b4b5d795cb0ade11a9abe4333afd363f5778830afa47a50d1" name="afe9b0f279fe9c233b4b5d795cb0ade11a9abe4333afd363f5778830afa47a50d1"></a>LayerNormOp&#160;</td><td class="fielddoc"><p>Layer normalization operation. </p>
</td></tr>
<tr><td class="fieldname"><a id="afe9b0f279fe9c233b4b5d795cb0ade11a753dee665dd7674150f555815d471f5f" name="afe9b0f279fe9c233b4b5d795cb0ade11a753dee665dd7674150f555815d471f5f"></a>MultiHeadAttentionOp&#160;</td><td class="fielddoc"><p>Multi-head attention operation for transformers. </p>
</td></tr>
<tr><td class="fieldname"><a id="afe9b0f279fe9c233b4b5d795cb0ade11a35d8ea1936b14a4aabff8f268d50e737" name="afe9b0f279fe9c233b4b5d795cb0ade11a35d8ea1936b14a4aabff8f268d50e737"></a>ResidualOp&#160;</td><td class="fielddoc"><p><a class="el" href="classMila_1_1Dnn_1_1Residual.html" title="A class implementing a residual connection module.">Residual</a> connection operation. </p>
</td></tr>
<tr><td class="fieldname"><a id="afe9b0f279fe9c233b4b5d795cb0ade11ab7aea4f7d4e55ce130b5cca0a345f8f1" name="afe9b0f279fe9c233b4b5d795cb0ade11ab7aea4f7d4e55ce130b5cca0a345f8f1"></a>SoftmaxOp&#160;</td><td class="fielddoc"><p><a class="el" href="classMila_1_1Dnn_1_1Softmax.html" title="Softmax module for neural networks.">Softmax</a> activation function. </p>
</td></tr>
</table>

</div>
</div>
<h2 class="groupheader">Function Documentation</h2>
<a id="aa0711964e9fee40a967d47ce110040a9" name="aa0711964e9fee40a967d47ce110040a9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa0711964e9fee40a967d47ce110040a9">&#9670;&#160;</a></span>ceil_div()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">constexpr int Mila::Dnn::Compute::ceil_div </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>M</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>N</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">constexpr</span><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Calculates ceiling division for kernel grid/block dimensions. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">M</td><td>Dividend value </td></tr>
    <tr><td class="paramname">N</td><td>Divisor value </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Ceiling of M/N as an integer </dd></dl>

</div>
</div>
<a id="a96ecd0d5401f97858e0a936ad10d59a6" name="a96ecd0d5401f97858e0a936ad10d59a6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a96ecd0d5401f97858e0a936ad10d59a6">&#9670;&#160;</a></span>checkDevice()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int Mila::Dnn::Compute::checkDevice </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>deviceId</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Validates that a device ID is valid and available. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">deviceId</td><td>CUDA device ID to check </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The same device ID if valid </dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If device ID is negative </td></tr>
    <tr><td class="paramname">std::runtime_error</td><td>If no CUDA devices are available </td></tr>
    <tr><td class="paramname">std::out_of_range</td><td>If device ID exceeds available device count </td></tr>
    <tr><td class="paramname">std::runtime_error</td><td>If device is in prohibited compute mode </td></tr>
  </table>
  </dd>
</dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a96ecd0d5401f97858e0a936ad10d59a6_cgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a96ecd0d5401f97858e0a936ad10d59a6_cgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a96ecd0d5401f97858e0a936ad10d59a6_cgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a96ecd0d5401f97858e0a936ad10d59a6_cgraph">
<area shape="rect" title="Validates that a device ID is valid and available." alt="" coords="5,5,156,45"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#af02152a475c650f6a64e0f2c67c1aaf5" title="Checks the status of a CUDA operation and throws if an error occurred." alt="" coords="403,5,553,45"/>
<area shape="poly" title=" " alt="" coords="156,20,204,19,355,19,389,19,389,25,355,24,204,24,156,25"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a8b2b00e63f2d2af850acece5227c63cd" title="Gets the number of available CUDA devices." alt="" coords="204,33,355,73"/>
<area shape="poly" title=" " alt="" coords="156,33,191,38,190,43,156,39"/>
<area shape="poly" title=" " alt="" coords="354,40,389,35,389,40,355,45"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a96ecd0d5401f97858e0a936ad10d59a6_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a96ecd0d5401f97858e0a936ad10d59a6_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a96ecd0d5401f97858e0a936ad10d59a6_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a96ecd0d5401f97858e0a936ad10d59a6_icgraph">
<area shape="rect" title="Validates that a device ID is valid and available." alt="" coords="204,5,355,45"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a58d62f6f183335114f9dd89dfefd0dad" title="Finds the most appropriate CUDA device for computation." alt="" coords="5,5,156,45"/>
<area shape="poly" title=" " alt="" coords="191,28,156,28,156,23,191,23"/>
</map>
</div>

</div>
</div>
<a id="aabb558ed498e925008cd96a0b6ca224e" name="aabb558ed498e925008cd96a0b6ca224e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aabb558ed498e925008cd96a0b6ca224e">&#9670;&#160;</a></span>CreateCompatibleContext()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html">DeviceContext</a> &gt; Mila::Dnn::Compute::CreateCompatibleContext </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Creates a device context compatible with the specified device type. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">TDevice</td><td>The device type to create a context for. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>std::shared_ptr&lt;DeviceContext&gt; A new context of the appropriate type. </dd></dl>

</div>
</div>
<a id="add162bc95a4a4f23ca4e4ba91ff9f662" name="add162bc95a4a4f23ca4e4ba91ff9f662"></a>
<h2 class="memtitle"><span class="permalink"><a href="#add162bc95a4a4f23ca4e4ba91ff9f662">&#9670;&#160;</a></span>cublaslt_matmul_forward()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TDataType , typename TCompute  = float&gt; <br />
requires std::is_same_v&lt;TDataType, float&gt; || std::is_same_v&lt;TDataType, half&gt; || std::is_same_v&lt;TDataType, __nv_bfloat16&gt; || std::is_same_v&lt;TDataType, __nv_fp8_e4m3&gt;</div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cublaslt_matmul_forward </td>
          <td>(</td>
          <td class="paramtype">TDataType *&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const TDataType *&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const TDataType *&#160;</td>
          <td class="paramname"><em>weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const TDataType *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>outer_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>OC</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cublasLtHandle_t&#160;</td>
          <td class="paramname"><em>cublasLtHandle</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>cuBLASLt implementation of matrix multiplication with bias addition </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">TPrecision</td><td><a class="el" href="namespaceMila_1_1Dnn_1_1Data.html">Data</a> type for computation (float, half, etc.) </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">out</td><td>Output tensor data pointer </td></tr>
    <tr><td class="paramname">inp</td><td>Input tensor data pointer </td></tr>
    <tr><td class="paramname">weight</td><td>Weight tensor data pointer </td></tr>
    <tr><td class="paramname">bias</td><td>Bias tensor data pointer (can be nullptr) </td></tr>
    <tr><td class="paramname">B</td><td>Batch size </td></tr>
    <tr><td class="paramname">TPrecision</td><td>Sequence length </td></tr>
    <tr><td class="paramname">C</td><td>Input channels </td></tr>
    <tr><td class="paramname">OC</td><td>Output channels </td></tr>
    <tr><td class="paramname">stream</td><td>CUDA stream </td></tr>
  </table>
  </dd>
</dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_add162bc95a4a4f23ca4e4ba91ff9f662_cgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_add162bc95a4a4f23ca4e4ba91ff9f662_cgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_add162bc95a4a4f23ca4e4ba91ff9f662_cgraph" id="anamespaceMila_1_1Dnn_1_1Compute_add162bc95a4a4f23ca4e4ba91ff9f662_cgraph">
<area shape="rect" title="cuBLASLt implementation of matrix multiplication with bias addition" alt="" coords="5,37,201,77"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#afbbce0b872aa390e8b90d8d913bc1559" title="Checks the status of a cuBLASLt operation and throws if an error occurred." alt="" coords="249,5,415,45"/>
<area shape="poly" title=" " alt="" coords="201,41,235,36,236,41,202,46"/>
<area shape="rect" href="classMila_1_1Utils_1_1Logger.html#adb3c53cb169b92a9840b2d1d5f1c729a" title=" " alt="" coords="262,69,402,109"/>
<area shape="poly" title=" " alt="" coords="202,68,249,75,248,80,201,74"/>
<area shape="rect" href="classMila_1_1Utils_1_1Logger.html#a0544e33077d84fa174dd2110ef333a65" title=" " alt="" coords="463,37,603,77"/>
<area shape="poly" title=" " alt="" coords="402,76,448,68,449,73,402,81"/>
<area shape="rect" href="classMila_1_1Utils_1_1Logger.html#a0342cf64754338574ccf7c28f6482d98" title=" " alt="" coords="463,101,603,141"/>
<area shape="poly" title=" " alt="" coords="402,98,449,105,448,111,402,103"/>
</map>
</div>

</div>
</div>
<a id="afbbce0b872aa390e8b90d8d913bc1559" name="afbbce0b872aa390e8b90d8d913bc1559"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afbbce0b872aa390e8b90d8d913bc1559">&#9670;&#160;</a></span>cublasLtCheckStatus()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cublasLtCheckStatus </td>
          <td>(</td>
          <td class="paramtype">cublasStatus_t&#160;</td>
          <td class="paramname"><em>status</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::source_location &amp;&#160;</td>
          <td class="paramname"><em>location</em> = <code>std::source_location::current()</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Checks the status of a cuBLASLt operation and throws if an error occurred. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">status</td><td>The cuBLASLt error status code to check. </td></tr>
    <tr><td class="paramname">location</td><td>Source location information (automatically populated by default). </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CublasLtError.html">CublasLtError</a></td><td>if the status is not CUBLAS_STATUS_SUCCESS. </td></tr>
  </table>
  </dd>
</dl>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_afbbce0b872aa390e8b90d8d913bc1559_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_afbbce0b872aa390e8b90d8d913bc1559_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_afbbce0b872aa390e8b90d8d913bc1559_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_afbbce0b872aa390e8b90d8d913bc1559_icgraph">
<area shape="rect" title="Checks the status of a cuBLASLt operation and throws if an error occurred." alt="" coords="249,5,415,45"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#add162bc95a4a4f23ca4e4ba91ff9f662" title="cuBLASLt implementation of matrix multiplication with bias addition" alt="" coords="5,5,201,45"/>
<area shape="poly" title=" " alt="" coords="236,28,202,28,202,23,236,23"/>
</map>
</div>

</div>
</div>
<a id="a366addef6857c5a70c4ca32041783fa0" name="a366addef6857c5a70c4ca32041783fa0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a366addef6857c5a70c4ca32041783fa0">&#9670;&#160;</a></span>cuda_encoder_forward_fp16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_encoder_forward_fp16 </td>
          <td>(</td>
          <td class="paramtype">half *&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int *&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const half *&#160;</td>
          <td class="paramname"><em>wte</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const half *&#160;</td>
          <td class="paramname"><em>wpe</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>B</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>T</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a366addef6857c5a70c4ca32041783fa0_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a366addef6857c5a70c4ca32041783fa0_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a366addef6857c5a70c4ca32041783fa0_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a366addef6857c5a70c4ca32041783fa0_icgraph">
<area shape="rect" title=" " alt="" coords="224,13,437,53"/>
<area shape="rect" href="structMila_1_1Dnn_1_1Compute_1_1Detail_1_1cuda__encoder__impl_3_01half_01_4.html#a9a1ee27e6e2300109cf25d67c11946d0" title=" " alt="" coords="5,5,176,60"/>
<area shape="poly" title=" " alt="" coords="210,35,176,35,176,30,210,30"/>
</map>
</div>

</div>
</div>
<a id="a3c868f9b0924d1fa480221776b7985c2" name="a3c868f9b0924d1fa480221776b7985c2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3c868f9b0924d1fa480221776b7985c2">&#9670;&#160;</a></span>cuda_encoder_forward_fp32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_encoder_forward_fp32 </td>
          <td>(</td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int *&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>wte</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>wpe</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>B</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>T</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a3c868f9b0924d1fa480221776b7985c2_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a3c868f9b0924d1fa480221776b7985c2_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a3c868f9b0924d1fa480221776b7985c2_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a3c868f9b0924d1fa480221776b7985c2_icgraph">
<area shape="rect" title=" " alt="" coords="228,13,441,53"/>
<area shape="rect" href="structMila_1_1Dnn_1_1Compute_1_1Detail_1_1cuda__encoder__impl_3_01float_01_4.html#a35ae9fd1ec4838eca81481468ed3d5d8" title=" " alt="" coords="5,5,180,60"/>
<area shape="poly" title=" " alt="" coords="214,35,180,35,180,30,214,30"/>
</map>
</div>

</div>
</div>
<a id="a42a835f0a5a11bc570716119a4765704" name="a42a835f0a5a11bc570716119a4765704"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a42a835f0a5a11bc570716119a4765704">&#9670;&#160;</a></span>cuda_gelu_backward_fp16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_gelu_backward_fp16 </td>
          <td>(</td>
          <td class="paramtype">half *&#160;</td>
          <td class="paramname"><em>dX</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const half *&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const half *&#160;</td>
          <td class="paramname"><em>dY</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>N</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3e8dcac0f2ac5c24a627fbe2b9be9671" name="a3e8dcac0f2ac5c24a627fbe2b9be9671"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3e8dcac0f2ac5c24a627fbe2b9be9671">&#9670;&#160;</a></span>cuda_gelu_backward_fp32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_gelu_backward_fp32 </td>
          <td>(</td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>dX</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>dY</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>N</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a3e8dcac0f2ac5c24a627fbe2b9be9671_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a3e8dcac0f2ac5c24a627fbe2b9be9671_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a3e8dcac0f2ac5c24a627fbe2b9be9671_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a3e8dcac0f2ac5c24a627fbe2b9be9671_icgraph">
<area shape="rect" title=" " alt="" coords="209,20,412,60"/>
<area shape="rect" href="structMila_1_1Dnn_1_1Compute_1_1Detail_1_1cuda__gelu__impl_3_01float_01_4.html#a1a99a3860e937f0eb03295c0195daca9" title=" " alt="" coords="5,5,161,75"/>
<area shape="poly" title=" " alt="" coords="195,43,161,43,161,37,195,37"/>
</map>
</div>

</div>
</div>
<a id="a2bd00e832a92926319daf2f0984e5fd7" name="a2bd00e832a92926319daf2f0984e5fd7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2bd00e832a92926319daf2f0984e5fd7">&#9670;&#160;</a></span>cuda_gelu_forward_fp16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_gelu_forward_fp16 </td>
          <td>(</td>
          <td class="paramtype">half *&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const half *&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>N</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a2bd00e832a92926319daf2f0984e5fd7_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a2bd00e832a92926319daf2f0984e5fd7_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a2bd00e832a92926319daf2f0984e5fd7_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a2bd00e832a92926319daf2f0984e5fd7_icgraph">
<area shape="rect" title=" " alt="" coords="224,13,413,53"/>
<area shape="rect" href="structMila_1_1Dnn_1_1Compute_1_1Detail_1_1cuda__gelu__impl_3_01half_01_4.html#a225901892bad59989ab4968d72b284ae" title=" " alt="" coords="5,5,176,60"/>
<area shape="poly" title=" " alt="" coords="210,35,176,35,176,30,210,30"/>
</map>
</div>

</div>
</div>
<a id="a053c82c575baebe18906be8ef85b5d1a" name="a053c82c575baebe18906be8ef85b5d1a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a053c82c575baebe18906be8ef85b5d1a">&#9670;&#160;</a></span>cuda_gelu_forward_fp32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_gelu_forward_fp32 </td>
          <td>(</td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>N</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a053c82c575baebe18906be8ef85b5d1a_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a053c82c575baebe18906be8ef85b5d1a_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a053c82c575baebe18906be8ef85b5d1a_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a053c82c575baebe18906be8ef85b5d1a_icgraph">
<area shape="rect" title=" " alt="" coords="209,20,399,60"/>
<area shape="rect" href="structMila_1_1Dnn_1_1Compute_1_1Detail_1_1cuda__gelu__impl_3_01float_01_4.html#a1a99a3860e937f0eb03295c0195daca9" title=" " alt="" coords="5,5,161,75"/>
<area shape="poly" title=" " alt="" coords="196,43,162,43,162,37,196,37"/>
</map>
</div>

</div>
</div>
<a id="a015e542888fbd38e2048df219fd4665c" name="a015e542888fbd38e2048df219fd4665c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a015e542888fbd38e2048df219fd4665c">&#9670;&#160;</a></span>cuda_layernorm_forward_fp16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_layernorm_forward_fp16 </td>
          <td>(</td>
          <td class="paramtype">half *&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">half *&#160;</td>
          <td class="paramname"><em>mean</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">half *&#160;</td>
          <td class="paramname"><em>rstd</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const half *&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const half *&#160;</td>
          <td class="paramname"><em>weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const half *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>B</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>T</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a015e542888fbd38e2048df219fd4665c_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a015e542888fbd38e2048df219fd4665c_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a015e542888fbd38e2048df219fd4665c_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a015e542888fbd38e2048df219fd4665c_icgraph">
<area shape="rect" title=" " alt="" coords="236,13,464,53"/>
<area shape="rect" href="structMila_1_1Dnn_1_1Compute_1_1Detail_1_1cuda__layernorm__impl_3_01half_01_4.html#a60c04df72aa23b106ead1b552af59cf3" title=" " alt="" coords="5,5,188,60"/>
<area shape="poly" title=" " alt="" coords="222,35,188,35,188,30,222,30"/>
</map>
</div>

</div>
</div>
<a id="a9a810f32be785c810b2d8738290c33eb" name="a9a810f32be785c810b2d8738290c33eb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9a810f32be785c810b2d8738290c33eb">&#9670;&#160;</a></span>cuda_layernorm_forward_fp32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_layernorm_forward_fp32 </td>
          <td>(</td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>mean</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>rstd</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>B</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>T</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a9a810f32be785c810b2d8738290c33eb_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a9a810f32be785c810b2d8738290c33eb_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a9a810f32be785c810b2d8738290c33eb_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a9a810f32be785c810b2d8738290c33eb_icgraph">
<area shape="rect" title=" " alt="" coords="236,13,464,53"/>
<area shape="rect" href="structMila_1_1Dnn_1_1Compute_1_1Detail_1_1cuda__layernorm__impl_3_01float_01_4.html#ac5c210d24366a971a3eb7741e9c7b82e" title=" " alt="" coords="5,5,188,60"/>
<area shape="poly" title=" " alt="" coords="222,35,188,35,188,30,222,30"/>
</map>
</div>

</div>
</div>
<a id="a60405d0daed6cb8d910a3d4da2795f9f" name="a60405d0daed6cb8d910a3d4da2795f9f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a60405d0daed6cb8d910a3d4da2795f9f">&#9670;&#160;</a></span>cuda_matmul_forward_fp16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_matmul_forward_fp16 </td>
          <td>(</td>
          <td class="paramtype">half *&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const half *&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const half *&#160;</td>
          <td class="paramname"><em>weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const half *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>outer_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>OC</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a60405d0daed6cb8d910a3d4da2795f9f_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a60405d0daed6cb8d910a3d4da2795f9f_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a60405d0daed6cb8d910a3d4da2795f9f_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a60405d0daed6cb8d910a3d4da2795f9f_icgraph">
<area shape="rect" title=" " alt="" coords="224,13,436,53"/>
<area shape="rect" href="structMila_1_1Dnn_1_1Compute_1_1Detail_1_1cuda__matmul__impl_3_01half_01_4.html#a04de8d2a326fef8a786a99cb62ace2ca" title=" " alt="" coords="5,5,176,60"/>
<area shape="poly" title=" " alt="" coords="210,35,176,35,176,30,210,30"/>
</map>
</div>

</div>
</div>
<a id="a6eda598cf61e803efbe42800f7d3bf9d" name="a6eda598cf61e803efbe42800f7d3bf9d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6eda598cf61e803efbe42800f7d3bf9d">&#9670;&#160;</a></span>cuda_matmul_forward_fp32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_matmul_forward_fp32 </td>
          <td>(</td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>weight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>outer_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>OC</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a6eda598cf61e803efbe42800f7d3bf9d_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a6eda598cf61e803efbe42800f7d3bf9d_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a6eda598cf61e803efbe42800f7d3bf9d_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a6eda598cf61e803efbe42800f7d3bf9d_icgraph">
<area shape="rect" title=" " alt="" coords="228,13,440,53"/>
<area shape="rect" href="structMila_1_1Dnn_1_1Compute_1_1Detail_1_1cuda__matmul__impl_3_01float_01_4.html#af548084321b26862f49c6a2893995aae" title=" " alt="" coords="5,5,180,60"/>
<area shape="poly" title=" " alt="" coords="215,35,180,35,180,30,215,30"/>
</map>
</div>

</div>
</div>
<a id="ac47dfe5123c2b0b33c17a037c47d2a13" name="ac47dfe5123c2b0b33c17a037c47d2a13"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac47dfe5123c2b0b33c17a037c47d2a13">&#9670;&#160;</a></span>cuda_mha_forward_fp16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_mha_forward_fp16 </td>
          <td>(</td>
          <td class="paramtype">half *&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">half *&#160;</td>
          <td class="paramname"><em>qkvr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">half *&#160;</td>
          <td class="paramname"><em>att</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const half *&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>B</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>T</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>NH</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a375d72038d6d1326b6b595096e76a5ed" name="a375d72038d6d1326b6b595096e76a5ed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a375d72038d6d1326b6b595096e76a5ed">&#9670;&#160;</a></span>cuda_mha_forward_fp32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_mha_forward_fp32 </td>
          <td>(</td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>qkvr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>att</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>B</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>T</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>NH</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a375d72038d6d1326b6b595096e76a5ed_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a375d72038d6d1326b6b595096e76a5ed_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a375d72038d6d1326b6b595096e76a5ed_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a375d72038d6d1326b6b595096e76a5ed_icgraph">
<area shape="rect" title=" " alt="" coords="233,13,424,53"/>
<area shape="rect" href="structMila_1_1Dnn_1_1Compute_1_1Detail_1_1cuda__mha__impl_3_01float_01_4.html#aec7435e6d103194b0ba78acd3affcf2b" title=" " alt="" coords="5,5,185,60"/>
<area shape="poly" title=" " alt="" coords="219,35,185,35,185,30,219,30"/>
</map>
</div>

</div>
</div>
<a id="ac16d74cbeabd3e400f948789cf3336bc" name="ac16d74cbeabd3e400f948789cf3336bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac16d74cbeabd3e400f948789cf3336bc">&#9670;&#160;</a></span>cuda_residual_forward_fp16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_residual_forward_fp16 </td>
          <td>(</td>
          <td class="paramtype">half *&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const half *&#160;</td>
          <td class="paramname"><em>X1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const half *&#160;</td>
          <td class="paramname"><em>X2</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>N</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_ac16d74cbeabd3e400f948789cf3336bc_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_ac16d74cbeabd3e400f948789cf3336bc_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_ac16d74cbeabd3e400f948789cf3336bc_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_ac16d74cbeabd3e400f948789cf3336bc_icgraph">
<area shape="rect" title=" " alt="" coords="224,13,437,53"/>
<area shape="rect" href="structMila_1_1Dnn_1_1Compute_1_1Detail_1_1cuda__residual__impl_3_01half_01_4.html#af34025d5d653cf1a19399215232cbc02" title=" " alt="" coords="5,5,176,60"/>
<area shape="poly" title=" " alt="" coords="210,35,176,35,176,30,210,30"/>
</map>
</div>

</div>
</div>
<a id="aa80d55b23db037fa0d11e200342133fe" name="aa80d55b23db037fa0d11e200342133fe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa80d55b23db037fa0d11e200342133fe">&#9670;&#160;</a></span>cuda_residual_forward_fp32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_residual_forward_fp32 </td>
          <td>(</td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>X1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>X2</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>N</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_aa80d55b23db037fa0d11e200342133fe_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_aa80d55b23db037fa0d11e200342133fe_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_aa80d55b23db037fa0d11e200342133fe_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_aa80d55b23db037fa0d11e200342133fe_icgraph">
<area shape="rect" title=" " alt="" coords="228,13,441,53"/>
<area shape="rect" href="structMila_1_1Dnn_1_1Compute_1_1Detail_1_1cuda__residual__impl_3_01float_01_4.html#aba59fac7f1156f5bb44bf9bb2d4fc653" title=" " alt="" coords="5,5,180,60"/>
<area shape="poly" title=" " alt="" coords="214,35,180,35,180,30,214,30"/>
</map>
</div>

</div>
</div>
<a id="a6c99f562b010b1d7c93b19e81aa07054" name="a6c99f562b010b1d7c93b19e81aa07054"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6c99f562b010b1d7c93b19e81aa07054">&#9670;&#160;</a></span>cuda_softmax_crossentropy_backward()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TPrecision &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_softmax_crossentropy_backward </td>
          <td>(</td>
          <td class="paramtype">TPrecision *&#160;</td>
          <td class="paramname"><em>dlogits</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const TPrecision *&#160;</td>
          <td class="paramname"><em>dlosses</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const TPrecision *&#160;</td>
          <td class="paramname"><em>probs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int *&#160;</td>
          <td class="paramname"><em>targets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>seq_len</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>vocab_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="abdd81adcc543bffda394b5ef6742cb32" name="abdd81adcc543bffda394b5ef6742cb32"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abdd81adcc543bffda394b5ef6742cb32">&#9670;&#160;</a></span>cuda_softmax_crossentropy_forward()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TPrecision &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_softmax_crossentropy_forward </td>
          <td>(</td>
          <td class="paramtype">TPrecision *&#160;</td>
          <td class="paramname"><em>losses</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">TPrecision *&#160;</td>
          <td class="paramname"><em>probs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const TPrecision *&#160;</td>
          <td class="paramname"><em>logits</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int *&#160;</td>
          <td class="paramname"><em>targets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>seq_len</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>vocab_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8f94ddbf4b181078f079c0cf49f01256" name="a8f94ddbf4b181078f079c0cf49f01256"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8f94ddbf4b181078f079c0cf49f01256">&#9670;&#160;</a></span>cuda_softmax_forward()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TPrecision &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_softmax_forward </td>
          <td>(</td>
          <td class="paramtype">TPrecision *&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const TPrecision *&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>N</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>C</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3a4587581d8fb126179468a0af8e3075" name="a3a4587581d8fb126179468a0af8e3075"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3a4587581d8fb126179468a0af8e3075">&#9670;&#160;</a></span>cuda_softmax_forward_general()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TPrecision &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cuda_softmax_forward_general </td>
          <td>(</td>
          <td class="paramtype">TPrecision *&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const TPrecision *&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>outer_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>dim_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>inner_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab06697660f29cc1d553a3ce26951d6d5" name="ab06697660f29cc1d553a3ce26951d6d5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab06697660f29cc1d553a3ce26951d6d5">&#9670;&#160;</a></span>cudaCheckLastError()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cudaCheckLastError </td>
          <td>(</td>
          <td class="paramtype">const std::source_location &amp;&#160;</td>
          <td class="paramname"><em>location</em> = <code>std::source_location::current()</code></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Checks the last CUDA error and throws if an error occurred. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">location</td><td>Source location information (automatically populated by default). </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaError.html" title="Exception class for CUDA runtime errors.">CudaError</a></td><td>if the last error is not cudaSuccess. </td></tr>
  </table>
  </dd>
</dl>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_ab06697660f29cc1d553a3ce26951d6d5_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_ab06697660f29cc1d553a3ce26951d6d5_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_ab06697660f29cc1d553a3ce26951d6d5_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_ab06697660f29cc1d553a3ce26951d6d5_icgraph">
<area shape="rect" title="Checks the last CUDA error and throws if an error occurred." alt="" coords="231,13,389,53"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1CudaMemoryResource.html#ad5609224eda17eedd97c7e7e4da1181c" title="Deallocates memory on the CUDA device." alt="" coords="5,5,183,60"/>
<area shape="poly" title=" " alt="" coords="217,35,183,35,183,30,217,30"/>
</map>
</div>

</div>
</div>
<a id="af02152a475c650f6a64e0f2c67c1aaf5" name="af02152a475c650f6a64e0f2c67c1aaf5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af02152a475c650f6a64e0f2c67c1aaf5">&#9670;&#160;</a></span>cudaCheckStatus()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void Mila::Dnn::Compute::cudaCheckStatus </td>
          <td>(</td>
          <td class="paramtype">cudaError_t&#160;</td>
          <td class="paramname"><em>status</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::source_location &amp;&#160;</td>
          <td class="paramname"><em>location</em> = <code>std::source_location::current()</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Checks the status of a CUDA operation and throws if an error occurred. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">status</td><td>The CUDA error status code to check. </td></tr>
    <tr><td class="paramname">location</td><td>Source location information (automatically populated by default). </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaError.html" title="Exception class for CUDA runtime errors.">CudaError</a></td><td>if the status is not cudaSuccess. </td></tr>
  </table>
  </dd>
</dl>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_af02152a475c650f6a64e0f2c67c1aaf5_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_af02152a475c650f6a64e0f2c67c1aaf5_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_af02152a475c650f6a64e0f2c67c1aaf5_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_af02152a475c650f6a64e0f2c67c1aaf5_icgraph">
<area shape="rect" title="Checks the status of a CUDA operation and throws if an error occurred." alt="" coords="671,200,821,240"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1DeviceProps.html#a529dd50ac0b8d13b093136abf7db0175" title=" " alt="" coords="423,5,623,45"/>
<area shape="poly" title=" " alt="" coords="725,190,682,127,653,95,621,66,588,48,591,43,624,62,657,91,686,124,729,187"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a96ecd0d5401f97858e0a936ad10d59a6" title="Validates that a device ID is valid and available." alt="" coords="214,115,365,155"/>
<area shape="poly" title=" " alt="" coords="720,191,678,147,651,126,622,110,587,100,552,94,479,93,410,103,351,117,350,112,409,98,478,88,552,89,589,95,624,106,654,121,682,143,724,187"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1CudaMemoryResource.html#ad5609224eda17eedd97c7e7e4da1181c" title="Deallocates memory on the CUDA device." alt="" coords="434,121,611,175"/>
<area shape="poly" title=" " alt="" coords="669,198,607,178,609,173,671,193"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a8b2b00e63f2d2af850acece5227c63cd" title="Gets the number of available CUDA devices." alt="" coords="447,200,598,240"/>
<area shape="poly" title=" " alt="" coords="657,223,598,223,598,217,657,217"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a3fda490e9b40a00ee92bfdb94b61a1f3" title="Gets the installed CUDA driver version." alt="" coords="447,264,598,304"/>
<area shape="poly" title=" " alt="" coords="663,246,594,267,592,261,662,241"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#aba323577eb42d9d2cb1043649db8018d" title="Gets the installed CUDA runtime version." alt="" coords="445,328,600,368"/>
<area shape="poly" title=" " alt="" coords="716,251,674,286,624,318,597,330,595,325,621,314,671,282,712,247"/>
<area shape="rect" href="classMila_1_1Dnn_1_1TensorBuffer.html#a7d6a1db3f2401e0a42aeb2b2e6524222" title="Resizes the buffer to a new size, preserving existing data when possible." alt="" coords="436,392,609,432"/>
<area shape="poly" title=" " alt="" coords="730,254,688,319,658,353,624,382,603,394,600,390,621,378,655,349,684,315,726,251"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a58d62f6f183335114f9dd89dfefd0dad" title="Finds the most appropriate CUDA device for computation." alt="" coords="5,169,156,209"/>
<area shape="poly" title=" " alt="" coords="201,161,157,172,156,167,200,155"/>
<area shape="poly" title=" " alt="" coords="446,198,422,189,339,157,341,152,424,184,448,193"/>
<area shape="poly" title=" " alt="" coords="433,217,156,197,157,192,434,211"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a9b44f2af3eb466afccacc8dedc589421" title="Identifies the best CUDA device based on performance characteristics." alt="" coords="214,229,365,269"/>
<area shape="poly" title=" " alt="" coords="434,234,365,243,364,237,433,229"/>
<area shape="poly" title=" " alt="" coords="205,228,150,212,152,207,207,223"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#ae1d32d7cbc15006084fde71c7f8d9fe1" title="Gets the best device of a specific type based on performance characteristics." alt="" coords="5,233,156,273"/>
<area shape="poly" title=" " alt="" coords="200,254,156,255,156,249,200,248"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1DeviceProps.html#aee43b0cbb5985b608ed2f51d6d5b5ce9" title=" " alt="" coords="204,296,375,336"/>
<area shape="poly" title=" " alt="" coords="434,299,375,307,374,302,433,294"/>
<area shape="poly" title=" " alt="" coords="431,338,374,330,375,325,432,333"/>
</map>
</div>

</div>
</div>
<a id="abc57784bcbd77f21ea2524f0161e7e4f" name="abc57784bcbd77f21ea2524f0161e7e4f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abc57784bcbd77f21ea2524f0161e7e4f">&#9670;&#160;</a></span>deviceToString()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::string Mila::Dnn::Compute::deviceToString </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a>&#160;</td>
          <td class="paramname"><em>device_type</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Converts a DeviceType to its string representation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">device_type</td><td>The device type to convert. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>std::string The string representation of the device type ("CPU" or "CUDA"). </dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>If the device type is invalid. </td></tr>
  </table>
  </dd>
</dl>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_abc57784bcbd77f21ea2524f0161e7e4f_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_abc57784bcbd77f21ea2524f0161e7e4f_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_abc57784bcbd77f21ea2524f0161e7e4f_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_abc57784bcbd77f21ea2524f0161e7e4f_icgraph">
<area shape="rect" title="Converts a DeviceType to its string representation." alt="" coords="272,443,423,483"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Module.html#a9c68c425ffc1643d090c881f935b1d81" title="Constructor with device name." alt="" coords="41,5,189,45"/>
<area shape="poly" title=" " alt="" coords="343,429,338,353,321,254,306,201,285,150,257,102,222,59,206,47,188,39,190,34,209,43,226,55,261,99,289,147,311,200,326,253,344,353,349,429"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Module.html#a2c3a64e5bc2b0d9464d341a86bf52a69" title="Constructor with a specific device context." alt="" coords="41,69,189,109"/>
<area shape="poly" title=" " alt="" coords="341,429,332,364,312,282,297,239,277,197,252,158,222,123,206,112,188,103,190,98,209,107,226,119,257,154,282,194,302,237,318,280,338,363,346,428"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#ae1d32d7cbc15006084fde71c7f8d9fe1" title="Gets the best device of a specific type based on performance characteristics." alt="" coords="39,133,190,173"/>
<area shape="poly" title=" " alt="" coords="338,430,326,376,304,311,270,244,248,214,222,187,189,168,191,164,226,183,252,211,274,242,309,309,331,375,343,429"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#ab56e16e838f04b07ad1bf746bc75c635" title="Lists compute devices of a specific type." alt="" coords="39,197,190,237"/>
<area shape="poly" title=" " alt="" coords="333,430,318,389,294,341,262,293,222,251,189,233,191,229,226,247,267,289,299,338,322,387,338,429"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Model.html#ab1d7e81eeb43446ce683e4990cbcf34c" title="Prints the model&#39;s structure and total number of parameters." alt="" coords="29,262,200,287"/>
<area shape="poly" title=" " alt="" coords="328,431,287,364,257,330,223,301,199,290,202,285,225,296,261,326,291,361,333,429"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Gelu.html#a0fb000c57a6bbdfc2121b060269e2a29" title="Generates a string representation of this module&#39;s configuration." alt="" coords="24,311,205,337"/>
<area shape="poly" title=" " alt="" coords="320,434,277,390,251,368,223,350,195,339,197,334,225,346,254,364,281,386,324,430"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MLP.html#aee8a9284ec818f02e5ede4cc0552758f" title="Generates a string representation of this module&#39;s configuration." alt="" coords="25,361,204,386"/>
<area shape="poly" title=" " alt="" coords="300,438,223,401,182,389,183,384,225,396,303,433"/>
<area shape="rect" href="classMila_1_1Dnn_1_1TransformerBlock.html#add82601fef958270857c9bfcdc7bc238" title="Generates a string representation of this module&#39;s configuration." alt="" coords="11,411,218,451"/>
<area shape="poly" title=" " alt="" coords="258,453,218,448,219,442,259,448"/>
<area shape="rect" href="classMila_1_1Dnn_1_1CompositeModule.html#a6d0e6e057478620c6a6f243cc31efbb9" title="Default toString implementation for container modules." alt="" coords="9,475,220,515"/>
<area shape="poly" title=" " alt="" coords="259,477,220,483,220,478,258,472"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Linear.html#a0c546375aeed14578ca460df4569b394" title="Converts the module information to a human&#45;readable string." alt="" coords="45,539,185,579"/>
<area shape="poly" title=" " alt="" coords="301,492,225,529,186,543,184,538,223,524,299,487"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a91762121adfdf91a746f16619b26fb98" title="Generates a string representation of this module&#39;s configuration." alt="" coords="5,603,224,643"/>
<area shape="poly" title=" " alt="" coords="326,496,283,546,256,571,225,593,201,605,199,600,223,588,252,567,279,542,322,492"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Residual.html#a8b3c6febf9f356726599e1266eb92b03" title="Converts the module information to a human&#45;readable string." alt="" coords="41,667,189,707"/>
<area shape="poly" title=" " alt="" coords="336,497,319,534,295,577,264,620,226,657,190,675,188,670,222,652,260,617,291,574,314,532,331,495"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Softmax.html#a3fb73fc80d74a0c68e4384249e0d1c07" title="Generates a string representation of this module&#39;s configuration." alt="" coords="41,731,188,771"/>
<area shape="poly" title=" " alt="" coords="342,497,328,546,305,607,272,668,250,696,226,721,208,732,189,741,187,736,206,728,222,717,246,692,267,665,301,604,323,545,337,495"/>
<area shape="rect" href="classMila_1_1Dnn_1_1CrossEntropy.html#a69dae26995d248d7a22b761f7c809c82" title="Generates a string representation of this module&#39;s configuration." alt="" coords="25,795,204,835"/>
<area shape="poly" title=" " alt="" coords="345,497,335,558,315,635,299,676,279,715,255,752,226,785,206,799,203,794,222,781,251,749,275,713,294,674,310,634,330,557,340,496"/>
<area shape="rect" href="classMila_1_1Dnn_1_1LayerNorm.html#ae921e4baf1dc5898e061fca3a48284e0" title="Generates a string representation of this module&#39;s configuration." alt="" coords="33,859,197,899"/>
<area shape="poly" title=" " alt="" coords="348,496,342,569,323,663,308,713,287,762,260,808,226,849,198,867,196,862,222,845,256,805,282,760,303,711,318,662,336,568,343,496"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Dropout.html#af55518e3523b5f13530ae33fefec28cc" title="Generates a string representation of this module&#39;s configuration." alt="" coords="43,923,187,963"/>
<area shape="poly" title=" " alt="" coords="350,496,347,580,342,633,332,691,316,751,294,809,265,864,226,913,208,926,188,935,186,930,205,922,222,909,260,861,289,807,311,749,326,690,336,632,342,579,345,496"/>
</map>
</div>

</div>
</div>
<a id="a58d62f6f183335114f9dd89dfefd0dad" name="a58d62f6f183335114f9dd89dfefd0dad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a58d62f6f183335114f9dd89dfefd0dad">&#9670;&#160;</a></span>findCudaDevice()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int Mila::Dnn::Compute::findCudaDevice </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>deviceId</em> = <code>-1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>preferMemory</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Finds the most appropriate CUDA device for computation. </p>
<p>Either validates a specific device ID if provided or finds the best available device when no preference is specified.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">deviceId</td><td>Preferred device ID, or -1 to select the best device </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Valid CUDA device ID </dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>If no CUDA devices are found </td></tr>
  </table>
  </dd>
</dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a58d62f6f183335114f9dd89dfefd0dad_cgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a58d62f6f183335114f9dd89dfefd0dad_cgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a58d62f6f183335114f9dd89dfefd0dad_cgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a58d62f6f183335114f9dd89dfefd0dad_cgraph">
<area shape="rect" title="Finds the most appropriate CUDA device for computation." alt="" coords="5,63,156,103"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a96ecd0d5401f97858e0a936ad10d59a6" title="Validates that a device ID is valid and available." alt="" coords="204,5,355,45"/>
<area shape="poly" title=" " alt="" coords="150,60,195,47,197,52,151,65"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a8b2b00e63f2d2af850acece5227c63cd" title="Gets the number of available CUDA devices." alt="" coords="403,63,553,103"/>
<area shape="poly" title=" " alt="" coords="156,80,389,80,389,85,156,85"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a9b44f2af3eb466afccacc8dedc589421" title="Identifies the best CUDA device based on performance characteristics." alt="" coords="204,120,355,160"/>
<area shape="poly" title=" " alt="" coords="151,100,197,113,195,119,150,105"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#af02152a475c650f6a64e0f2c67c1aaf5" title="Checks the status of a CUDA operation and throws if an error occurred." alt="" coords="601,35,752,75"/>
<area shape="poly" title=" " alt="" coords="355,28,588,45,587,51,355,34"/>
<area shape="poly" title=" " alt="" coords="350,43,395,56,394,61,348,48"/>
<area shape="poly" title=" " alt="" coords="553,69,587,65,588,70,554,75"/>
<area shape="poly" title=" " alt="" coords="348,117,394,104,395,109,350,123"/>
</map>
</div>

</div>
</div>
<a id="ae1d32d7cbc15006084fde71c7f8d9fe1" name="ae1d32d7cbc15006084fde71c7f8d9fe1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae1d32d7cbc15006084fde71c7f8d9fe1">&#9670;&#160;</a></span>getBestDevice()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::string Mila::Dnn::Compute::getBestDevice </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a>&#160;</td>
          <td class="paramname"><em>type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>preferMemory</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Gets the best device of a specific type based on performance characteristics. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">type</td><td>The device type to filter by (e.g., Cuda) </td></tr>
    <tr><td class="paramname">preferMemory</td><td>When true, prioritizes memory bandwidth over compute capability </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>std::string Identifier of the best available device </dd></dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_ae1d32d7cbc15006084fde71c7f8d9fe1_cgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_ae1d32d7cbc15006084fde71c7f8d9fe1_cgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_ae1d32d7cbc15006084fde71c7f8d9fe1_cgraph" id="anamespaceMila_1_1Dnn_1_1Compute_ae1d32d7cbc15006084fde71c7f8d9fe1_cgraph">
<area shape="rect" title="Gets the best device of a specific type based on performance characteristics." alt="" coords="5,69,156,109"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#abc57784bcbd77f21ea2524f0161e7e4f" title="Converts a DeviceType to its string representation." alt="" coords="204,5,355,45"/>
<area shape="poly" title=" " alt="" coords="143,67,203,47,205,52,144,72"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a9b44f2af3eb466afccacc8dedc589421" title="Identifies the best CUDA device based on performance characteristics." alt="" coords="204,69,355,109"/>
<area shape="poly" title=" " alt="" coords="156,87,190,87,190,92,156,92"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a259f89c596b838487dc1d70e93c84a28" title="Lists all available compute devices." alt="" coords="204,133,355,173"/>
<area shape="poly" title=" " alt="" coords="144,107,205,127,203,132,143,112"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a8b2b00e63f2d2af850acece5227c63cd" title="Gets the number of available CUDA devices." alt="" coords="423,69,573,109"/>
<area shape="poly" title=" " alt="" coords="355,87,409,87,409,92,355,92"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#af02152a475c650f6a64e0f2c67c1aaf5" title="Checks the status of a CUDA operation and throws if an error occurred." alt="" coords="641,69,792,109"/>
<area shape="poly" title=" " alt="" coords="574,87,628,87,628,92,574,92"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1DeviceRegistry.html#a7fad4212ab870e74917da2abcaf77938" title="Gets the singleton instance of the DeviceRegistry." alt="" coords="403,133,593,173"/>
<area shape="poly" title=" " alt="" coords="355,151,389,151,389,156,355,156"/>
</map>
</div>

</div>
</div>
<a id="a9b44f2af3eb466afccacc8dedc589421" name="a9b44f2af3eb466afccacc8dedc589421"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9b44f2af3eb466afccacc8dedc589421">&#9670;&#160;</a></span>getBestDeviceId()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int Mila::Dnn::Compute::getBestDeviceId </td>
          <td>(</td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>preferMemory</em> = <code>false</code></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Identifies the best CUDA device based on performance characteristics. </p>
<p>Evaluates available CUDA devices and selects the one with highest performance potential. Selection criteria vary based on the intended workload type.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">preferMemory</td><td>When true, prioritizes memory bandwidth over compute </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Device ID of the best available CUDA device </dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaError.html" title="Exception class for CUDA runtime errors.">CudaError</a></td><td>If device properties cannot be accessed </td></tr>
  </table>
  </dd>
</dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a9b44f2af3eb466afccacc8dedc589421_cgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a9b44f2af3eb466afccacc8dedc589421_cgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a9b44f2af3eb466afccacc8dedc589421_cgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a9b44f2af3eb466afccacc8dedc589421_cgraph">
<area shape="rect" title="Identifies the best CUDA device based on performance characteristics." alt="" coords="5,5,156,45"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a8b2b00e63f2d2af850acece5227c63cd" title="Gets the number of available CUDA devices." alt="" coords="204,5,355,45"/>
<area shape="poly" title=" " alt="" coords="156,23,190,23,190,28,156,28"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#af02152a475c650f6a64e0f2c67c1aaf5" title="Checks the status of a CUDA operation and throws if an error occurred." alt="" coords="403,5,553,45"/>
<area shape="poly" title=" " alt="" coords="355,23,389,23,389,28,355,28"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a9b44f2af3eb466afccacc8dedc589421_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a9b44f2af3eb466afccacc8dedc589421_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a9b44f2af3eb466afccacc8dedc589421_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a9b44f2af3eb466afccacc8dedc589421_icgraph">
<area shape="rect" title="Identifies the best CUDA device based on performance characteristics." alt="" coords="204,37,355,77"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a58d62f6f183335114f9dd89dfefd0dad" title="Finds the most appropriate CUDA device for computation." alt="" coords="5,5,156,45"/>
<area shape="poly" title=" " alt="" coords="190,46,156,40,157,35,191,40"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#ae1d32d7cbc15006084fde71c7f8d9fe1" title="Gets the best device of a specific type based on performance characteristics." alt="" coords="5,69,156,109"/>
<area shape="poly" title=" " alt="" coords="191,74,157,80,156,75,190,69"/>
</map>
</div>

</div>
</div>
<a id="a8b2b00e63f2d2af850acece5227c63cd" name="a8b2b00e63f2d2af850acece5227c63cd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8b2b00e63f2d2af850acece5227c63cd">&#9670;&#160;</a></span>getDeviceCount()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int Mila::Dnn::Compute::getDeviceCount </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the number of available CUDA devices. </p>
<dl class="section return"><dt>Returns</dt><dd>Number of CUDA devices available to the application </dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaError.html" title="Exception class for CUDA runtime errors.">CudaError</a></td><td>If device enumeration fails </td></tr>
  </table>
  </dd>
</dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a8b2b00e63f2d2af850acece5227c63cd_cgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a8b2b00e63f2d2af850acece5227c63cd_cgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a8b2b00e63f2d2af850acece5227c63cd_cgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a8b2b00e63f2d2af850acece5227c63cd_cgraph">
<area shape="rect" title="Gets the number of available CUDA devices." alt="" coords="5,5,156,45"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#af02152a475c650f6a64e0f2c67c1aaf5" title="Checks the status of a CUDA operation and throws if an error occurred." alt="" coords="204,5,355,45"/>
<area shape="poly" title=" " alt="" coords="156,23,190,23,190,28,156,28"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a8b2b00e63f2d2af850acece5227c63cd_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a8b2b00e63f2d2af850acece5227c63cd_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a8b2b00e63f2d2af850acece5227c63cd_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a8b2b00e63f2d2af850acece5227c63cd_icgraph">
<area shape="rect" title="Gets the number of available CUDA devices." alt="" coords="403,63,553,103"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a96ecd0d5401f97858e0a936ad10d59a6" title="Validates that a device ID is valid and available." alt="" coords="204,5,355,45"/>
<area shape="poly" title=" " alt="" coords="394,61,349,48,350,43,396,56"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a58d62f6f183335114f9dd89dfefd0dad" title="Finds the most appropriate CUDA device for computation." alt="" coords="5,59,156,99"/>
<area shape="poly" title=" " alt="" coords="389,84,156,82,156,77,389,79"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#a9b44f2af3eb466afccacc8dedc589421" title="Identifies the best CUDA device based on performance characteristics." alt="" coords="204,120,355,160"/>
<area shape="poly" title=" " alt="" coords="396,109,350,122,349,117,394,104"/>
<area shape="poly" title=" " alt="" coords="192,52,157,61,155,56,191,46"/>
<area shape="poly" title=" " alt="" coords="200,118,145,101,147,96,202,113"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#ae1d32d7cbc15006084fde71c7f8d9fe1" title="Gets the best device of a specific type based on performance characteristics." alt="" coords="5,123,156,163"/>
<area shape="poly" title=" " alt="" coords="191,144,156,144,156,139,191,139"/>
</map>
</div>

</div>
</div>
<a id="a3fda490e9b40a00ee92bfdb94b61a1f3" name="a3fda490e9b40a00ee92bfdb94b61a1f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3fda490e9b40a00ee92bfdb94b61a1f3">&#9670;&#160;</a></span>getDriverVersion()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int Mila::Dnn::Compute::getDriverVersion </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the installed CUDA driver version. </p>
<dl class="section return"><dt>Returns</dt><dd>Integer representation of the CUDA driver version </dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaError.html" title="Exception class for CUDA runtime errors.">CudaError</a></td><td>If driver version cannot be determined </td></tr>
  </table>
  </dd>
</dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a3fda490e9b40a00ee92bfdb94b61a1f3_cgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a3fda490e9b40a00ee92bfdb94b61a1f3_cgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a3fda490e9b40a00ee92bfdb94b61a1f3_cgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a3fda490e9b40a00ee92bfdb94b61a1f3_cgraph">
<area shape="rect" title="Gets the installed CUDA driver version." alt="" coords="5,5,156,45"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#af02152a475c650f6a64e0f2c67c1aaf5" title="Checks the status of a CUDA operation and throws if an error occurred." alt="" coords="204,5,355,45"/>
<area shape="poly" title=" " alt="" coords="156,23,190,23,190,28,156,28"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a3fda490e9b40a00ee92bfdb94b61a1f3_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a3fda490e9b40a00ee92bfdb94b61a1f3_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a3fda490e9b40a00ee92bfdb94b61a1f3_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a3fda490e9b40a00ee92bfdb94b61a1f3_icgraph">
<area shape="rect" title="Gets the installed CUDA driver version." alt="" coords="224,5,375,45"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1DeviceProps.html#aee43b0cbb5985b608ed2f51d6d5b5ce9" title=" " alt="" coords="5,5,176,45"/>
<area shape="poly" title=" " alt="" coords="210,28,176,28,176,23,210,23"/>
</map>
</div>

</div>
</div>
<a id="aba323577eb42d9d2cb1043649db8018d" name="aba323577eb42d9d2cb1043649db8018d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aba323577eb42d9d2cb1043649db8018d">&#9670;&#160;</a></span>getRuntimeVersion()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int Mila::Dnn::Compute::getRuntimeVersion </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the installed CUDA runtime version. </p>
<dl class="section return"><dt>Returns</dt><dd>Integer representation of the CUDA runtime version </dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaError.html" title="Exception class for CUDA runtime errors.">CudaError</a></td><td>If runtime version cannot be determined </td></tr>
  </table>
  </dd>
</dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_aba323577eb42d9d2cb1043649db8018d_cgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_aba323577eb42d9d2cb1043649db8018d_cgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_aba323577eb42d9d2cb1043649db8018d_cgraph" id="anamespaceMila_1_1Dnn_1_1Compute_aba323577eb42d9d2cb1043649db8018d_cgraph">
<area shape="rect" title="Gets the installed CUDA runtime version." alt="" coords="5,5,160,45"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#af02152a475c650f6a64e0f2c67c1aaf5" title="Checks the status of a CUDA operation and throws if an error occurred." alt="" coords="208,5,359,45"/>
<area shape="poly" title=" " alt="" coords="161,23,194,23,194,28,161,28"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_aba323577eb42d9d2cb1043649db8018d_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_aba323577eb42d9d2cb1043649db8018d_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_aba323577eb42d9d2cb1043649db8018d_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_aba323577eb42d9d2cb1043649db8018d_icgraph">
<area shape="rect" title="Gets the installed CUDA runtime version." alt="" coords="224,5,379,45"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1DeviceProps.html#aee43b0cbb5985b608ed2f51d6d5b5ce9" title=" " alt="" coords="5,5,176,45"/>
<area shape="poly" title=" " alt="" coords="210,28,176,28,176,23,210,23"/>
</map>
</div>

</div>
</div>
<a id="af19cbe36b1fbdf2c0c9b63951e00e587" name="af19cbe36b1fbdf2c0c9b63951e00e587"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af19cbe36b1fbdf2c0c9b63951e00e587">&#9670;&#160;</a></span>isDeviceAvailable()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool Mila::Dnn::Compute::isDeviceAvailable </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>device_name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Checks if a specific device is available. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">device_name</td><td>The name of the device to check (e.g., "CPU", "CUDA:0"). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>bool True if the device is available, false otherwise. </dd></dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_af19cbe36b1fbdf2c0c9b63951e00e587_cgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_af19cbe36b1fbdf2c0c9b63951e00e587_cgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_af19cbe36b1fbdf2c0c9b63951e00e587_cgraph" id="anamespaceMila_1_1Dnn_1_1Compute_af19cbe36b1fbdf2c0c9b63951e00e587_cgraph">
<area shape="rect" title="Checks if a specific device is available." alt="" coords="5,5,156,45"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1DeviceRegistry.html#a7fad4212ab870e74917da2abcaf77938" title="Gets the singleton instance of the DeviceRegistry." alt="" coords="204,5,395,45"/>
<area shape="poly" title=" " alt="" coords="156,23,190,23,190,28,156,28"/>
</map>
</div>

</div>
</div>
<a id="a259f89c596b838487dc1d70e93c84a28" name="a259f89c596b838487dc1d70e93c84a28"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a259f89c596b838487dc1d70e93c84a28">&#9670;&#160;</a></span>listDevices()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; std::string &gt; Mila::Dnn::Compute::listDevices </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Lists all available compute devices. </p>
<p>This function returns a list of all available compute devices that can be used with <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html" title="The DeviceContext class manages device contexts for module and tensor computations.">DeviceContext</a>.</p>
<dl class="section return"><dt>Returns</dt><dd>std::vector&lt;std::string&gt; A list of device identifiers (e.g., "CPU", "CUDA:0", "CUDA:1"). </dd></dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a259f89c596b838487dc1d70e93c84a28_cgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a259f89c596b838487dc1d70e93c84a28_cgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a259f89c596b838487dc1d70e93c84a28_cgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a259f89c596b838487dc1d70e93c84a28_cgraph">
<area shape="rect" title="Lists all available compute devices." alt="" coords="5,5,156,45"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1DeviceRegistry.html#a7fad4212ab870e74917da2abcaf77938" title="Gets the singleton instance of the DeviceRegistry." alt="" coords="204,5,395,45"/>
<area shape="poly" title=" " alt="" coords="156,23,190,23,190,28,156,28"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a259f89c596b838487dc1d70e93c84a28_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a259f89c596b838487dc1d70e93c84a28_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a259f89c596b838487dc1d70e93c84a28_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a259f89c596b838487dc1d70e93c84a28_icgraph">
<area shape="rect" title="Lists all available compute devices." alt="" coords="204,5,355,45"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#ae1d32d7cbc15006084fde71c7f8d9fe1" title="Gets the best device of a specific type based on performance characteristics." alt="" coords="5,5,156,45"/>
<area shape="poly" title=" " alt="" coords="191,28,156,28,156,23,191,23"/>
</map>
</div>

</div>
</div>
<a id="ab56e16e838f04b07ad1bf746bc75c635" name="ab56e16e838f04b07ad1bf746bc75c635"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab56e16e838f04b07ad1bf746bc75c635">&#9670;&#160;</a></span>listDevicesByType()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; std::string &gt; Mila::Dnn::Compute::listDevicesByType </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a>&#160;</td>
          <td class="paramname"><em>type</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Lists compute devices of a specific type. </p>
<p>Filters the available devices by their type, returning only devices that match the specified type. This allows clients to efficiently discover devices with specific capabilities.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">type</td><td>The device type to filter by </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>std::vector&lt;std::string&gt; List of matching device identifiers </dd></dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_ab56e16e838f04b07ad1bf746bc75c635_cgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_ab56e16e838f04b07ad1bf746bc75c635_cgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_ab56e16e838f04b07ad1bf746bc75c635_cgraph" id="anamespaceMila_1_1Dnn_1_1Compute_ab56e16e838f04b07ad1bf746bc75c635_cgraph">
<area shape="rect" title="Lists compute devices of a specific type." alt="" coords="5,37,156,77"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#abc57784bcbd77f21ea2524f0161e7e4f" title="Converts a DeviceType to its string representation." alt="" coords="224,5,375,45"/>
<area shape="poly" title=" " alt="" coords="156,44,210,36,211,41,157,49"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1DeviceRegistry.html#a7fad4212ab870e74917da2abcaf77938" title="Gets the singleton instance of the DeviceRegistry." alt="" coords="204,69,395,109"/>
<area shape="poly" title=" " alt="" coords="157,66,191,71,190,76,156,71"/>
</map>
</div>

</div>
</div>
<a id="a0fd8b0110b79e4bbc96ba4fbecb3fc96" name="a0fd8b0110b79e4bbc96ba4fbecb3fc96"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0fd8b0110b79e4bbc96ba4fbecb3fc96">&#9670;&#160;</a></span>operationTypeToString()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::string Mila::Dnn::Compute::operationTypeToString </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11">OperationType</a>&#160;</td>
          <td class="paramname"><em>op</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Converts an operation type to its string representation. </p>
<p>This utility function converts an OperationType enum value to a human-readable string representation, which can be used for logging, debugging, or serialization.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">op</td><td>The operation type to convert to string </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>std::string The string representation of the operation type </dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>If the operation type is invalid or not recognized </td></tr>
  </table>
  </dd>
</dl>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="namespaceMila_1_1Dnn_1_1Compute_a0fd8b0110b79e4bbc96ba4fbecb3fc96_icgraph.png" border="0" usemap="#anamespaceMila_1_1Dnn_1_1Compute_a0fd8b0110b79e4bbc96ba4fbecb3fc96_icgraph" alt=""/></div>
<map name="anamespaceMila_1_1Dnn_1_1Compute_a0fd8b0110b79e4bbc96ba4fbecb3fc96_icgraph" id="anamespaceMila_1_1Dnn_1_1Compute_a0fd8b0110b79e4bbc96ba4fbecb3fc96_icgraph">
<area shape="rect" title="Converts an operation type to its string representation." alt="" coords="236,13,411,53"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1OperationRegistry.html#aa911b14191b4358022447413a6a0260e" title="Register a fused operation." alt="" coords="5,5,188,60"/>
<area shape="poly" title=" " alt="" coords="222,35,188,35,188,30,222,30"/>
</map>
</div>

</div>
</div>
<a id="a472a51381e39e5ea4fd7ecb9a1f74ba7" name="a472a51381e39e5ea4fd7ecb9a1f74ba7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a472a51381e39e5ea4fd7ecb9a1f74ba7">&#9670;&#160;</a></span>toDeviceType()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> Mila::Dnn::Compute::toDeviceType </td>
          <td>(</td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>device_type</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Converts a string to the corresponding DeviceType. </p>
<p>Performs case-insensitive matching to convert device type strings to the corresponding enum value.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">device_type</td><td>The string representation of the device type. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>DeviceType The corresponding device type enum value. </dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>If the string does not represent a valid device type. Valid options are: "CPU", "CUDA", "AUTO". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>"AUTO" option is currently commented out in implementation. </dd></dl>

</div>
</div>
<a id="a66f85c884cd3dca53943bcc9242e1b9e" name="a66f85c884cd3dca53943bcc9242e1b9e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a66f85c884cd3dca53943bcc9242e1b9e">&#9670;&#160;</a></span>ValidateContext()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html">DeviceContext</a> &gt; Mila::Dnn::Compute::ValidateContext </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html">DeviceContext</a> &gt;&#160;</td>
          <td class="paramname"><em>context</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Validates that the provided context is compatible with the specified device type. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">TDevice</td><td>The device type to validate against. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">context</td><td>The context to validate. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>std::shared_ptr&lt;DeviceContext&gt; The validated context. </dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If the context is null. </td></tr>
    <tr><td class="paramname">std::runtime_error</td><td>If the context is incompatible with TDevice. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a2d5ac5775f485e941cfbf70a8cc2ce12" name="a2d5ac5775f485e941cfbf70a8cc2ce12"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2d5ac5775f485e941cfbf70a8cc2ce12">&#9670;&#160;</a></span>always_false</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">constexpr bool Mila::Dnn::Compute::always_false = false</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="acd986c72b7e6ee39abc90c3668e385a5" name="acd986c72b7e6ee39abc90c3668e385a5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acd986c72b7e6ee39abc90c3668e385a5">&#9670;&#160;</a></span>GELU_SCALING_FACTOR</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const float Mila::Dnn::Compute::GELU_SCALING_FACTOR = sqrtf( 2.0f / M_PI )</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespaceMila.html">Mila</a></li><li class="navelem"><a class="el" href="namespaceMila_1_1Dnn.html">Dnn</a></li><li class="navelem"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html">Compute</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
