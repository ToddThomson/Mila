<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Mila: Mila::Dnn::LayerNorm&lt; TInput, TPrecision, TDeviceType &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Mila
   </div>
   <div id="projectbrief">Deep Neural Network Library</div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('class_mila_1_1_dnn_1_1_layer_norm.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pri-methods">Private Member Functions</a> &#124;
<a href="#pri-attribs">Private Attributes</a> &#124;
<a href="class_mila_1_1_dnn_1_1_layer_norm-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">Mila::Dnn::LayerNorm&lt; TInput, TPrecision, TDeviceType &gt; Class Template Reference<span class="mlabels"><span class="mlabel export">export</span></span><div class="ingroups">module <a class="el" href="module___dnn_8_modules_8_layer_norm.html">Dnn.Modules.LayerNorm</a></div></div></div>
</div><!--header-->
<div class="contents">

<p>Layer Normalization module.  
 <a href="#details">More...</a></p>
<div class="dynheader">
Inheritance diagram for Mila::Dnn::LayerNorm&lt; TInput, TPrecision, TDeviceType &gt;:</div>
<div class="dyncontent">
 <div class="center">
  <img src="class_mila_1_1_dnn_1_1_layer_norm.png" usemap="#Mila::Dnn::LayerNorm_3C_20TInput_2C_20TPrecision_2C_20TDeviceType_20_3E_map" alt=""/>
  <map id="Mila::Dnn::LayerNorm_3C_20TInput_2C_20TPrecision_2C_20TDeviceType_20_3E_map" name="Mila::Dnn::LayerNorm_3C_20TInput_2C_20TPrecision_2C_20TDeviceType_20_3E_map">
<area href="class_mila_1_1_dnn_1_1_module.html" alt="Mila::Dnn::Module&lt; TInput, TInput, Compute::DeviceType::Cuda &gt;" shape="rect" coords="0,0,382,24"/>
  </map>
</div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-types" name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:ab96302e6797e85e2654ff34392a5d8da" id="r_ab96302e6797e85e2654ff34392a5d8da"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a> = std::conditional_t&lt;TDeviceType == <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4a8b95dcff7397d0693c03e394af5552aa">Compute::DeviceType::Cuda</a>, <a class="el" href="class_mila_1_1_dnn_1_1_compute_1_1_device_memory_resource.html">Compute::DeviceMemoryResource</a>, <a class="el" href="class_mila_1_1_dnn_1_1_compute_1_1_host_memory_resource.html">Compute::HostMemoryResource</a>&gt;</td></tr>
<tr class="memdesc:ab96302e6797e85e2654ff34392a5d8da"><td class="mdescLeft">&#160;</td><td class="mdescRight">Memory resource type based on the device type.  <br /></td></tr>
<tr class="separator:ab96302e6797e85e2654ff34392a5d8da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_types_class_mila_1_1_dnn_1_1_module"><td colspan="2" onclick="javascript:dynsection.toggleInherit('pub_types_class_mila_1_1_dnn_1_1_module')"><img src="closed.png" alt="-"/>&#160;Public Types inherited from <a class="el" href="class_mila_1_1_dnn_1_1_module.html">Mila::Dnn::Module&lt; TInput, TInput, Compute::DeviceType::Cuda &gt;</a></td></tr>
<tr class="memitem:ac18c08e7167030eaba576b5238c94d74 inherit pub_types_class_mila_1_1_dnn_1_1_module" id="r_ac18c08e7167030eaba576b5238c94d74"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_mila_1_1_dnn_1_1_module.html#ac18c08e7167030eaba576b5238c94d74">MR</a></td></tr>
<tr class="separator:ac18c08e7167030eaba576b5238c94d74 inherit pub_types_class_mila_1_1_dnn_1_1_module"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a8a1849fe66e55fb3c086661e590e64d6" id="r_a8a1849fe66e55fb3c086661e590e64d6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a8a1849fe66e55fb3c086661e590e64d6">LayerNorm</a> (std::string name, const std::vector&lt; size_t &gt; &amp;input_shape, int64_t axis=-1, bool has_bias=true, bool is_training=false)</td></tr>
<tr class="memdesc:a8a1849fe66e55fb3c086661e590e64d6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs a new <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html" title="Layer Normalization module.">LayerNorm</a> object.  <br /></td></tr>
<tr class="separator:a8a1849fe66e55fb3c086661e590e64d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a020c4e56c216596acf217105ba81385f" id="r_a020c4e56c216596acf217105ba81385f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a020c4e56c216596acf217105ba81385f">forward</a> (const <a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; TInput, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a> &gt; &amp;input, <a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; TPrecision, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a> &gt; &amp;output)</td></tr>
<tr class="memdesc:a020c4e56c216596acf217105ba81385f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs the forward pass of the Layer Normalization operation.  <br /></td></tr>
<tr class="separator:a020c4e56c216596acf217105ba81385f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad7616bc29f922e321552d6f67f52ba40" id="r_ad7616bc29f922e321552d6f67f52ba40"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; TInput, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad7616bc29f922e321552d6f67f52ba40">getBias</a> ()</td></tr>
<tr class="memdesc:ad7616bc29f922e321552d6f67f52ba40"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the bias tensor used after normalization and scaling.  <br /></td></tr>
<tr class="separator:ad7616bc29f922e321552d6f67f52ba40"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6a54464bb7b0596a3c7d33e0878a4bb7" id="r_a6a54464bb7b0596a3c7d33e0878a4bb7"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; TInput, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a6a54464bb7b0596a3c7d33e0878a4bb7">getWeight</a> ()</td></tr>
<tr class="memdesc:a6a54464bb7b0596a3c7d33e0878a4bb7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the weight tensor used for scaling after normalization.  <br /></td></tr>
<tr class="separator:a6a54464bb7b0596a3c7d33e0878a4bb7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ccd1ec0f1ef3f3d70a10d6fabcefa46" id="r_a5ccd1ec0f1ef3f3d70a10d6fabcefa46"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5ccd1ec0f1ef3f3d70a10d6fabcefa46">load</a> (mz_zip_archive &amp;zip) override</td></tr>
<tr class="memdesc:a5ccd1ec0f1ef3f3d70a10d6fabcefa46"><td class="mdescLeft">&#160;</td><td class="mdescRight">Loads the module state from a ZIP archive.  <br /></td></tr>
<tr class="separator:a5ccd1ec0f1ef3f3d70a10d6fabcefa46"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf339ab2b66839e9b356e3e6c1586485" id="r_abf339ab2b66839e9b356e3e6c1586485"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#abf339ab2b66839e9b356e3e6c1586485">parameterCount</a> () const override</td></tr>
<tr class="memdesc:abf339ab2b66839e9b356e3e6c1586485"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the number of trainable parameters in this module.  <br /></td></tr>
<tr class="separator:abf339ab2b66839e9b356e3e6c1586485"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a239f1ebf13fec1265d1d8d26e720b117" id="r_a239f1ebf13fec1265d1d8d26e720b117"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a239f1ebf13fec1265d1d8d26e720b117">save</a> (mz_zip_archive &amp;zip) const override</td></tr>
<tr class="memdesc:a239f1ebf13fec1265d1d8d26e720b117"><td class="mdescLeft">&#160;</td><td class="mdescRight">Saves the module state to a ZIP archive.  <br /></td></tr>
<tr class="separator:a239f1ebf13fec1265d1d8d26e720b117"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a416e79a91da6c073e5aedeb4f0e62245" id="r_a416e79a91da6c073e5aedeb4f0e62245"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a416e79a91da6c073e5aedeb4f0e62245">toString</a> () const override</td></tr>
<tr class="memdesc:a416e79a91da6c073e5aedeb4f0e62245"><td class="mdescLeft">&#160;</td><td class="mdescRight">Converts the module information to a human-readable string.  <br /></td></tr>
<tr class="separator:a416e79a91da6c073e5aedeb4f0e62245"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_class_mila_1_1_dnn_1_1_module"><td colspan="2" onclick="javascript:dynsection.toggleInherit('pub_methods_class_mila_1_1_dnn_1_1_module')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="class_mila_1_1_dnn_1_1_module.html">Mila::Dnn::Module&lt; TInput, TInput, Compute::DeviceType::Cuda &gt;</a></td></tr>
<tr class="memitem:a7a9e855139381995afb6e7d51be85d18 inherit pub_methods_class_mila_1_1_dnn_1_1_module" id="r_a7a9e855139381995afb6e7d51be85d18"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_mila_1_1_dnn_1_1_module.html#a7a9e855139381995afb6e7d51be85d18">~Module</a> ()=default</td></tr>
<tr class="separator:a7a9e855139381995afb6e7d51be85d18 inherit pub_methods_class_mila_1_1_dnn_1_1_module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01f9e9e61e840817e841b05440c32d0d inherit pub_methods_class_mila_1_1_dnn_1_1_module" id="r_a01f9e9e61e840817e841b05440c32d0d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_mila_1_1_dnn_1_1_module.html#a01f9e9e61e840817e841b05440c32d0d">addModule</a> (std::shared_ptr&lt; <a class="el" href="class_mila_1_1_dnn_1_1_module.html">Module</a>&lt; TInput, TInput, TDeviceType &gt; &gt; module)</td></tr>
<tr class="memdesc:a01f9e9e61e840817e841b05440c32d0d inherit pub_methods_class_mila_1_1_dnn_1_1_module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Register a child module.  <br /></td></tr>
<tr class="separator:a01f9e9e61e840817e841b05440c32d0d inherit pub_methods_class_mila_1_1_dnn_1_1_module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc7f9ed647754f206d507e109d0768f0 inherit pub_methods_class_mila_1_1_dnn_1_1_module" id="r_adc7f9ed647754f206d507e109d0768f0"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_mila_1_1_dnn_1_1_module.html#adc7f9ed647754f206d507e109d0768f0">getName</a> () const</td></tr>
<tr class="memdesc:adc7f9ed647754f206d507e109d0768f0 inherit pub_methods_class_mila_1_1_dnn_1_1_module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the name of the module.  <br /></td></tr>
<tr class="separator:adc7f9ed647754f206d507e109d0768f0 inherit pub_methods_class_mila_1_1_dnn_1_1_module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab972a637ef909d427796b65d3ec22ac4 inherit pub_methods_class_mila_1_1_dnn_1_1_module" id="r_ab972a637ef909d427796b65d3ec22ac4"><td class="memItemLeft" align="right" valign="top">const std::unordered_map&lt; std::string, std::shared_ptr&lt; <a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; TInput, <a class="el" href="class_mila_1_1_dnn_1_1_module.html#ac18c08e7167030eaba576b5238c94d74">MR</a> &gt; &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_mila_1_1_dnn_1_1_module.html#ab972a637ef909d427796b65d3ec22ac4">getParameterTensors</a> () const</td></tr>
<tr class="separator:ab972a637ef909d427796b65d3ec22ac4 inherit pub_methods_class_mila_1_1_dnn_1_1_module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae597b147c714e9f75b34a1b463777aec inherit pub_methods_class_mila_1_1_dnn_1_1_module" id="r_ae597b147c714e9f75b34a1b463777aec"><td class="memItemLeft" align="right" valign="top">const std::unordered_map&lt; std::string, std::shared_ptr&lt; <a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; TInput, <a class="el" href="class_mila_1_1_dnn_1_1_module.html#ac18c08e7167030eaba576b5238c94d74">MR</a> &gt; &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_mila_1_1_dnn_1_1_module.html#ae597b147c714e9f75b34a1b463777aec">getStateTensors</a> () const</td></tr>
<tr class="separator:ae597b147c714e9f75b34a1b463777aec inherit pub_methods_class_mila_1_1_dnn_1_1_module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea48ab532b8b13820acbdfe9765a48b2 inherit pub_methods_class_mila_1_1_dnn_1_1_module" id="r_aea48ab532b8b13820acbdfe9765a48b2"><td class="memItemLeft" align="right" valign="top">const std::vector&lt; std::shared_ptr&lt; <a class="el" href="class_mila_1_1_dnn_1_1_module.html">Module</a>&lt; TInput, TInput, TDeviceType &gt; &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_mila_1_1_dnn_1_1_module.html#aea48ab532b8b13820acbdfe9765a48b2">getSubModules</a> () const</td></tr>
<tr class="separator:aea48ab532b8b13820acbdfe9765a48b2 inherit pub_methods_class_mila_1_1_dnn_1_1_module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3fc7e4035042fd7584ee1fe29dfab05c inherit pub_methods_class_mila_1_1_dnn_1_1_module" id="r_a3fc7e4035042fd7584ee1fe29dfab05c"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_mila_1_1_dnn_1_1_module.html#a3fc7e4035042fd7584ee1fe29dfab05c">isTraining</a> () const</td></tr>
<tr class="memdesc:a3fc7e4035042fd7584ee1fe29dfab05c inherit pub_methods_class_mila_1_1_dnn_1_1_module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Check if the module is in training mode.  <br /></td></tr>
<tr class="separator:a3fc7e4035042fd7584ee1fe29dfab05c inherit pub_methods_class_mila_1_1_dnn_1_1_module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad2f14c8a28fe6bbe1c7748bc9fca08e3 inherit pub_methods_class_mila_1_1_dnn_1_1_module" id="r_ad2f14c8a28fe6bbe1c7748bc9fca08e3"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_mila_1_1_dnn_1_1_module.html#ad2f14c8a28fe6bbe1c7748bc9fca08e3">setName</a> (const std::string &amp;name)</td></tr>
<tr class="memdesc:ad2f14c8a28fe6bbe1c7748bc9fca08e3 inherit pub_methods_class_mila_1_1_dnn_1_1_module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the name of the module.  <br /></td></tr>
<tr class="separator:ad2f14c8a28fe6bbe1c7748bc9fca08e3 inherit pub_methods_class_mila_1_1_dnn_1_1_module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2ab035156adc5326be61d75930a79a31 inherit pub_methods_class_mila_1_1_dnn_1_1_module" id="r_a2ab035156adc5326be61d75930a79a31"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_mila_1_1_dnn_1_1_module.html#a2ab035156adc5326be61d75930a79a31">setTraining</a> (bool is_training)</td></tr>
<tr class="separator:a2ab035156adc5326be61d75930a79a31 inherit pub_methods_class_mila_1_1_dnn_1_1_module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17d62c0daec5309771670fff1e2cc405 inherit pub_methods_class_mila_1_1_dnn_1_1_module" id="r_a17d62c0daec5309771670fff1e2cc405"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_mila_1_1_dnn_1_1_module.html#a17d62c0daec5309771670fff1e2cc405">setTrainingMode</a> (bool training)</td></tr>
<tr class="memdesc:a17d62c0daec5309771670fff1e2cc405 inherit pub_methods_class_mila_1_1_dnn_1_1_module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the training mode of the module.  <br /></td></tr>
<tr class="separator:a17d62c0daec5309771670fff1e2cc405 inherit pub_methods_class_mila_1_1_dnn_1_1_module"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-methods" name="pri-methods"></a>
Private Member Functions</h2></td></tr>
<tr class="memitem:add5d808349e4a8ee60447a6739545db7" id="r_add5d808349e4a8ee60447a6739545db7"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#add5d808349e4a8ee60447a6739545db7">createOperation</a> ()</td></tr>
<tr class="memdesc:add5d808349e4a8ee60447a6739545db7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates the appropriate Layer Normalization operation based on device type.  <br /></td></tr>
<tr class="separator:add5d808349e4a8ee60447a6739545db7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d5224eb2e7235b7dbb7a14513b11bde" id="r_a5d5224eb2e7235b7dbb7a14513b11bde"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5d5224eb2e7235b7dbb7a14513b11bde">initializeTensors</a> ()</td></tr>
<tr class="memdesc:a5d5224eb2e7235b7dbb7a14513b11bde"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initializes the tensors needed for the Layer Normalization operation.  <br /></td></tr>
<tr class="separator:a5d5224eb2e7235b7dbb7a14513b11bde"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-attribs" name="pri-attribs"></a>
Private Attributes</h2></td></tr>
<tr class="memitem:a2860415cd495f3e02648407826eb20b1" id="r_a2860415cd495f3e02648407826eb20b1"><td class="memItemLeft" align="right" valign="top">int64_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a2860415cd495f3e02648407826eb20b1">axis_</a> { -1 }</td></tr>
<tr class="memdesc:a2860415cd495f3e02648407826eb20b1"><td class="mdescLeft">&#160;</td><td class="mdescRight">The axis along which to normalize.  <br /></td></tr>
<tr class="separator:a2860415cd495f3e02648407826eb20b1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3286de3c5838fab290958f9b6d9637a7" id="r_a3286de3c5838fab290958f9b6d9637a7"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; float, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a3286de3c5838fab290958f9b6d9637a7">bias_</a> { nullptr }</td></tr>
<tr class="memdesc:a3286de3c5838fab290958f9b6d9637a7"><td class="mdescLeft">&#160;</td><td class="mdescRight">The bias tensor added after normalization and scaling.  <br /></td></tr>
<tr class="separator:a3286de3c5838fab290958f9b6d9637a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aab31f7db365120be65e3b59ed51b367d" id="r_aab31f7db365120be65e3b59ed51b367d"><td class="memItemLeft" align="right" valign="top">float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aab31f7db365120be65e3b59ed51b367d">epsilon_</a> { 1e-05f }</td></tr>
<tr class="memdesc:aab31f7db365120be65e3b59ed51b367d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Small constant added to variance for numerical stability.  <br /></td></tr>
<tr class="separator:aab31f7db365120be65e3b59ed51b367d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a236b4383254bdcd16b05149a8910c754" id="r_a236b4383254bdcd16b05149a8910c754"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a236b4383254bdcd16b05149a8910c754">has_bias_</a> { true }</td></tr>
<tr class="memdesc:a236b4383254bdcd16b05149a8910c754"><td class="mdescLeft">&#160;</td><td class="mdescRight">Whether the module has a bias tensor.  <br /></td></tr>
<tr class="separator:a236b4383254bdcd16b05149a8910c754"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a58634c2c40b13fce94fc8529fff393b1" id="r_a58634c2c40b13fce94fc8529fff393b1"><td class="memItemLeft" align="right" valign="top">std::vector&lt; size_t &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a58634c2c40b13fce94fc8529fff393b1">input_shape_</a></td></tr>
<tr class="memdesc:a58634c2c40b13fce94fc8529fff393b1"><td class="mdescLeft">&#160;</td><td class="mdescRight">The shape of the input tensor to be normalized.  <br /></td></tr>
<tr class="separator:a58634c2c40b13fce94fc8529fff393b1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a44da92c83cc096adc40ef4af692a6c3b" id="r_a44da92c83cc096adc40ef4af692a6c3b"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; float, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a44da92c83cc096adc40ef4af692a6c3b">mean_</a> = { nullptr }</td></tr>
<tr class="memdesc:a44da92c83cc096adc40ef4af692a6c3b"><td class="mdescLeft">&#160;</td><td class="mdescRight">The mean tensor used for normalization.  <br /></td></tr>
<tr class="separator:a44da92c83cc096adc40ef4af692a6c3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acbd9cf0245137b65979462d822127bbd" id="r_acbd9cf0245137b65979462d822127bbd"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="class_mila_1_1_dnn_1_1_compute_1_1_unary_operation.html">Dnn::Compute::UnaryOperation</a>&lt; TInput, TPrecision, TDeviceType &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#acbd9cf0245137b65979462d822127bbd">operation_</a></td></tr>
<tr class="memdesc:acbd9cf0245137b65979462d822127bbd"><td class="mdescLeft">&#160;</td><td class="mdescRight">The underlying operation that implements Layer Normalization.  <br /></td></tr>
<tr class="separator:acbd9cf0245137b65979462d822127bbd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a559ef3283a055071a380ed0b1a73f4b8" id="r_a559ef3283a055071a380ed0b1a73f4b8"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::shared_ptr&lt; <a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; float, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a> &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a559ef3283a055071a380ed0b1a73f4b8">output_state_</a></td></tr>
<tr class="memdesc:a559ef3283a055071a380ed0b1a73f4b8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Cache of intermediate tensors needed for backward pass.  <br /></td></tr>
<tr class="separator:a559ef3283a055071a380ed0b1a73f4b8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4ce62cd5ed888224cf0b51c26704fe13" id="r_a4ce62cd5ed888224cf0b51c26704fe13"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::shared_ptr&lt; <a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; float, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a> &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a4ce62cd5ed888224cf0b51c26704fe13">parameters_</a></td></tr>
<tr class="memdesc:a4ce62cd5ed888224cf0b51c26704fe13"><td class="mdescLeft">&#160;</td><td class="mdescRight">The trainable parameters for this module (weight and bias).  <br /></td></tr>
<tr class="separator:a4ce62cd5ed888224cf0b51c26704fe13"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac7abf91898a639f922f4a4f347852036" id="r_ac7abf91898a639f922f4a4f347852036"><td class="memItemLeft" align="right" valign="top"><a class="el" href="struct_mila_1_1_dnn_1_1_compute_1_1_operation_attributes.html">OperationAttributes</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ac7abf91898a639f922f4a4f347852036">properties_</a></td></tr>
<tr class="memdesc:ac7abf91898a639f922f4a4f347852036"><td class="mdescLeft">&#160;</td><td class="mdescRight">The operation attributes, including epsilon and axis information.  <br /></td></tr>
<tr class="separator:ac7abf91898a639f922f4a4f347852036"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1b4fd5b5b7205098358da2761396f8ee" id="r_a1b4fd5b5b7205098358da2761396f8ee"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; float, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a1b4fd5b5b7205098358da2761396f8ee">rstd_</a> { nullptr }</td></tr>
<tr class="memdesc:a1b4fd5b5b7205098358da2761396f8ee"><td class="mdescLeft">&#160;</td><td class="mdescRight">The reciprocal standard deviation tensor.  <br /></td></tr>
<tr class="separator:a1b4fd5b5b7205098358da2761396f8ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a59819b943b99c696796e8f5a744e9f81" id="r_a59819b943b99c696796e8f5a744e9f81"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; float, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a59819b943b99c696796e8f5a744e9f81">weight_</a> { nullptr }</td></tr>
<tr class="memdesc:a59819b943b99c696796e8f5a744e9f81"><td class="mdescLeft">&#160;</td><td class="mdescRight">The weight tensor for scaling after normalization.  <br /></td></tr>
<tr class="separator:a59819b943b99c696796e8f5a744e9f81"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="inherited" name="inherited"></a>
Additional Inherited Members</h2></td></tr>
<tr class="inherit_header pro_methods_class_mila_1_1_dnn_1_1_module"><td colspan="2" onclick="javascript:dynsection.toggleInherit('pro_methods_class_mila_1_1_dnn_1_1_module')"><img src="closed.png" alt="-"/>&#160;Protected Member Functions inherited from <a class="el" href="class_mila_1_1_dnn_1_1_module.html">Mila::Dnn::Module&lt; TInput, TInput, Compute::DeviceType::Cuda &gt;</a></td></tr>
<tr class="memitem:acb03ea2584440a573dfda079d8858906 inherit pro_methods_class_mila_1_1_dnn_1_1_module" id="r_acb03ea2584440a573dfda079d8858906"><td class="memItemLeft" align="right" valign="top">const std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_mila_1_1_dnn_1_1_module.html#acb03ea2584440a573dfda079d8858906">parametersToString</a> () const</td></tr>
<tr class="separator:acb03ea2584440a573dfda079d8858906 inherit pro_methods_class_mila_1_1_dnn_1_1_module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a37c244f23034b5a40c425db1165c9d88 inherit pro_methods_class_mila_1_1_dnn_1_1_module" id="r_a37c244f23034b5a40c425db1165c9d88"><td class="memItemLeft" align="right" valign="top">const std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_mila_1_1_dnn_1_1_module.html#a37c244f23034b5a40c425db1165c9d88">stateToString</a> () const</td></tr>
<tr class="separator:a37c244f23034b5a40c425db1165c9d88 inherit pro_methods_class_mila_1_1_dnn_1_1_module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_attribs_class_mila_1_1_dnn_1_1_module"><td colspan="2" onclick="javascript:dynsection.toggleInherit('pro_attribs_class_mila_1_1_dnn_1_1_module')"><img src="closed.png" alt="-"/>&#160;Protected Attributes inherited from <a class="el" href="class_mila_1_1_dnn_1_1_module.html">Mila::Dnn::Module&lt; TInput, TInput, Compute::DeviceType::Cuda &gt;</a></td></tr>
<tr class="memitem:a9e6a323569c4f10e1370e436a8374c5c inherit pro_attribs_class_mila_1_1_dnn_1_1_module" id="r_a9e6a323569c4f10e1370e436a8374c5c"><td class="memItemLeft" align="right" valign="top">std::unordered_map&lt; std::string, std::shared_ptr&lt; <a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; TInput, <a class="el" href="class_mila_1_1_dnn_1_1_module.html#ac18c08e7167030eaba576b5238c94d74">MR</a> &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_mila_1_1_dnn_1_1_module.html#a9e6a323569c4f10e1370e436a8374c5c">parameter_map_</a></td></tr>
<tr class="separator:a9e6a323569c4f10e1370e436a8374c5c inherit pro_attribs_class_mila_1_1_dnn_1_1_module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a16c9b4c5f43c8c13633c34b93e2faf5c inherit pro_attribs_class_mila_1_1_dnn_1_1_module" id="r_a16c9b4c5f43c8c13633c34b93e2faf5c"><td class="memItemLeft" align="right" valign="top">std::unordered_map&lt; std::string, std::shared_ptr&lt; <a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; TInput, <a class="el" href="class_mila_1_1_dnn_1_1_module.html#ac18c08e7167030eaba576b5238c94d74">MR</a> &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_mila_1_1_dnn_1_1_module.html#a16c9b4c5f43c8c13633c34b93e2faf5c">state_map_</a></td></tr>
<tr class="separator:a16c9b4c5f43c8c13633c34b93e2faf5c inherit pro_attribs_class_mila_1_1_dnn_1_1_module"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><div class="compoundTemplParams">template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt;<br />
requires ValidTensorTypes&lt;TInput, TPrecision&gt;<br />
class Mila::Dnn::LayerNorm&lt; TInput, TPrecision, TDeviceType &gt;</div><p>Layer Normalization module. </p>
<p>Layer Normalization is a technique used to normalize the inputs across features for each data sample in a batch. It helps stabilize and accelerate deep neural network training by reducing internal covariate shift.</p>
<p>The operation can be expressed as: y = ((x - mean) / sqrt(variance + epsilon)) * weight + bias</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">TInput</td><td>The data type of the input tensor elements. </td></tr>
    <tr><td class="paramname">TPrecision</td><td>The data type used for computation and output (defaults to the input type). </td></tr>
    <tr><td class="paramname">TDeviceType</td><td>The device type where the computation will be performed (CPU or CUDA). </td></tr>
  </table>
  </dd>
</dl>
</div><h2 class="groupheader">Member Typedef Documentation</h2>
<a id="ab96302e6797e85e2654ff34392a5d8da" name="ab96302e6797e85e2654ff34392a5d8da"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab96302e6797e85e2654ff34392a5d8da">&#9670;&#160;</a></span>MR</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::MR = std::conditional_t&lt;TDeviceType == <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4a8b95dcff7397d0693c03e394af5552aa">Compute::DeviceType::Cuda</a>, <a class="el" href="class_mila_1_1_dnn_1_1_compute_1_1_device_memory_resource.html">Compute::DeviceMemoryResource</a>, <a class="el" href="class_mila_1_1_dnn_1_1_compute_1_1_host_memory_resource.html">Compute::HostMemoryResource</a>&gt;</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Memory resource type based on the device type. </p>
<p>This alias resolves to either <a class="el" href="class_mila_1_1_dnn_1_1_compute_1_1_device_memory_resource.html" title="A memory resource that allocates memory on a CUDA device.">DeviceMemoryResource</a> for CUDA devices or <a class="el" href="class_mila_1_1_dnn_1_1_compute_1_1_host_memory_resource.html" title="A memory resource for CPU memory allocation.">HostMemoryResource</a> for CPU devices. </p>

</div>
</div>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a8a1849fe66e55fb3c086661e590e64d6" name="a8a1849fe66e55fb3c086661e590e64d6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8a1849fe66e55fb3c086661e590e64d6">&#9670;&#160;</a></span>LayerNorm()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::LayerNorm </td>
          <td>(</td>
          <td class="paramtype">std::string</td>          <td class="paramname"><span class="paramname"><em>name</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; size_t &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>input_shape</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int64_t</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">-1</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>has_bias</em></span><span class="paramdefsep"> = </span><span class="paramdefval">true</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>is_training</em></span><span class="paramdefsep"> = </span><span class="paramdefval">false</span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Constructs a new <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html" title="Layer Normalization module.">LayerNorm</a> object. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>Name of the module for identification purposes. </td></tr>
    <tr><td class="paramname">input_shape</td><td>Shape of the input tensor, typically [batch_size, sequence_length, channels]. </td></tr>
    <tr><td class="paramname">axis</td><td>Axis for normalization. Default is -1 (last dimension). </td></tr>
    <tr><td class="paramname">has_bias</td><td>Whether the module should use a bias tensor. Default is true. </td></tr>
    <tr><td class="paramname">is_training</td><td>Whether the module is initially in training mode. Default is false. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="add5d808349e4a8ee60447a6739545db7" name="add5d808349e4a8ee60447a6739545db7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#add5d808349e4a8ee60447a6739545db7">&#9670;&#160;</a></span>createOperation()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::createOperation </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span><span class="mlabel private">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Creates the appropriate Layer Normalization operation based on device type. </p>
<p>This method initializes the operation_ member with the appropriate implementation of Layer Normalization for either CPU or CUDA, as determined by the TDeviceType template parameter. </p>

</div>
</div>
<a id="a020c4e56c216596acf217105ba81385f" name="a020c4e56c216596acf217105ba81385f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a020c4e56c216596acf217105ba81385f">&#9670;&#160;</a></span>forward()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::forward </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; TInput, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; TPrecision, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>output</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs the forward pass of the Layer Normalization operation. </p>
<p>Normalizes the input tensor across the specified axis, then scales and shifts the result using the weight and bias tensors.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to be normalized. </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor where the results will be stored. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ad7616bc29f922e321552d6f67f52ba40" name="ad7616bc29f922e321552d6f67f52ba40"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad7616bc29f922e321552d6f67f52ba40">&#9670;&#160;</a></span>getBias()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt; <a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; TInput, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a> &gt; &gt; <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::getBias </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the bias tensor used after normalization and scaling. </p>
<p>The bias tensor is added after normalization and scaling.</p>
<dl class="section return"><dt>Returns</dt><dd>std::shared_ptr&lt;Tensor&lt;TInput, MR&gt;&gt; Shared pointer to the bias tensor. </dd></dl>

</div>
</div>
<a id="a6a54464bb7b0596a3c7d33e0878a4bb7" name="a6a54464bb7b0596a3c7d33e0878a4bb7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6a54464bb7b0596a3c7d33e0878a4bb7">&#9670;&#160;</a></span>getWeight()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt; <a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt; TInput, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a> &gt; &gt; <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::getWeight </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the weight tensor used for scaling after normalization. </p>
<p>The weight tensor is applied as a scale factor to the normalized values.</p>
<dl class="section return"><dt>Returns</dt><dd>std::shared_ptr&lt;Tensor&lt;TInput, MR&gt;&gt; Shared pointer to the weight tensor. </dd></dl>

</div>
</div>
<a id="a5d5224eb2e7235b7dbb7a14513b11bde" name="a5d5224eb2e7235b7dbb7a14513b11bde"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5d5224eb2e7235b7dbb7a14513b11bde">&#9670;&#160;</a></span>initializeTensors()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::initializeTensors </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span><span class="mlabel private">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Initializes the tensors needed for the Layer Normalization operation. </p>
<p>Creates and initializes:</p><ul>
<li>weight tensor (initialized to ones)</li>
<li>bias tensor (initialized to zeros)</li>
<li>mean tensor (for storing means during forward pass)</li>
<li>reciprocal standard deviation tensor (for storing 1/std during forward pass) </li>
</ul>

</div>
</div>
<a id="a5ccd1ec0f1ef3f3d70a10d6fabcefa46" name="a5ccd1ec0f1ef3f3d70a10d6fabcefa46"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5ccd1ec0f1ef3f3d70a10d6fabcefa46">&#9670;&#160;</a></span>load()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::load </td>
          <td>(</td>
          <td class="paramtype">mz_zip_archive &amp;</td>          <td class="paramname"><span class="paramname"><em>zip</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span><span class="mlabel override">override</span><span class="mlabel virtual">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Loads the module state from a ZIP archive. </p>
<p>Deserializes the trainable parameters (weight, bias) from the provided archive.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">zip</td><td>The ZIP archive to load the module state from. </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="class_mila_1_1_dnn_1_1_module.html#a96834593a3df24bd0d6bc5bd90f9b7f0">Mila::Dnn::Module&lt; TInput, TInput, Compute::DeviceType::Cuda &gt;</a>.</p>

</div>
</div>
<a id="abf339ab2b66839e9b356e3e6c1586485" name="abf339ab2b66839e9b356e3e6c1586485"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abf339ab2b66839e9b356e3e6c1586485">&#9670;&#160;</a></span>parameterCount()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::parameterCount </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span><span class="mlabel override">override</span><span class="mlabel virtual">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the number of trainable parameters in this module. </p>
<p>Counts the total number of trainable parameters, which includes the weight tensor and, if present, the bias tensor.</p>
<dl class="section return"><dt>Returns</dt><dd>size_t The total number of parameters. </dd></dl>

<p>Implements <a class="el" href="class_mila_1_1_dnn_1_1_module.html#a362c75120160cf82ba6a105151d65f71">Mila::Dnn::Module&lt; TInput, TInput, Compute::DeviceType::Cuda &gt;</a>.</p>

</div>
</div>
<a id="a239f1ebf13fec1265d1d8d26e720b117" name="a239f1ebf13fec1265d1d8d26e720b117"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a239f1ebf13fec1265d1d8d26e720b117">&#9670;&#160;</a></span>save()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::save </td>
          <td>(</td>
          <td class="paramtype">mz_zip_archive &amp;</td>          <td class="paramname"><span class="paramname"><em>zip</em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span><span class="mlabel override">override</span><span class="mlabel virtual">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Saves the module state to a ZIP archive. </p>
<p>Serializes the trainable parameters (weight, bias) to the provided archive.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">zip</td><td>The ZIP archive to save the module state to. </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="class_mila_1_1_dnn_1_1_module.html#a45f9853768e6752788ce2a247ae6b76b">Mila::Dnn::Module&lt; TInput, TInput, Compute::DeviceType::Cuda &gt;</a>.</p>

</div>
</div>
<a id="a416e79a91da6c073e5aedeb4f0e62245" name="a416e79a91da6c073e5aedeb4f0e62245"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a416e79a91da6c073e5aedeb4f0e62245">&#9670;&#160;</a></span>toString()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::string <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::toString </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span><span class="mlabel override">override</span><span class="mlabel virtual">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Converts the module information to a human-readable string. </p>
<p>Includes detailed information about the module configuration, parameters, and state tensors.</p>
<dl class="section return"><dt>Returns</dt><dd>std::string A string representation of the module information. </dd></dl>

<p>Implements <a class="el" href="class_mila_1_1_dnn_1_1_module.html#aadc4faf769916b8996197a28f944fa8e">Mila::Dnn::Module&lt; TInput, TInput, Compute::DeviceType::Cuda &gt;</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a2860415cd495f3e02648407826eb20b1" name="a2860415cd495f3e02648407826eb20b1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2860415cd495f3e02648407826eb20b1">&#9670;&#160;</a></span>axis_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int64_t <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::axis_ { -1 }</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel private">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The axis along which to normalize. </p>
<p>Default is -1 for last dimension. </p>

</div>
</div>
<a id="a3286de3c5838fab290958f9b6d9637a7" name="a3286de3c5838fab290958f9b6d9637a7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3286de3c5838fab290958f9b6d9637a7">&#9670;&#160;</a></span>bias_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt;<a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt;float, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a>&gt; &gt; <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::bias_ { nullptr }</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel private">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The bias tensor added after normalization and scaling. </p>

</div>
</div>
<a id="aab31f7db365120be65e3b59ed51b367d" name="aab31f7db365120be65e3b59ed51b367d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aab31f7db365120be65e3b59ed51b367d">&#9670;&#160;</a></span>epsilon_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">float <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::epsilon_ { 1e-05f }</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel private">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Small constant added to variance for numerical stability. </p>

</div>
</div>
<a id="a236b4383254bdcd16b05149a8910c754" name="a236b4383254bdcd16b05149a8910c754"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a236b4383254bdcd16b05149a8910c754">&#9670;&#160;</a></span>has_bias_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::has_bias_ { true }</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel private">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Whether the module has a bias tensor. </p>
<p>Default is true. </p>

</div>
</div>
<a id="a58634c2c40b13fce94fc8529fff393b1" name="a58634c2c40b13fce94fc8529fff393b1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a58634c2c40b13fce94fc8529fff393b1">&#9670;&#160;</a></span>input_shape_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;size_t&gt; <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::input_shape_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel private">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The shape of the input tensor to be normalized. </p>

</div>
</div>
<a id="a44da92c83cc096adc40ef4af692a6c3b" name="a44da92c83cc096adc40ef4af692a6c3b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a44da92c83cc096adc40ef4af692a6c3b">&#9670;&#160;</a></span>mean_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt;<a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt;float, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a>&gt; &gt; <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::mean_ = { nullptr }</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel private">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The mean tensor used for normalization. </p>
<p>Stores the mean values computed during the forward pass. </p>

</div>
</div>
<a id="acbd9cf0245137b65979462d822127bbd" name="acbd9cf0245137b65979462d822127bbd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acbd9cf0245137b65979462d822127bbd">&#9670;&#160;</a></span>operation_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt;<a class="el" href="class_mila_1_1_dnn_1_1_compute_1_1_unary_operation.html">Dnn::Compute::UnaryOperation</a>&lt;TInput, TPrecision, TDeviceType&gt; &gt; <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::operation_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel private">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The underlying operation that implements Layer Normalization. </p>

</div>
</div>
<a id="a559ef3283a055071a380ed0b1a73f4b8" name="a559ef3283a055071a380ed0b1a73f4b8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a559ef3283a055071a380ed0b1a73f4b8">&#9670;&#160;</a></span>output_state_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;std::shared_ptr&lt;<a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt;float, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a>&gt; &gt; &gt; <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::output_state_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel private">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Cache of intermediate tensors needed for backward pass. </p>

</div>
</div>
<a id="a4ce62cd5ed888224cf0b51c26704fe13" name="a4ce62cd5ed888224cf0b51c26704fe13"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4ce62cd5ed888224cf0b51c26704fe13">&#9670;&#160;</a></span>parameters_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;std::shared_ptr&lt;<a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt;float, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a>&gt; &gt; &gt; <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::parameters_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel private">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The trainable parameters for this module (weight and bias). </p>

</div>
</div>
<a id="ac7abf91898a639f922f4a4f347852036" name="ac7abf91898a639f922f4a4f347852036"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac7abf91898a639f922f4a4f347852036">&#9670;&#160;</a></span>properties_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="struct_mila_1_1_dnn_1_1_compute_1_1_operation_attributes.html">OperationAttributes</a> <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::properties_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel private">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The operation attributes, including epsilon and axis information. </p>

</div>
</div>
<a id="a1b4fd5b5b7205098358da2761396f8ee" name="a1b4fd5b5b7205098358da2761396f8ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1b4fd5b5b7205098358da2761396f8ee">&#9670;&#160;</a></span>rstd_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt;<a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt;float, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a>&gt; &gt; <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::rstd_ { nullptr }</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel private">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The reciprocal standard deviation tensor. </p>
<p>Stores the reciprocal of the standard deviation values (1/sqrt(variance + epsilon)) computed during the forward pass. </p>

</div>
</div>
<a id="a59819b943b99c696796e8f5a744e9f81" name="a59819b943b99c696796e8f5a744e9f81"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a59819b943b99c696796e8f5a744e9f81">&#9670;&#160;</a></span>weight_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput, typename TPrecision = TInput, <a class="el" href="namespace_mila_1_1_dnn_1_1_compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a> TDeviceType = Compute::DeviceType::Cuda&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt;<a class="el" href="class_mila_1_1_dnn_1_1_tensor.html">Tensor</a>&lt;float, <a class="el" href="#ab96302e6797e85e2654ff34392a5d8da">MR</a>&gt; &gt; <a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">Mila::Dnn::LayerNorm</a>&lt; TInput, TPrecision, TDeviceType &gt;::weight_ { nullptr }</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel private">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The weight tensor for scaling after normalization. </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>Src/Dnn/Modules/<a class="el" href="_layer_norm_8ixx.html">LayerNorm.ixx</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespace_mila.html">Mila</a></li><li class="navelem"><a class="el" href="namespace_mila_1_1_dnn.html">Dnn</a></li><li class="navelem"><a class="el" href="class_mila_1_1_dnn_1_1_layer_norm.html">LayerNorm</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
