<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Mila: Mila::Dnn::Compute::CudaMultiHeadAttentionOp&lt; TInput, TPrecision &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Mila
   </div>
   <div id="projectbrief">Deep Neural Network Library</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">Mila::Dnn::Compute::CudaMultiHeadAttentionOp&lt; TInput, TPrecision &gt; Class Template Reference<span class="mlabels"><span class="mlabel">export</span></span><div class="ingroups">module <a class="el" href="module_Compute_8CudaMHAOp.html">Compute.CudaMHAOp</a></div></div></div>
</div><!--header-->
<div class="contents">

<p>CUDA implementation of the Multi-Head Attention operation for transformer models.  
 <a href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#details">More...</a></p>
<div class="dynheader">
Inheritance diagram for Mila::Dnn::Compute::CudaMultiHeadAttentionOp&lt; TInput, TPrecision &gt;:</div>
<div class="dyncontent">
<div class="center"><img src="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp__inherit__graph.png" border="0" usemap="#aMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp_3_01TInput_00_01TPrecision_01_4_inherit__map" alt="Inheritance graph"/></div>
<map name="aMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp_3_01TInput_00_01TPrecision_01_4_inherit__map" id="aMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp_3_01TInput_00_01TPrecision_01_4_inherit__map">
<area shape="rect" title="CUDA implementation of the Multi&#45;Head Attention operation for transformer models." alt="" coords="5,211,213,265"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html" title="Abstract base class for unary operations in the compute framework." alt="" coords="10,108,209,163"/>
<area shape="poly" title=" " alt="" coords="112,176,112,211,107,211,107,176"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1OperationBase.html" title="Base class for all compute operations." alt="" coords="10,5,209,60"/>
<area shape="poly" title=" " alt="" coords="112,74,112,108,107,108,107,74"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for Mila::Dnn::Compute::CudaMultiHeadAttentionOp&lt; TInput, TPrecision &gt;:</div>
<div class="dyncontent">
<div class="center"><img src="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp__coll__graph.png" border="0" usemap="#aMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp_3_01TInput_00_01TPrecision_01_4_coll__map" alt="Collaboration graph"/></div>
<map name="aMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp_3_01TInput_00_01TPrecision_01_4_coll__map" id="aMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp_3_01TInput_00_01TPrecision_01_4_coll__map">
<area shape="rect" title="CUDA implementation of the Multi&#45;Head Attention operation for transformer models." alt="" coords="5,211,213,265"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html" title="Abstract base class for unary operations in the compute framework." alt="" coords="10,108,209,163"/>
<area shape="poly" title=" " alt="" coords="112,176,112,211,107,211,107,176"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1OperationBase.html" title="Base class for all compute operations." alt="" coords="10,5,209,60"/>
<area shape="poly" title=" " alt="" coords="112,74,112,108,107,108,107,74"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-types" name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:a061d5fba1405a59bed722f6721aedb39" id="r_a061d5fba1405a59bed722f6721aedb39"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> = typename <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaDevice.html#a0fc51073f8405e15fe0d1e9f3bce3570">CudaDevice::MR</a></td></tr>
<tr class="separator:a061d5fba1405a59bed722f6721aedb39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_types_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation"><td colspan="2" onclick="javascript:toggleInherit('pub_types_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation')"><img src="closed.png" alt="-"/>&#160;Public Types inherited from <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html">Mila::Dnn::Compute::UnaryOperation&lt; TInput, TPrecision, TDeviceType &gt;</a></td></tr>
<tr class="memitem:aae5c71504c495ed63554e0d9702fd086 inherit pub_types_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation" id="r_aae5c71504c495ed63554e0d9702fd086"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html#aae5c71504c495ed63554e0d9702fd086">MR</a> = std::conditional_t&lt; TDeviceType==<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4a8b95dcff7397d0693c03e394af5552aa">DeviceType::Cuda</a>, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceMemoryResource.html">DeviceMemoryResource</a>, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1HostMemoryResource.html">HostMemoryResource</a> &gt;</td></tr>
<tr class="separator:aae5c71504c495ed63554e0d9702fd086 inherit pub_types_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a2590be0e7617e0a225020dc52035538e" id="r_a2590be0e7617e0a225020dc52035538e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a2590be0e7617e0a225020dc52035538e">CudaMultiHeadAttentionOp</a> ()</td></tr>
<tr class="memdesc:a2590be0e7617e0a225020dc52035538e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs a new CUDA Multi-Head Attention operation with the default device context.  <br /></td></tr>
<tr class="separator:a2590be0e7617e0a225020dc52035538e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8398283cf3a600c65668143d34df0dea" id="r_a8398283cf3a600c65668143d34df0dea"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a8398283cf3a600c65668143d34df0dea">CudaMultiHeadAttentionOp</a> (std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html">DeviceContext</a> &gt; context)</td></tr>
<tr class="memdesc:a8398283cf3a600c65668143d34df0dea"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs a new CUDA Multi-Head Attention operation with a specific device context.  <br /></td></tr>
<tr class="separator:a8398283cf3a600c65668143d34df0dea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9352ac12fe53fcb34395fadb2d9050c2" id="r_a9352ac12fe53fcb34395fadb2d9050c2"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a9352ac12fe53fcb34395fadb2d9050c2">backward</a> (const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &amp;input, const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TPrecision, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &amp;output, const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TPrecision, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &amp;output_gradient, const std::vector&lt; std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &gt; &gt; &amp;parameters, std::vector&lt; std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &gt; &gt; &amp;parameter_gradients, <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &amp;input_gradient, const <a class="el" href="structMila_1_1Dnn_1_1Compute_1_1OperationAttributes.html">OperationAttributes</a> &amp;properties, const std::vector&lt; std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TPrecision, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &gt; &gt; &amp;output_cache) const</td></tr>
<tr class="memdesc:a9352ac12fe53fcb34395fadb2d9050c2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs the backward pass of the Multi-Head Attention operation.  <br /></td></tr>
<tr class="separator:a9352ac12fe53fcb34395fadb2d9050c2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afdefbe424df62af4c4c271813664cee0" id="r_afdefbe424df62af4c4c271813664cee0"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#afdefbe424df62af4c4c271813664cee0">forward</a> (const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &amp;input, const std::vector&lt; std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &gt; &gt; &amp;parameters, const <a class="el" href="structMila_1_1Dnn_1_1Compute_1_1OperationAttributes.html">OperationAttributes</a> &amp;properties, <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TPrecision, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &amp;output, std::vector&lt; std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TPrecision, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &gt; &gt; &amp;output_cache) const override</td></tr>
<tr class="memdesc:afdefbe424df62af4c4c271813664cee0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs the forward pass of the Multi-Head Attention operation on CUDA.  <br /></td></tr>
<tr class="separator:afdefbe424df62af4c4c271813664cee0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1da95cd9898f8450d0d79804dfafc9ea" id="r_a1da95cd9898f8450d0d79804dfafc9ea"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a1da95cd9898f8450d0d79804dfafc9ea">getName</a> () const override</td></tr>
<tr class="memdesc:a1da95cd9898f8450d0d79804dfafc9ea"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the name of this operation.  <br /></td></tr>
<tr class="separator:a1da95cd9898f8450d0d79804dfafc9ea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html">Mila::Dnn::Compute::UnaryOperation&lt; TInput, TPrecision, TDeviceType &gt;</a></td></tr>
<tr class="memitem:a0137d6b6b585e56e32dfa9203d475f04 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation" id="r_a0137d6b6b585e56e32dfa9203d475f04"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html#a0137d6b6b585e56e32dfa9203d475f04">UnaryOperation</a> (<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11">OperationType</a> operation_type)</td></tr>
<tr class="memdesc:a0137d6b6b585e56e32dfa9203d475f04 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs a <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html" title="Abstract base class for unary operations in the compute framework.">UnaryOperation</a> with the specified operation type.  <br /></td></tr>
<tr class="separator:a0137d6b6b585e56e32dfa9203d475f04 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a53e40414f0101463ce41a4c23fe844ac inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation" id="r_a53e40414f0101463ce41a4c23fe844ac"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html#a53e40414f0101463ce41a4c23fe844ac">UnaryOperation</a> (<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11">OperationType</a> operation_type, std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html">DeviceContext</a> &gt; context)</td></tr>
<tr class="memdesc:a53e40414f0101463ce41a4c23fe844ac inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs a <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html" title="Abstract base class for unary operations in the compute framework.">UnaryOperation</a> with the specified operation type and device context.  <br /></td></tr>
<tr class="separator:a53e40414f0101463ce41a4c23fe844ac inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6735f4a3fa46aedb14718f1352fc1c5d inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation" id="r_a6735f4a3fa46aedb14718f1352fc1c5d"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html#a6735f4a3fa46aedb14718f1352fc1c5d">~UnaryOperation</a> ()=default</td></tr>
<tr class="memdesc:a6735f4a3fa46aedb14718f1352fc1c5d inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation"><td class="mdescLeft">&#160;</td><td class="mdescRight">Virtual destructor for proper cleanup of derived classes.  <br /></td></tr>
<tr class="separator:a6735f4a3fa46aedb14718f1352fc1c5d inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe285e2b5304fd831e9605f8245009e7 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation" id="r_abe285e2b5304fd831e9605f8245009e7"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html#abe285e2b5304fd831e9605f8245009e7">backward</a> (const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html#aae5c71504c495ed63554e0d9702fd086">MR</a> &gt; &amp;grad, const std::vector&lt; std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TPrecision, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html#aae5c71504c495ed63554e0d9702fd086">MR</a> &gt; &gt; &gt; &amp;parameters, std::vector&lt; std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TPrecision, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html#aae5c71504c495ed63554e0d9702fd086">MR</a> &gt; &gt; &gt; &amp;output_grads) const</td></tr>
<tr class="memdesc:abe285e2b5304fd831e9605f8245009e7 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation"><td class="mdescLeft">&#160;</td><td class="mdescRight">Executes the backward pass of a unary operation.  <br /></td></tr>
<tr class="separator:abe285e2b5304fd831e9605f8245009e7 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a183b29a34bed8278d9b134f0b61e91bb inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation" id="r_a183b29a34bed8278d9b134f0b61e91bb"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html#a183b29a34bed8278d9b134f0b61e91bb">forward</a> (const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html#aae5c71504c495ed63554e0d9702fd086">MR</a> &gt; &amp;input, const std::vector&lt; std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TPrecision, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html#aae5c71504c495ed63554e0d9702fd086">MR</a> &gt; &gt; &gt; &amp;parameters, const <a class="el" href="structMila_1_1Dnn_1_1Compute_1_1OperationAttributes.html">OperationAttributes</a> &amp;properties, <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TPrecision, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html#aae5c71504c495ed63554e0d9702fd086">MR</a> &gt; &amp;output, std::vector&lt; std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TPrecision, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html#aae5c71504c495ed63554e0d9702fd086">MR</a> &gt; &gt; &gt; &amp;output_state) const =0</td></tr>
<tr class="memdesc:a183b29a34bed8278d9b134f0b61e91bb inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation"><td class="mdescLeft">&#160;</td><td class="mdescRight">Executes the forward pass of a unary operation.  <br /></td></tr>
<tr class="separator:a183b29a34bed8278d9b134f0b61e91bb inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1UnaryOperation"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classMila_1_1Dnn_1_1Compute_1_1OperationBase"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classMila_1_1Dnn_1_1Compute_1_1OperationBase')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1OperationBase.html">Mila::Dnn::Compute::OperationBase&lt; TInput, TPrecision, TDeviceType &gt;</a></td></tr>
<tr class="memitem:a95029cd50c5813c71f0249b1e9314df6 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1OperationBase" id="r_a95029cd50c5813c71f0249b1e9314df6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1OperationBase.html#a95029cd50c5813c71f0249b1e9314df6">OperationBase</a> (<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11">OperationType</a> operation_type, std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html">DeviceContext</a> &gt; context)</td></tr>
<tr class="memdesc:a95029cd50c5813c71f0249b1e9314df6 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1OperationBase"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs an <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1OperationBase.html" title="Base class for all compute operations.">OperationBase</a> object with a specific device context.  <br /></td></tr>
<tr class="separator:a95029cd50c5813c71f0249b1e9314df6 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1OperationBase"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af48032a442a24db3eaddb8045b99cd9b inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1OperationBase" id="r_af48032a442a24db3eaddb8045b99cd9b"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1OperationBase.html#af48032a442a24db3eaddb8045b99cd9b">~OperationBase</a> ()=default</td></tr>
<tr class="memdesc:af48032a442a24db3eaddb8045b99cd9b inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1OperationBase"><td class="mdescLeft">&#160;</td><td class="mdescRight">Virtual destructor for the <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1OperationBase.html" title="Base class for all compute operations.">OperationBase</a> class.  <br /></td></tr>
<tr class="separator:af48032a442a24db3eaddb8045b99cd9b inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1OperationBase"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afc149535c8b0ca6b623e28248a523204 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1OperationBase" id="r_afc149535c8b0ca6b623e28248a523204"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html">DeviceContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1OperationBase.html#afc149535c8b0ca6b623e28248a523204">getDeviceContext</a> () const</td></tr>
<tr class="memdesc:afc149535c8b0ca6b623e28248a523204 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1OperationBase"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the device context.  <br /></td></tr>
<tr class="separator:afc149535c8b0ca6b623e28248a523204 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1OperationBase"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a73d50f0b74db81d1d98a68f3199f4c40 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1OperationBase" id="r_a73d50f0b74db81d1d98a68f3199f4c40"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1OperationBase.html#a73d50f0b74db81d1d98a68f3199f4c40">getDeviceType</a> () const</td></tr>
<tr class="memdesc:a73d50f0b74db81d1d98a68f3199f4c40 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1OperationBase"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the device type.  <br /></td></tr>
<tr class="separator:a73d50f0b74db81d1d98a68f3199f4c40 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1OperationBase"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea2c92561481c128a3ce3e13e5a6a8f4 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1OperationBase" id="r_aea2c92561481c128a3ce3e13e5a6a8f4"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#afe9b0f279fe9c233b4b5d795cb0ade11">OperationType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1OperationBase.html#aea2c92561481c128a3ce3e13e5a6a8f4">getOperationType</a> () const</td></tr>
<tr class="memdesc:aea2c92561481c128a3ce3e13e5a6a8f4 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1OperationBase"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the operation type.  <br /></td></tr>
<tr class="separator:aea2c92561481c128a3ce3e13e5a6a8f4 inherit pub_methods_classMila_1_1Dnn_1_1Compute_1_1OperationBase"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><div class="compoundTemplParams">template&lt;typename TInput, typename TPrecision = TInput&gt;<br />
class Mila::Dnn::Compute::CudaMultiHeadAttentionOp&lt; TInput, TPrecision &gt;</div><p>CUDA implementation of the Multi-Head Attention operation for transformer models. </p>
<p>This class provides a CUDA-based implementation of the Multi-Head Attention operation, which is a key component of transformer architectures. The operation allows the model to jointly attend to information from different representation subspaces at different positions.</p>
<p>Multi-Head Attention consists of several attention mechanisms operating in parallel:</p><ol type="1">
<li>Linear projections of the input into query, key, and value vectors</li>
<li>Scaled dot-product attention computation between queries and keys</li>
<li>Applying attention weights to values</li>
<li>Concatenation of attention outputs from different heads</li>
</ol>
<p>The implementation is optimized for NVIDIA GPUs using CUDA for high-performance computation.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">TInput</td><td>The data type of the input tensor elements. </td></tr>
    <tr><td class="paramname">TPrecision</td><td>The data type of the output tensor elements (defaults to the input type). </td></tr>
  </table>
  </dd>
</dl>
</div><h2 class="groupheader">Member Typedef Documentation</h2>
<a id="a061d5fba1405a59bed722f6721aedb39" name="a061d5fba1405a59bed722f6721aedb39"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a061d5fba1405a59bed722f6721aedb39">&#9670;&#160;</a></span>MR</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput , typename TPrecision  = TInput&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html">Mila::Dnn::Compute::CudaMultiHeadAttentionOp</a>&lt; TInput, TPrecision &gt;::MR =  typename <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaDevice.html#a0fc51073f8405e15fe0d1e9f3bce3570">CudaDevice::MR</a></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a2590be0e7617e0a225020dc52035538e" name="a2590be0e7617e0a225020dc52035538e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2590be0e7617e0a225020dc52035538e">&#9670;&#160;</a></span>CudaMultiHeadAttentionOp() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput , typename TPrecision  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html">Mila::Dnn::Compute::CudaMultiHeadAttentionOp</a>&lt; TInput, TPrecision &gt;<a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html">::CudaMultiHeadAttentionOp</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Constructs a new CUDA Multi-Head Attention operation with the default device context. </p>
<p>Initializes the operation with a CUDA device context (defaults to CUDA:0). </p>

</div>
</div>
<a id="a8398283cf3a600c65668143d34df0dea" name="a8398283cf3a600c65668143d34df0dea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8398283cf3a600c65668143d34df0dea">&#9670;&#160;</a></span>CudaMultiHeadAttentionOp() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput , typename TPrecision  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html">Mila::Dnn::Compute::CudaMultiHeadAttentionOp</a>&lt; TInput, TPrecision &gt;<a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html">::CudaMultiHeadAttentionOp</a> </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html">DeviceContext</a> &gt;&#160;</td>
          <td class="paramname"><em>context</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Constructs a new CUDA Multi-Head Attention operation with a specific device context. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">context</td><td>The device context to use for this operation. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::runtime_error</td><td>If the context is not for a CUDA device. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a9352ac12fe53fcb34395fadb2d9050c2" name="a9352ac12fe53fcb34395fadb2d9050c2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9352ac12fe53fcb34395fadb2d9050c2">&#9670;&#160;</a></span>backward()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput , typename TPrecision  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html">Mila::Dnn::Compute::CudaMultiHeadAttentionOp</a>&lt; TInput, TPrecision &gt;::backward </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TPrecision, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TPrecision, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>output_gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &gt; &gt; &amp;&#160;</td>
          <td class="paramname"><em>parameters</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &gt; &gt; &amp;&#160;</td>
          <td class="paramname"><em>parameter_gradients</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>input_gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structMila_1_1Dnn_1_1Compute_1_1OperationAttributes.html">OperationAttributes</a> &amp;&#160;</td>
          <td class="paramname"><em>properties</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TPrecision, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &gt; &gt; &amp;&#160;</td>
          <td class="paramname"><em>output_cache</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs the backward pass of the Multi-Head Attention operation. </p>
<p>Computes gradients with respect to inputs, weights, and biases.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>Input tensor from the forward pass. </td></tr>
    <tr><td class="paramname">output</td><td>Output tensor from the forward pass. </td></tr>
    <tr><td class="paramname">output_gradient</td><td>Gradient of the loss with respect to the output. </td></tr>
    <tr><td class="paramname">parameters</td><td>Parameters tensor from forward pass [weight, bias]. </td></tr>
    <tr><td class="paramname">parameter_gradients</td><td>Gradients for parameters [d_weight, d_bias]. </td></tr>
    <tr><td class="paramname">input_gradient</td><td>Gradient of the loss with respect to the input. </td></tr>
    <tr><td class="paramname">properties</td><td>Additional attributes for the operation. </td></tr>
    <tr><td class="paramname">output_cache</td><td>Cache tensors from forward pass (attention scores and weights). </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="afdefbe424df62af4c4c271813664cee0" name="afdefbe424df62af4c4c271813664cee0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afdefbe424df62af4c4c271813664cee0">&#9670;&#160;</a></span>forward()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput , typename TPrecision  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html">Mila::Dnn::Compute::CudaMultiHeadAttentionOp</a>&lt; TInput, TPrecision &gt;::forward </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &gt; &gt; &amp;&#160;</td>
          <td class="paramname"><em>parameters</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structMila_1_1Dnn_1_1Compute_1_1OperationAttributes.html">OperationAttributes</a> &amp;&#160;</td>
          <td class="paramname"><em>properties</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TPrecision, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TPrecision, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html#a061d5fba1405a59bed722f6721aedb39">MR</a> &gt; &gt; &gt; &amp;&#160;</td>
          <td class="paramname"><em>output_cache</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">override</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs the forward pass of the Multi-Head Attention operation on CUDA. </p>
<p>Computes attention scores, applies softmax to get attention weights, and uses these weights to compute a weighted sum of value vectors. This process is performed in parallel for multiple attention heads, then outputs are concatenated and projected.</p>
<p>The computation is performed on the GPU using CUDA kernels for optimal performance.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>Input tensor of shape [B, T, C] containing the input sequence, where B is batch size, T is sequence length, and C is the input feature dimension. </td></tr>
    <tr><td class="paramname">parameters</td><td>Vector of parameter tensors [weight, bias], where weight contains the query, key, value projections and output projection, and bias contains the corresponding biases. </td></tr>
    <tr><td class="paramname">properties</td><td>Additional attributes for the operation, such as number of attention heads. </td></tr>
    <tr><td class="paramname">output</td><td>Output tensor of shape [B, T, OC] containing the attention output, where OC is the output feature dimension. </td></tr>
    <tr><td class="paramname">output_cache</td><td>Cache for intermediate results like attention scores and weights for potential use in backward pass or visualization. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a1da95cd9898f8450d0d79804dfafc9ea" name="a1da95cd9898f8450d0d79804dfafc9ea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1da95cd9898f8450d0d79804dfafc9ea">&#9670;&#160;</a></span>getName()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename TInput , typename TPrecision  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::string <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html">Mila::Dnn::Compute::CudaMultiHeadAttentionOp</a>&lt; TInput, TPrecision &gt;::getName </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the name of this operation. </p>
<dl class="section return"><dt>Returns</dt><dd>std::string The name of the operation ("Cuda::MultiHeadAttentionOp"). </dd></dl>

<p>Implements <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1OperationBase.html#a9c4531f4e686ee70e776f8900542dedd">Mila::Dnn::Compute::OperationBase&lt; TInput, TPrecision, TDeviceType &gt;</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>Src/Dnn/Compute/Operations/Cuda/<a class="el" href="CudaMultiHeadAttentionOp_8ixx.html">CudaMultiHeadAttentionOp.ixx</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespaceMila.html">Mila</a></li><li class="navelem"><a class="el" href="namespaceMila_1_1Dnn.html">Dnn</a></li><li class="navelem"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html">Compute</a></li><li class="navelem"><a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMultiHeadAttentionOp.html">CudaMultiHeadAttentionOp</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
