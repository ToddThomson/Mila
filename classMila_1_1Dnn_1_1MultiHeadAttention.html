<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Mila: Mila::Dnn::MultiHeadAttention&lt; TDeviceType, TInput, TOutput &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Mila
   </div>
   <div id="projectbrief">Deep Neural Network Library</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classMila_1_1Dnn_1_1MultiHeadAttention.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pri-methods">Private Member Functions</a> &#124;
<a href="#pri-attribs">Private Attributes</a> &#124;
<a href="classMila_1_1Dnn_1_1MultiHeadAttention-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">Mila::Dnn::MultiHeadAttention&lt; TDeviceType, TInput, TOutput &gt; Class Template Reference<span class="mlabels"><span class="mlabel">export</span></span><div class="ingroups">module <a class="el" href="module_Dnn_8Modules_8Attention.html">Dnn.Modules.Attention</a></div></div></div>
</div><!--header-->
<div class="contents">

<p>Multi-head attention module for transformer architectures.  
 <a href="classMila_1_1Dnn_1_1MultiHeadAttention.html#details">More...</a></p>
<div class="dynheader">
Inheritance diagram for Mila::Dnn::MultiHeadAttention&lt; TDeviceType, TInput, TOutput &gt;:</div>
<div class="dyncontent">
<div class="center"><img src="classMila_1_1Dnn_1_1MultiHeadAttention__inherit__graph.png" border="0" usemap="#aMila_1_1Dnn_1_1MultiHeadAttention_3_01TDeviceType_00_01TInput_00_01TOutput_01_4_inherit__map" alt="Inheritance graph"/></div>
<map name="aMila_1_1Dnn_1_1MultiHeadAttention_3_01TDeviceType_00_01TInput_00_01TOutput_01_4_inherit__map" id="aMila_1_1Dnn_1_1MultiHeadAttention_3_01TDeviceType_00_01TInput_00_01TOutput_01_4_inherit__map">
<area shape="rect" title="Multi&#45;head attention module for transformer architectures." alt="" coords="5,108,249,148"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Module.html" title="Abstract base class for all modules in the Mila DNN framework." alt="" coords="46,5,209,60"/>
<area shape="poly" title=" " alt="" coords="130,74,130,108,125,108,125,74"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for Mila::Dnn::MultiHeadAttention&lt; TDeviceType, TInput, TOutput &gt;:</div>
<div class="dyncontent">
<div class="center"><img src="classMila_1_1Dnn_1_1MultiHeadAttention__coll__graph.png" border="0" usemap="#aMila_1_1Dnn_1_1MultiHeadAttention_3_01TDeviceType_00_01TInput_00_01TOutput_01_4_coll__map" alt="Collaboration graph"/></div>
<map name="aMila_1_1Dnn_1_1MultiHeadAttention_3_01TDeviceType_00_01TInput_00_01TOutput_01_4_coll__map" id="aMila_1_1Dnn_1_1MultiHeadAttention_3_01TDeviceType_00_01TInput_00_01TOutput_01_4_coll__map">
<area shape="rect" title="Multi&#45;head attention module for transformer architectures." alt="" coords="656,85,900,125"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Module.html" title="Abstract base class for all modules in the Mila DNN framework." alt="" coords="340,5,503,60"/>
<area shape="poly" title=" " alt="" coords="517,49,678,82,677,87,516,54"/>
<area shape="rect" href="classMila_1_1Dnn_1_1ComponentConfig.html" title="Base configuration class for all neural network components." alt="" coords="5,57,213,83"/>
<area shape="poly" title=" " alt="" coords="227,53,340,40,340,45,228,59"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html" title="Configuration class for MultiHeadAttention module." alt="" coords="312,85,531,125"/>
<area shape="poly" title=" " alt="" coords="227,80,312,90,311,95,227,86"/>
<area shape="poly" title=" " alt="" coords="544,102,656,102,656,107,544,107"/>
<area shape="rect" href="structMila_1_1Dnn_1_1Compute_1_1OperationAttributes.html" title="Common attributes for neural network operations." alt="" coords="342,149,501,189"/>
<area shape="poly" title=" " alt="" coords="514,149,665,122,666,127,515,155"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-types" name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:a9fea4bf3612d224d2b54da7a1cb78cb8" id="r_a9fea4bf3612d224d2b54da7a1cb78cb8"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a9fea4bf3612d224d2b54da7a1cb78cb8">ModuleBase</a> = <a class="el" href="classMila_1_1Dnn_1_1Module.html">Module</a>&lt; TDeviceType, TInput, TOutput &gt;</td></tr>
<tr class="memdesc:a9fea4bf3612d224d2b54da7a1cb78cb8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Alias for base module type.  <br /></td></tr>
<tr class="separator:a9fea4bf3612d224d2b54da7a1cb78cb8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a44c10df27cce6d2a46dbb81e455d5d4a" id="r_a44c10df27cce6d2a46dbb81e455d5d4a"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> = std::conditional_t&lt; TDeviceType==DeviceType::Cuda, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMemoryResource.html">CudaMemoryResource</a>, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuMemoryResource.html">CpuMemoryResource</a> &gt;</td></tr>
<tr class="memdesc:a44c10df27cce6d2a46dbb81e455d5d4a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Memory resource type used for tensors, selected based on device type.  <br /></td></tr>
<tr class="separator:a44c10df27cce6d2a46dbb81e455d5d4a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_types_classMila_1_1Dnn_1_1Module"><td colspan="2" onclick="javascript:toggleInherit('pub_types_classMila_1_1Dnn_1_1Module')"><img src="closed.png" alt="-"/>&#160;Public Types inherited from <a class="el" href="classMila_1_1Dnn_1_1Module.html">Mila::Dnn::Module&lt; TDeviceType, TInput, TOutput &gt;</a></td></tr>
<tr class="memitem:a30d5b0cc3f9fa994c166180483b2ea51 inherit pub_types_classMila_1_1Dnn_1_1Module" id="r_a30d5b0cc3f9fa994c166180483b2ea51"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Module.html#a30d5b0cc3f9fa994c166180483b2ea51">MR</a> = std::conditional_t&lt; TDeviceType==DeviceType::Cuda, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMemoryResource.html">CudaMemoryResource</a>, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuMemoryResource.html">CpuMemoryResource</a> &gt;</td></tr>
<tr class="separator:a30d5b0cc3f9fa994c166180483b2ea51 inherit pub_types_classMila_1_1Dnn_1_1Module"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a205a226fb09b4c4b083e60e1d4b4311a" id="r_a205a226fb09b4c4b083e60e1d4b4311a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a205a226fb09b4c4b083e60e1d4b4311a">MultiHeadAttention</a> (const std::string &amp;device_name, const <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html">MultiHeadAttentionConfig</a> &amp;config)</td></tr>
<tr class="memdesc:a205a226fb09b4c4b083e60e1d4b4311a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs a new <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html" title="Multi-head attention module for transformer architectures.">MultiHeadAttention</a> module with a device name.  <br /></td></tr>
<tr class="separator:a205a226fb09b4c4b083e60e1d4b4311a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2184c5fdc3dffb5dbbe2ba3f00ed48a9" id="r_a2184c5fdc3dffb5dbbe2ba3f00ed48a9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a2184c5fdc3dffb5dbbe2ba3f00ed48a9">MultiHeadAttention</a> (std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html">DeviceContext</a> &gt; device_context, const <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html">MultiHeadAttentionConfig</a> &amp;config)</td></tr>
<tr class="memdesc:a2184c5fdc3dffb5dbbe2ba3f00ed48a9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs a new <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html" title="Multi-head attention module for transformer architectures.">MultiHeadAttention</a> module with a provided device context.  <br /></td></tr>
<tr class="separator:a2184c5fdc3dffb5dbbe2ba3f00ed48a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe9c2244b3ec8fd5ff188d26da34c8e9" id="r_abe9c2244b3ec8fd5ff188d26da34c8e9"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#abe9c2244b3ec8fd5ff188d26da34c8e9">backward</a> (const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &amp;input, const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TOutput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &amp;output_grad, <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &amp;input_grad)</td></tr>
<tr class="memdesc:abe9c2244b3ec8fd5ff188d26da34c8e9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs the backward pass of the <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html" title="Multi-head attention module for transformer architectures.">MultiHeadAttention</a> operation.  <br /></td></tr>
<tr class="separator:abe9c2244b3ec8fd5ff188d26da34c8e9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a825e50e3cc60ac78310129b056904810" id="r_a825e50e3cc60ac78310129b056904810"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a825e50e3cc60ac78310129b056904810">forward</a> (const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &amp;input, const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &amp;mask, <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TOutput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &amp;output)</td></tr>
<tr class="memdesc:a825e50e3cc60ac78310129b056904810"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs the forward pass with an explicit attention mask.  <br /></td></tr>
<tr class="separator:a825e50e3cc60ac78310129b056904810"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa68240bd5a909f19afe06e497f50a9aa" id="r_aa68240bd5a909f19afe06e497f50a9aa"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#aa68240bd5a909f19afe06e497f50a9aa">forward</a> (const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &amp;input, <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TOutput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &amp;output)</td></tr>
<tr class="memdesc:aa68240bd5a909f19afe06e497f50a9aa"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs the forward pass of the <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html" title="Multi-head attention module for transformer architectures.">MultiHeadAttention</a> operation.  <br /></td></tr>
<tr class="separator:aa68240bd5a909f19afe06e497f50a9aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a73b8961371a4f0c0881b08aa0a5de198" id="r_a73b8961371a4f0c0881b08aa0a5de198"><td class="memItemLeft" align="right" valign="top">float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a73b8961371a4f0c0881b08aa0a5de198">getDropout</a> () const</td></tr>
<tr class="memdesc:a73b8961371a4f0c0881b08aa0a5de198"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the dropout rate.  <br /></td></tr>
<tr class="separator:a73b8961371a4f0c0881b08aa0a5de198"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa3b867c5cfaeeef2936fb4ca46ff61ff" id="r_aa3b867c5cfaeeef2936fb4ca46ff61ff"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#aa3b867c5cfaeeef2936fb4ca46ff61ff">getEmbeddingDim</a> () const</td></tr>
<tr class="memdesc:aa3b867c5cfaeeef2936fb4ca46ff61ff"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the embedding dimension.  <br /></td></tr>
<tr class="separator:aa3b867c5cfaeeef2936fb4ca46ff61ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a21b2cafa427d56474aea9bf5deffa2ed" id="r_a21b2cafa427d56474aea9bf5deffa2ed"><td class="memItemLeft" align="right" valign="top">const std::vector&lt; size_t &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a21b2cafa427d56474aea9bf5deffa2ed">getInputShape</a> () const</td></tr>
<tr class="memdesc:a21b2cafa427d56474aea9bf5deffa2ed"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the input shape.  <br /></td></tr>
<tr class="separator:a21b2cafa427d56474aea9bf5deffa2ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a27412f9f4f9e60fa2c6a569c59167f" id="r_a8a27412f9f4f9e60fa2c6a569c59167f"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a8a27412f9f4f9e60fa2c6a569c59167f">getNumHeads</a> () const</td></tr>
<tr class="memdesc:a8a27412f9f4f9e60fa2c6a569c59167f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the number of attention heads.  <br /></td></tr>
<tr class="separator:a8a27412f9f4f9e60fa2c6a569c59167f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab4c16e1be1d56f6eebb1b969e5bbc6ca" id="r_ab4c16e1be1d56f6eebb1b969e5bbc6ca"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#ab4c16e1be1d56f6eebb1b969e5bbc6ca">load</a> (<a class="el" href="classMila_1_1Dnn_1_1Serialization_1_1ModelArchive.html">ModelArchive</a> &amp;archive) override</td></tr>
<tr class="memdesc:ab4c16e1be1d56f6eebb1b969e5bbc6ca"><td class="mdescLeft">&#160;</td><td class="mdescRight">Loads the module state from a ZIP archive.  <br /></td></tr>
<tr class="separator:ab4c16e1be1d56f6eebb1b969e5bbc6ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d7f1415090f6ce3f84a492d72a93504" id="r_a7d7f1415090f6ce3f84a492d72a93504"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a7d7f1415090f6ce3f84a492d72a93504">parameterCount</a> () const override</td></tr>
<tr class="memdesc:a7d7f1415090f6ce3f84a492d72a93504"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the number of trainable parameters in this module.  <br /></td></tr>
<tr class="separator:a7d7f1415090f6ce3f84a492d72a93504"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aae30a0f8075da1f957316a0a0c0643d7" id="r_aae30a0f8075da1f957316a0a0c0643d7"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#aae30a0f8075da1f957316a0a0c0643d7">save</a> (<a class="el" href="classMila_1_1Dnn_1_1Serialization_1_1ModelArchive.html">ModelArchive</a> &amp;zip) const override</td></tr>
<tr class="memdesc:aae30a0f8075da1f957316a0a0c0643d7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Saves the module state to a ZIP archive.  <br /></td></tr>
<tr class="separator:aae30a0f8075da1f957316a0a0c0643d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a91762121adfdf91a746f16619b26fb98" id="r_a91762121adfdf91a746f16619b26fb98"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a91762121adfdf91a746f16619b26fb98">toString</a> () const override</td></tr>
<tr class="memdesc:a91762121adfdf91a746f16619b26fb98"><td class="mdescLeft">&#160;</td><td class="mdescRight">Generates a string representation of this module's configuration.  <br /></td></tr>
<tr class="separator:a91762121adfdf91a746f16619b26fb98"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac0b829536527ba668c4180f67aa0f874" id="r_ac0b829536527ba668c4180f67aa0f874"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#ac0b829536527ba668c4180f67aa0f874">useCausalMask</a> () const</td></tr>
<tr class="memdesc:ac0b829536527ba668c4180f67aa0f874"><td class="mdescLeft">&#160;</td><td class="mdescRight">Checks if causal masking is enabled.  <br /></td></tr>
<tr class="separator:ac0b829536527ba668c4180f67aa0f874"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classMila_1_1Dnn_1_1Module"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classMila_1_1Dnn_1_1Module')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classMila_1_1Dnn_1_1Module.html">Mila::Dnn::Module&lt; TDeviceType, TInput, TOutput &gt;</a></td></tr>
<tr class="memitem:a9c68c425ffc1643d090c881f935b1d81 inherit pub_methods_classMila_1_1Dnn_1_1Module" id="r_a9c68c425ffc1643d090c881f935b1d81"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Module.html#a9c68c425ffc1643d090c881f935b1d81">Module</a> (const std::string &amp;device_name, const <a class="el" href="classMila_1_1Dnn_1_1ComponentConfig.html">ComponentConfig</a> &amp;config)</td></tr>
<tr class="memdesc:a9c68c425ffc1643d090c881f935b1d81 inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor with device name.  <br /></td></tr>
<tr class="separator:a9c68c425ffc1643d090c881f935b1d81 inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c3a64e5bc2b0d9464d341a86bf52a69 inherit pub_methods_classMila_1_1Dnn_1_1Module" id="r_a2c3a64e5bc2b0d9464d341a86bf52a69"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Module.html#a2c3a64e5bc2b0d9464d341a86bf52a69">Module</a> (std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html">DeviceContext</a> &gt; context, const <a class="el" href="classMila_1_1Dnn_1_1ComponentConfig.html">ComponentConfig</a> &amp;config)</td></tr>
<tr class="memdesc:a2c3a64e5bc2b0d9464d341a86bf52a69 inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor with a specific device context.  <br /></td></tr>
<tr class="separator:a2c3a64e5bc2b0d9464d341a86bf52a69 inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a325c8ef88aae9f988c8ba90b815b85b3 inherit pub_methods_classMila_1_1Dnn_1_1Module" id="r_a325c8ef88aae9f988c8ba90b815b85b3"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Module.html#a325c8ef88aae9f988c8ba90b815b85b3">~Module</a> ()=default</td></tr>
<tr class="memdesc:a325c8ef88aae9f988c8ba90b815b85b3 inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Virtual destructor for proper cleanup in derived classes.  <br /></td></tr>
<tr class="separator:a325c8ef88aae9f988c8ba90b815b85b3 inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1163624b16a6518b2ed573f51827759d inherit pub_methods_classMila_1_1Dnn_1_1Module" id="r_a1163624b16a6518b2ed573f51827759d"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html">Compute::DeviceContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Module.html#a1163624b16a6518b2ed573f51827759d">getDeviceContext</a> () const</td></tr>
<tr class="memdesc:a1163624b16a6518b2ed573f51827759d inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the device context for this module.  <br /></td></tr>
<tr class="separator:a1163624b16a6518b2ed573f51827759d inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a94b3a479c6e9c49879ef2079d34df471 inherit pub_methods_classMila_1_1Dnn_1_1Module" id="r_a94b3a479c6e9c49879ef2079d34df471"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">Compute::DeviceType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Module.html#a94b3a479c6e9c49879ef2079d34df471">getDeviceType</a> () const</td></tr>
<tr class="memdesc:a94b3a479c6e9c49879ef2079d34df471 inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the device type of the current device context.  <br /></td></tr>
<tr class="separator:a94b3a479c6e9c49879ef2079d34df471 inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c8e8735eaf75d6bad6d454f7d23b2ca inherit pub_methods_classMila_1_1Dnn_1_1Module" id="r_a2c8e8735eaf75d6bad6d454f7d23b2ca"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Module.html#a2c8e8735eaf75d6bad6d454f7d23b2ca">getName</a> () const</td></tr>
<tr class="memdesc:a2c8e8735eaf75d6bad6d454f7d23b2ca inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the name of the module.  <br /></td></tr>
<tr class="separator:a2c8e8735eaf75d6bad6d454f7d23b2ca inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a980423a0db37b7680c3668a579d342 inherit pub_methods_classMila_1_1Dnn_1_1Module" id="r_a4a980423a0db37b7680c3668a579d342"><td class="memItemLeft" align="right" valign="top">const auto &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Module.html#a4a980423a0db37b7680c3668a579d342">getParameterTensors</a> () const</td></tr>
<tr class="memdesc:a4a980423a0db37b7680c3668a579d342 inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the parameter tensors of this module.  <br /></td></tr>
<tr class="separator:a4a980423a0db37b7680c3668a579d342 inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2e2d974ab30511a0bafd4477bc9117f3 inherit pub_methods_classMila_1_1Dnn_1_1Module" id="r_a2e2d974ab30511a0bafd4477bc9117f3"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1ComputePrecision.html#af05f57f23853ffa03a13e968cd141b9d">ComputePrecision::Policy</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Module.html#a2e2d974ab30511a0bafd4477bc9117f3">getPrecision</a> () const</td></tr>
<tr class="separator:a2e2d974ab30511a0bafd4477bc9117f3 inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e8be0bc8f91844acfdce17c8cc85364 inherit pub_methods_classMila_1_1Dnn_1_1Module" id="r_a8e8be0bc8f91844acfdce17c8cc85364"><td class="memItemLeft" align="right" valign="top">const auto &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Module.html#a8e8be0bc8f91844acfdce17c8cc85364">getStateTensors</a> () const</td></tr>
<tr class="memdesc:a8e8be0bc8f91844acfdce17c8cc85364 inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the state tensors of this module.  <br /></td></tr>
<tr class="separator:a8e8be0bc8f91844acfdce17c8cc85364 inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af676dd818a0afaa6f2839b53c42fb72b inherit pub_methods_classMila_1_1Dnn_1_1Module" id="r_af676dd818a0afaa6f2839b53c42fb72b"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Module.html#af676dd818a0afaa6f2839b53c42fb72b">isTraining</a> () const</td></tr>
<tr class="memdesc:af676dd818a0afaa6f2839b53c42fb72b inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Check if the module is in training mode.  <br /></td></tr>
<tr class="separator:af676dd818a0afaa6f2839b53c42fb72b inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac7b2a55c5d4108aa8eceb96c8db55004 inherit pub_methods_classMila_1_1Dnn_1_1Module" id="r_ac7b2a55c5d4108aa8eceb96c8db55004"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Module.html#ac7b2a55c5d4108aa8eceb96c8db55004">setTraining</a> (bool is_training)</td></tr>
<tr class="memdesc:ac7b2a55c5d4108aa8eceb96c8db55004 inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the training mode of this module.  <br /></td></tr>
<tr class="separator:ac7b2a55c5d4108aa8eceb96c8db55004 inherit pub_methods_classMila_1_1Dnn_1_1Module"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-methods" name="pri-methods"></a>
Private Member Functions</h2></td></tr>
<tr class="memitem:aa582f04abff968b547719d6a31320e5a" id="r_aa582f04abff968b547719d6a31320e5a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#aa582f04abff968b547719d6a31320e5a">createOperation</a> ()</td></tr>
<tr class="memdesc:aa582f04abff968b547719d6a31320e5a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates the appropriate attention operation for the current device.  <br /></td></tr>
<tr class="separator:aa582f04abff968b547719d6a31320e5a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa2e09b883e547c95eee3b1f26b212c2f" id="r_aa2e09b883e547c95eee3b1f26b212c2f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#aa2e09b883e547c95eee3b1f26b212c2f">initializeTensors</a> ()</td></tr>
<tr class="memdesc:aa2e09b883e547c95eee3b1f26b212c2f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initializes the tensors needed for attention computation.  <br /></td></tr>
<tr class="separator:aa2e09b883e547c95eee3b1f26b212c2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-attribs" name="pri-attribs"></a>
Private Attributes</h2></td></tr>
<tr class="memitem:ad6a96211088c452ecad01c26c4abf1ab" id="r_ad6a96211088c452ecad01c26c4abf1ab"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TOutput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#ad6a96211088c452ecad01c26c4abf1ab">attn_</a> { nullptr }</td></tr>
<tr class="memdesc:ad6a96211088c452ecad01c26c4abf1ab"><td class="mdescLeft">&#160;</td><td class="mdescRight">Attention weight tensor from the forward pass.  <br /></td></tr>
<tr class="separator:ad6a96211088c452ecad01c26c4abf1ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad0fe952f1cba9b123c7ff402fb1f0e72" id="r_ad0fe952f1cba9b123c7ff402fb1f0e72"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html">MultiHeadAttentionConfig</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#ad0fe952f1cba9b123c7ff402fb1f0e72">config_</a></td></tr>
<tr class="memdesc:ad0fe952f1cba9b123c7ff402fb1f0e72"><td class="mdescLeft">&#160;</td><td class="mdescRight">Configuration for the <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html" title="Multi-head attention module for transformer architectures.">MultiHeadAttention</a> module.  <br /></td></tr>
<tr class="separator:ad0fe952f1cba9b123c7ff402fb1f0e72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3c4375367d92713af8837672b3c7780" id="r_ab3c4375367d92713af8837672b3c7780"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html">UnaryOperation</a>&lt; TDeviceType, TInput, TOutput &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#ab3c4375367d92713af8837672b3c7780">operation_</a> { nullptr }</td></tr>
<tr class="memdesc:ab3c4375367d92713af8837672b3c7780"><td class="mdescLeft">&#160;</td><td class="mdescRight">The operation that implements the attention mechanism.  <br /></td></tr>
<tr class="separator:ab3c4375367d92713af8837672b3c7780"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab56f25b08a4d71130c54e35b17a67690" id="r_ab56f25b08a4d71130c54e35b17a67690"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TOutput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#ab56f25b08a4d71130c54e35b17a67690">output_state_</a></td></tr>
<tr class="memdesc:ab56f25b08a4d71130c54e35b17a67690"><td class="mdescLeft">&#160;</td><td class="mdescRight">Collection of output state tensors for caching.  <br /></td></tr>
<tr class="separator:ab56f25b08a4d71130c54e35b17a67690"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54da4678bf30ea520cbf8070268cce18" id="r_a54da4678bf30ea520cbf8070268cce18"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TOutput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a54da4678bf30ea520cbf8070268cce18">parameters_</a></td></tr>
<tr class="memdesc:a54da4678bf30ea520cbf8070268cce18"><td class="mdescLeft">&#160;</td><td class="mdescRight">Collection of parameters for this module.  <br /></td></tr>
<tr class="separator:a54da4678bf30ea520cbf8070268cce18"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5a3ffa78b72bf120232f11ece348c7a" id="r_ae5a3ffa78b72bf120232f11ece348c7a"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TOutput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#ae5a3ffa78b72bf120232f11ece348c7a">pre_attn_</a> { nullptr }</td></tr>
<tr class="memdesc:ae5a3ffa78b72bf120232f11ece348c7a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Pre-softmax attention scores from the forward pass.  <br /></td></tr>
<tr class="separator:ae5a3ffa78b72bf120232f11ece348c7a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a62af7179a0cced02ded53601d4b50ce1" id="r_a62af7179a0cced02ded53601d4b50ce1"><td class="memItemLeft" align="right" valign="top"><a class="el" href="structMila_1_1Dnn_1_1Compute_1_1OperationAttributes.html">OperationAttributes</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a62af7179a0cced02ded53601d4b50ce1">properties_</a></td></tr>
<tr class="memdesc:a62af7179a0cced02ded53601d4b50ce1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Operation attributes and configuration.  <br /></td></tr>
<tr class="separator:a62af7179a0cced02ded53601d4b50ce1"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="inherited" name="inherited"></a>
Additional Inherited Members</h2></td></tr>
<tr class="inherit_header pro_methods_classMila_1_1Dnn_1_1Module"><td colspan="2" onclick="javascript:toggleInherit('pro_methods_classMila_1_1Dnn_1_1Module')"><img src="closed.png" alt="-"/>&#160;Protected Member Functions inherited from <a class="el" href="classMila_1_1Dnn_1_1Module.html">Mila::Dnn::Module&lt; TDeviceType, TInput, TOutput &gt;</a></td></tr>
<tr class="memitem:aa9c385b11a63c2e17eed36c807209c50 inherit pro_methods_classMila_1_1Dnn_1_1Module" id="r_aa9c385b11a63c2e17eed36c807209c50"><td class="memItemLeft" align="right" valign="top">const std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Module.html#aa9c385b11a63c2e17eed36c807209c50">parametersToString</a> () const</td></tr>
<tr class="memdesc:aa9c385b11a63c2e17eed36c807209c50 inherit pro_methods_classMila_1_1Dnn_1_1Module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Helper method to convert parameters to string representation.  <br /></td></tr>
<tr class="separator:aa9c385b11a63c2e17eed36c807209c50 inherit pro_methods_classMila_1_1Dnn_1_1Module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a301bf2920ad45f578126c1a68d2b37a0 inherit pro_methods_classMila_1_1Dnn_1_1Module" id="r_a301bf2920ad45f578126c1a68d2b37a0"><td class="memItemLeft" align="right" valign="top">const std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Module.html#a301bf2920ad45f578126c1a68d2b37a0">stateToString</a> () const</td></tr>
<tr class="memdesc:a301bf2920ad45f578126c1a68d2b37a0 inherit pro_methods_classMila_1_1Dnn_1_1Module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Helper method to convert state tensors to string representation.  <br /></td></tr>
<tr class="separator:a301bf2920ad45f578126c1a68d2b37a0 inherit pro_methods_classMila_1_1Dnn_1_1Module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_attribs_classMila_1_1Dnn_1_1Module"><td colspan="2" onclick="javascript:toggleInherit('pro_attribs_classMila_1_1Dnn_1_1Module')"><img src="closed.png" alt="-"/>&#160;Protected Attributes inherited from <a class="el" href="classMila_1_1Dnn_1_1Module.html">Mila::Dnn::Module&lt; TDeviceType, TInput, TOutput &gt;</a></td></tr>
<tr class="memitem:a9f7fbe15857ace6c72f48003df61a06c inherit pro_attribs_classMila_1_1Dnn_1_1Module" id="r_a9f7fbe15857ace6c72f48003df61a06c"><td class="memItemLeft" align="right" valign="top">std::unordered_map&lt; std::string, std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TOutput, <a class="el" href="classMila_1_1Dnn_1_1Module.html#a30d5b0cc3f9fa994c166180483b2ea51">MR</a> &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Module.html#a9f7fbe15857ace6c72f48003df61a06c">parameter_map_</a> = {}</td></tr>
<tr class="memdesc:a9f7fbe15857ace6c72f48003df61a06c inherit pro_attribs_classMila_1_1Dnn_1_1Module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Map of parameter names to parameter tensors.  <br /></td></tr>
<tr class="separator:a9f7fbe15857ace6c72f48003df61a06c inherit pro_attribs_classMila_1_1Dnn_1_1Module"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a78cc537819a1c1a5f48b99782ad8315d inherit pro_attribs_classMila_1_1Dnn_1_1Module" id="r_a78cc537819a1c1a5f48b99782ad8315d"><td class="memItemLeft" align="right" valign="top">std::unordered_map&lt; std::string, std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TOutput, <a class="el" href="classMila_1_1Dnn_1_1Module.html#a30d5b0cc3f9fa994c166180483b2ea51">MR</a> &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMila_1_1Dnn_1_1Module.html#a78cc537819a1c1a5f48b99782ad8315d">state_map_</a> = {}</td></tr>
<tr class="memdesc:a78cc537819a1c1a5f48b99782ad8315d inherit pro_attribs_classMila_1_1Dnn_1_1Module"><td class="mdescLeft">&#160;</td><td class="mdescRight">Map of state names to state tensors.  <br /></td></tr>
<tr class="separator:a78cc537819a1c1a5f48b99782ad8315d inherit pro_attribs_classMila_1_1Dnn_1_1Module"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><div class="compoundTemplParams">template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput = float, typename TOutput = TInput&gt;<br />
requires ValidTensorTypes&lt;TInput, TOutput&gt;<br />
class Mila::Dnn::MultiHeadAttention&lt; TDeviceType, TInput, TOutput &gt;</div><p>Multi-head attention module for transformer architectures. </p>
<p>This module implements the multi-head attention mechanism, which allows different parts of the input to attend to different parts of the sequence. This is a core component of transformer architectures.</p>
<p>The attention mechanism computes: Attention(Q, K, V) = softmax(QK^T/sqrt(d_k))V where Q, K, and V are the query, key, and value projections of the input.</p>
<p>Multi-head attention projects the input into multiple subspaces, computes attention independently in each subspace, then concatenates the results to form the output.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">TDeviceType</td><td>The device type (CPU or CUDA) on which to perform computations. </td></tr>
    <tr><td class="paramname">TInput</td><td>The data type of the input tensor elements. </td></tr>
    <tr><td class="paramname">TOutput</td><td>The data type of the output tensor elements, defaults to TInput. </td></tr>
  </table>
  </dd>
</dl>
</div><h2 class="groupheader">Member Typedef Documentation</h2>
<a id="a9fea4bf3612d224d2b54da7a1cb78cb8" name="a9fea4bf3612d224d2b54da7a1cb78cb8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9fea4bf3612d224d2b54da7a1cb78cb8">&#9670;&#160;</a></span>ModuleBase</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::ModuleBase =  <a class="el" href="classMila_1_1Dnn_1_1Module.html">Module</a>&lt;TDeviceType, TInput, TOutput&gt;</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Alias for base module type. </p>

</div>
</div>
<a id="a44c10df27cce6d2a46dbb81e455d5d4a" name="a44c10df27cce6d2a46dbb81e455d5d4a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a44c10df27cce6d2a46dbb81e455d5d4a">&#9670;&#160;</a></span>MR</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::MR =  std::conditional_t&lt;TDeviceType == DeviceType::Cuda, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CudaMemoryResource.html">CudaMemoryResource</a>, <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1CpuMemoryResource.html">CpuMemoryResource</a>&gt;</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Memory resource type used for tensors, selected based on device type. </p>

</div>
</div>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a205a226fb09b4c4b083e60e1d4b4311a" name="a205a226fb09b4c4b083e60e1d4b4311a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a205a226fb09b4c4b083e60e1d4b4311a">&#9670;&#160;</a></span>MultiHeadAttention() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::MultiHeadAttention </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>device_name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html">MultiHeadAttentionConfig</a> &amp;&#160;</td>
          <td class="paramname"><em>config</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">explicit</span><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Constructs a new <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html" title="Multi-head attention module for transformer architectures.">MultiHeadAttention</a> module with a device name. </p>
<p>Creates a new DeviceContext internally using the provided device name. This constructor is useful for creating standalone modules without pre-existing device contexts.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">device_name</td><td>The name of the device to use (e.g., "CPU", "CUDA:0"). </td></tr>
    <tr><td class="paramname">config</td><td>Configuration parameters for the <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html" title="Multi-head attention module for transformer architectures.">MultiHeadAttention</a> module. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If the device name is invalid or the configuration is invalid </td></tr>
    <tr><td class="paramname">std::runtime_error</td><td>If device type doesn't match template parameter TDeviceType </td></tr>
  </table>
  </dd>
</dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classMila_1_1Dnn_1_1MultiHeadAttention_a205a226fb09b4c4b083e60e1d4b4311a_cgraph.png" border="0" usemap="#aclassMila_1_1Dnn_1_1MultiHeadAttention_a205a226fb09b4c4b083e60e1d4b4311a_cgraph" alt=""/></div>
<map name="aclassMila_1_1Dnn_1_1MultiHeadAttention_a205a226fb09b4c4b083e60e1d4b4311a_cgraph" id="aclassMila_1_1Dnn_1_1MultiHeadAttention_a205a226fb09b4c4b083e60e1d4b4311a_cgraph">
<area shape="rect" title="Constructs a new MultiHeadAttention module with a device name." alt="" coords="5,453,224,493"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#aa582f04abff968b547719d6a31320e5a" title="Creates the appropriate attention operation for the current device." alt="" coords="272,121,491,161"/>
<area shape="poly" title=" " alt="" coords="130,451,354,170,358,173,134,454"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#aa2e09b883e547c95eee3b1f26b212c2f" title="Initializes the tensors needed for attention computation." alt="" coords="272,453,491,493"/>
<area shape="poly" title=" " alt="" coords="224,470,258,470,258,475,224,475"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a57c4cf0a91dcb9e987f3ec2cdc3c95dd" title="Validate configuration parameters." alt="" coords="272,613,491,653"/>
<area shape="poly" title=" " alt="" coords="151,491,336,603,333,608,148,495"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1OperationRegistry.html#a8bcbbd6e474b44727458887b4685f43e" title="Create a unary operation based on the type information, device type, and operation name." alt="" coords="563,5,738,60"/>
<area shape="poly" title=" " alt="" coords="426,118,538,70,558,62,560,67,540,75,428,123"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Module.html#a1163624b16a6518b2ed573f51827759d" title="Get the device context for this module." alt="" coords="577,85,725,125"/>
<area shape="poly" title=" " alt="" coords="490,123,563,114,564,119,491,129"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1OperationRegistry.html#a56e3658d8b09dd388ca379aefcdeb17f" title="Get the singleton instance of the OperationRegistry." alt="" coords="575,149,726,204"/>
<area shape="poly" title=" " alt="" coords="491,153,562,162,561,167,490,158"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a9d5e87b46522e0a8d423f4498d2bf184" title="Get the dropout rate." alt="" coords="541,229,760,269"/>
<area shape="poly" title=" " alt="" coords="391,451,413,414,446,367,488,319,537,278,547,272,550,277,540,283,492,323,450,371,418,417,396,454"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a568c2b5af5064ac8d83e0db4f5fe0187" title="Get the input shape." alt="" coords="541,293,760,333"/>
<area shape="poly" title=" " alt="" coords="400,450,458,397,496,368,537,342,552,335,554,340,540,347,499,372,462,401,404,454"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Module.html#a2c8e8735eaf75d6bad6d454f7d23b2ca" title="Get the name of the module." alt="" coords="577,357,725,397"/>
<area shape="poly" title=" " alt="" coords="427,450,538,406,562,398,564,403,540,411,429,455"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a64daa00677b693962db37b76c563283d" title="Get the number of attention heads." alt="" coords="541,421,760,461"/>
<area shape="poly" title=" " alt="" coords="490,457,527,453,528,458,491,462"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a2c0e9e41e04567dddcb4cc3660927518" title="Get the attention scaling factor." alt="" coords="541,485,760,525"/>
<area shape="poly" title=" " alt="" coords="491,483,528,487,527,493,490,488"/>
<area shape="rect" href="structMila_1_1Dnn_1_1Compute_1_1OperationAttributes.html#a77b49c21d0b585acf519138c166b6687" title="Helper method to set a value in the propsMap." alt="" coords="557,549,744,589"/>
<area shape="poly" title=" " alt="" coords="429,490,540,534,564,542,562,547,538,539,427,495"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a2bc9811ffcc719b67e1946331d363a36" title="Check if causal masking is enabled." alt="" coords="541,613,760,653"/>
<area shape="poly" title=" " alt="" coords="404,491,462,544,499,573,540,598,554,605,552,610,537,603,496,578,458,549,400,495"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#af1a67cdb792d19fb6c9720fa44c6fbff" title="Check if using separate projection matrices." alt="" coords="539,677,763,717"/>
<area shape="poly" title=" " alt="" coords="402,491,493,599,514,634,524,648,540,663,549,668,546,673,537,667,520,652,510,637,489,602,398,494"/>
<area shape="rect" href="classMila_1_1Dnn_1_1ComponentConfig.html#a35f7308c0a3de2579d0df7cdbb7ec268" title="Gets the configured component name." alt="" coords="811,357,1019,397"/>
<area shape="poly" title=" " alt="" coords="725,374,797,374,797,379,725,379"/>
<area shape="rect" href="classMila_1_1Dnn_1_1ComponentConfig.html#ab1b9997f5b9604f0f60b68985f2f3ffc" title="Validates the configuration." alt="" coords="547,741,755,781"/>
<area shape="poly" title=" " alt="" coords="412,651,469,689,540,726,558,734,556,738,538,731,466,693,409,655"/>
</map>
</div>

</div>
</div>
<a id="a2184c5fdc3dffb5dbbe2ba3f00ed48a9" name="a2184c5fdc3dffb5dbbe2ba3f00ed48a9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2184c5fdc3dffb5dbbe2ba3f00ed48a9">&#9670;&#160;</a></span>MultiHeadAttention() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::MultiHeadAttention </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; <a class="el" href="classMila_1_1Dnn_1_1Compute_1_1DeviceContext.html">DeviceContext</a> &gt;&#160;</td>
          <td class="paramname"><em>device_context</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html">MultiHeadAttentionConfig</a> &amp;&#160;</td>
          <td class="paramname"><em>config</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">explicit</span><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Constructs a new <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html" title="Multi-head attention module for transformer architectures.">MultiHeadAttention</a> module with a provided device context. </p>
<p>Uses a pre-existing DeviceContext instance. This constructor is useful when integrating the module into a larger network that shares device contexts across modules.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">device_context</td><td>The device context to use for this module. </td></tr>
    <tr><td class="paramname">config</td><td>Configuration parameters for the <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html" title="Multi-head attention module for transformer architectures.">MultiHeadAttention</a> module. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">std::invalid_argument</td><td>If device_context is null or configuration is invalid </td></tr>
    <tr><td class="paramname">std::runtime_error</td><td>If device context type doesn't match template parameter TDeviceType </td></tr>
  </table>
  </dd>
</dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classMila_1_1Dnn_1_1MultiHeadAttention_a2184c5fdc3dffb5dbbe2ba3f00ed48a9_cgraph.png" border="0" usemap="#aclassMila_1_1Dnn_1_1MultiHeadAttention_a2184c5fdc3dffb5dbbe2ba3f00ed48a9_cgraph" alt=""/></div>
<map name="aclassMila_1_1Dnn_1_1MultiHeadAttention_a2184c5fdc3dffb5dbbe2ba3f00ed48a9_cgraph" id="aclassMila_1_1Dnn_1_1MultiHeadAttention_a2184c5fdc3dffb5dbbe2ba3f00ed48a9_cgraph">
<area shape="rect" title="Constructs a new MultiHeadAttention module with a provided device context." alt="" coords="5,453,224,493"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#aa582f04abff968b547719d6a31320e5a" title="Creates the appropriate attention operation for the current device." alt="" coords="272,121,491,161"/>
<area shape="poly" title=" " alt="" coords="130,451,354,170,358,173,134,454"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#aa2e09b883e547c95eee3b1f26b212c2f" title="Initializes the tensors needed for attention computation." alt="" coords="272,453,491,493"/>
<area shape="poly" title=" " alt="" coords="224,470,258,470,258,475,224,475"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a57c4cf0a91dcb9e987f3ec2cdc3c95dd" title="Validate configuration parameters." alt="" coords="272,613,491,653"/>
<area shape="poly" title=" " alt="" coords="151,491,336,603,333,608,148,495"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1OperationRegistry.html#a8bcbbd6e474b44727458887b4685f43e" title="Create a unary operation based on the type information, device type, and operation name." alt="" coords="563,5,738,60"/>
<area shape="poly" title=" " alt="" coords="426,118,538,70,558,62,560,67,540,75,428,123"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Module.html#a1163624b16a6518b2ed573f51827759d" title="Get the device context for this module." alt="" coords="577,85,725,125"/>
<area shape="poly" title=" " alt="" coords="490,123,563,114,564,119,491,129"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1OperationRegistry.html#a56e3658d8b09dd388ca379aefcdeb17f" title="Get the singleton instance of the OperationRegistry." alt="" coords="575,149,726,204"/>
<area shape="poly" title=" " alt="" coords="491,153,562,162,561,167,490,158"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a9d5e87b46522e0a8d423f4498d2bf184" title="Get the dropout rate." alt="" coords="541,229,760,269"/>
<area shape="poly" title=" " alt="" coords="391,451,413,414,446,367,488,319,537,278,547,272,550,277,540,283,492,323,450,371,418,417,396,454"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a568c2b5af5064ac8d83e0db4f5fe0187" title="Get the input shape." alt="" coords="541,293,760,333"/>
<area shape="poly" title=" " alt="" coords="400,450,458,397,496,368,537,342,552,335,554,340,540,347,499,372,462,401,404,454"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Module.html#a2c8e8735eaf75d6bad6d454f7d23b2ca" title="Get the name of the module." alt="" coords="577,357,725,397"/>
<area shape="poly" title=" " alt="" coords="427,450,538,406,562,398,564,403,540,411,429,455"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a64daa00677b693962db37b76c563283d" title="Get the number of attention heads." alt="" coords="541,421,760,461"/>
<area shape="poly" title=" " alt="" coords="490,457,527,453,528,458,491,462"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a2c0e9e41e04567dddcb4cc3660927518" title="Get the attention scaling factor." alt="" coords="541,485,760,525"/>
<area shape="poly" title=" " alt="" coords="491,483,528,487,527,493,490,488"/>
<area shape="rect" href="structMila_1_1Dnn_1_1Compute_1_1OperationAttributes.html#a77b49c21d0b585acf519138c166b6687" title="Helper method to set a value in the propsMap." alt="" coords="557,549,744,589"/>
<area shape="poly" title=" " alt="" coords="429,490,540,534,564,542,562,547,538,539,427,495"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a2bc9811ffcc719b67e1946331d363a36" title="Check if causal masking is enabled." alt="" coords="541,613,760,653"/>
<area shape="poly" title=" " alt="" coords="404,491,462,544,499,573,540,598,554,605,552,610,537,603,496,578,458,549,400,495"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#af1a67cdb792d19fb6c9720fa44c6fbff" title="Check if using separate projection matrices." alt="" coords="539,677,763,717"/>
<area shape="poly" title=" " alt="" coords="402,491,493,599,514,634,524,648,540,663,549,668,546,673,537,667,520,652,510,637,489,602,398,494"/>
<area shape="rect" href="classMila_1_1Dnn_1_1ComponentConfig.html#a35f7308c0a3de2579d0df7cdbb7ec268" title="Gets the configured component name." alt="" coords="811,357,1019,397"/>
<area shape="poly" title=" " alt="" coords="725,374,797,374,797,379,725,379"/>
<area shape="rect" href="classMila_1_1Dnn_1_1ComponentConfig.html#ab1b9997f5b9604f0f60b68985f2f3ffc" title="Validates the configuration." alt="" coords="547,741,755,781"/>
<area shape="poly" title=" " alt="" coords="412,651,469,689,540,726,558,734,556,738,538,731,466,693,409,655"/>
</map>
</div>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="abe9c2244b3ec8fd5ff188d26da34c8e9" name="abe9c2244b3ec8fd5ff188d26da34c8e9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abe9c2244b3ec8fd5ff188d26da34c8e9">&#9670;&#160;</a></span>backward()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::backward </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TOutput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>output_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>input_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs the backward pass of the <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html" title="Multi-head attention module for transformer architectures.">MultiHeadAttention</a> operation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor from the forward pass. </td></tr>
    <tr><td class="paramname">output_grad</td><td>The gradient of loss with respect to the output. </td></tr>
    <tr><td class="paramname">input_grad</td><td>The tensor to store gradients with respect to input. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aa582f04abff968b547719d6a31320e5a" name="aa582f04abff968b547719d6a31320e5a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa582f04abff968b547719d6a31320e5a">&#9670;&#160;</a></span>createOperation()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::createOperation </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">export</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Creates the appropriate attention operation for the current device. </p>
<p>Instantiates either a CPU or CUDA attention operation based on the device type. </p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classMila_1_1Dnn_1_1MultiHeadAttention_aa582f04abff968b547719d6a31320e5a_cgraph.png" border="0" usemap="#aclassMila_1_1Dnn_1_1MultiHeadAttention_aa582f04abff968b547719d6a31320e5a_cgraph" alt=""/></div>
<map name="aclassMila_1_1Dnn_1_1MultiHeadAttention_aa582f04abff968b547719d6a31320e5a_cgraph" id="aclassMila_1_1Dnn_1_1MultiHeadAttention_aa582f04abff968b547719d6a31320e5a_cgraph">
<area shape="rect" title="Creates the appropriate attention operation for the current device." alt="" coords="5,85,224,125"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1OperationRegistry.html#a8bcbbd6e474b44727458887b4685f43e" title="Create a unary operation based on the type information, device type, and operation name." alt="" coords="272,5,447,60"/>
<area shape="poly" title=" " alt="" coords="183,82,258,60,260,65,184,87"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Module.html#a1163624b16a6518b2ed573f51827759d" title="Get the device context for this module." alt="" coords="285,85,433,125"/>
<area shape="poly" title=" " alt="" coords="224,102,271,102,271,107,224,107"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Compute_1_1OperationRegistry.html#a56e3658d8b09dd388ca379aefcdeb17f" title="Get the singleton instance of the OperationRegistry." alt="" coords="284,149,435,204"/>
<area shape="poly" title=" " alt="" coords="184,122,271,148,270,153,183,127"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classMila_1_1Dnn_1_1MultiHeadAttention_aa582f04abff968b547719d6a31320e5a_icgraph.png" border="0" usemap="#aclassMila_1_1Dnn_1_1MultiHeadAttention_aa582f04abff968b547719d6a31320e5a_icgraph" alt=""/></div>
<map name="aclassMila_1_1Dnn_1_1MultiHeadAttention_aa582f04abff968b547719d6a31320e5a_icgraph" id="aclassMila_1_1Dnn_1_1MultiHeadAttention_aa582f04abff968b547719d6a31320e5a_icgraph">
<area shape="rect" title="Creates the appropriate attention operation for the current device." alt="" coords="272,37,491,77"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a205a226fb09b4c4b083e60e1d4b4311a" title="Constructs a new MultiHeadAttention module with a device name." alt="" coords="5,5,224,45"/>
<area shape="poly" title=" " alt="" coords="258,45,224,41,225,36,259,40"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a2184c5fdc3dffb5dbbe2ba3f00ed48a9" title="Constructs a new MultiHeadAttention module with a provided device context." alt="" coords="5,69,224,109"/>
<area shape="poly" title=" " alt="" coords="259,75,225,79,224,74,258,69"/>
</map>
</div>

</div>
</div>
<a id="a825e50e3cc60ac78310129b056904810" name="a825e50e3cc60ac78310129b056904810"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a825e50e3cc60ac78310129b056904810">&#9670;&#160;</a></span>forward() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::forward </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>mask</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TOutput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs the forward pass with an explicit attention mask. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to be processed. </td></tr>
    <tr><td class="paramname">mask</td><td>The attention mask tensor (0s for masked positions). </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor where the results will be stored. </td></tr>
  </table>
  </dd>
</dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classMila_1_1Dnn_1_1MultiHeadAttention_a825e50e3cc60ac78310129b056904810_cgraph.png" border="0" usemap="#aclassMila_1_1Dnn_1_1MultiHeadAttention_a825e50e3cc60ac78310129b056904810_cgraph" alt=""/></div>
<map name="aclassMila_1_1Dnn_1_1MultiHeadAttention_a825e50e3cc60ac78310129b056904810_cgraph" id="aclassMila_1_1Dnn_1_1MultiHeadAttention_a825e50e3cc60ac78310129b056904810_cgraph">
<area shape="rect" title="Performs the forward pass with an explicit attention mask." alt="" coords="5,5,224,45"/>
<area shape="rect" href="structMila_1_1Dnn_1_1Compute_1_1OperationAttributes.html#a77b49c21d0b585acf519138c166b6687" title="Helper method to set a value in the propsMap." alt="" coords="272,5,459,45"/>
<area shape="poly" title=" " alt="" coords="224,23,258,23,258,28,224,28"/>
</map>
</div>

</div>
</div>
<a id="aa68240bd5a909f19afe06e497f50a9aa" name="aa68240bd5a909f19afe06e497f50a9aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa68240bd5a909f19afe06e497f50a9aa">&#9670;&#160;</a></span>forward() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::forward </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TInput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt; TOutput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs the forward pass of the <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html" title="Multi-head attention module for transformer architectures.">MultiHeadAttention</a> operation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to be processed. </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor where the results will be stored. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a73b8961371a4f0c0881b08aa0a5de198" name="a73b8961371a4f0c0881b08aa0a5de198"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a73b8961371a4f0c0881b08aa0a5de198">&#9670;&#160;</a></span>getDropout()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">float <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::getDropout </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the dropout rate. </p>
<dl class="section return"><dt>Returns</dt><dd>float The dropout rate. </dd></dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classMila_1_1Dnn_1_1MultiHeadAttention_a73b8961371a4f0c0881b08aa0a5de198_cgraph.png" border="0" usemap="#aclassMila_1_1Dnn_1_1MultiHeadAttention_a73b8961371a4f0c0881b08aa0a5de198_cgraph" alt=""/></div>
<map name="aclassMila_1_1Dnn_1_1MultiHeadAttention_a73b8961371a4f0c0881b08aa0a5de198_cgraph" id="aclassMila_1_1Dnn_1_1MultiHeadAttention_a73b8961371a4f0c0881b08aa0a5de198_cgraph">
<area shape="rect" title="Gets the dropout rate." alt="" coords="5,5,224,45"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a9d5e87b46522e0a8d423f4498d2bf184" title="Get the dropout rate." alt="" coords="272,5,491,45"/>
<area shape="poly" title=" " alt="" coords="224,23,258,23,258,28,224,28"/>
</map>
</div>

</div>
</div>
<a id="aa3b867c5cfaeeef2936fb4ca46ff61ff" name="aa3b867c5cfaeeef2936fb4ca46ff61ff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa3b867c5cfaeeef2936fb4ca46ff61ff">&#9670;&#160;</a></span>getEmbeddingDim()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::getEmbeddingDim </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the embedding dimension. </p>
<dl class="section return"><dt>Returns</dt><dd>size_t The embedding dimension. </dd></dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classMila_1_1Dnn_1_1MultiHeadAttention_aa3b867c5cfaeeef2936fb4ca46ff61ff_cgraph.png" border="0" usemap="#aclassMila_1_1Dnn_1_1MultiHeadAttention_aa3b867c5cfaeeef2936fb4ca46ff61ff_cgraph" alt=""/></div>
<map name="aclassMila_1_1Dnn_1_1MultiHeadAttention_aa3b867c5cfaeeef2936fb4ca46ff61ff_cgraph" id="aclassMila_1_1Dnn_1_1MultiHeadAttention_aa3b867c5cfaeeef2936fb4ca46ff61ff_cgraph">
<area shape="rect" title="Gets the embedding dimension." alt="" coords="5,5,224,45"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a926d9fe05b112e67fce76f47fd437fd6" title="Get the embedding dimension." alt="" coords="272,5,491,45"/>
<area shape="poly" title=" " alt="" coords="224,23,258,23,258,28,224,28"/>
</map>
</div>

</div>
</div>
<a id="a21b2cafa427d56474aea9bf5deffa2ed" name="a21b2cafa427d56474aea9bf5deffa2ed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a21b2cafa427d56474aea9bf5deffa2ed">&#9670;&#160;</a></span>getInputShape()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const std::vector&lt; size_t &gt; &amp; <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::getInputShape </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the input shape. </p>
<dl class="section return"><dt>Returns</dt><dd>const std::vector&lt;size_t&gt;&amp; The input shape. </dd></dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classMila_1_1Dnn_1_1MultiHeadAttention_a21b2cafa427d56474aea9bf5deffa2ed_cgraph.png" border="0" usemap="#aclassMila_1_1Dnn_1_1MultiHeadAttention_a21b2cafa427d56474aea9bf5deffa2ed_cgraph" alt=""/></div>
<map name="aclassMila_1_1Dnn_1_1MultiHeadAttention_a21b2cafa427d56474aea9bf5deffa2ed_cgraph" id="aclassMila_1_1Dnn_1_1MultiHeadAttention_a21b2cafa427d56474aea9bf5deffa2ed_cgraph">
<area shape="rect" title="Gets the input shape." alt="" coords="5,5,224,45"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a568c2b5af5064ac8d83e0db4f5fe0187" title="Get the input shape." alt="" coords="272,5,491,45"/>
<area shape="poly" title=" " alt="" coords="224,23,258,23,258,28,224,28"/>
</map>
</div>

</div>
</div>
<a id="a8a27412f9f4f9e60fa2c6a569c59167f" name="a8a27412f9f4f9e60fa2c6a569c59167f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8a27412f9f4f9e60fa2c6a569c59167f">&#9670;&#160;</a></span>getNumHeads()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::getNumHeads </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the number of attention heads. </p>
<dl class="section return"><dt>Returns</dt><dd>size_t The number of attention heads. </dd></dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classMila_1_1Dnn_1_1MultiHeadAttention_a8a27412f9f4f9e60fa2c6a569c59167f_cgraph.png" border="0" usemap="#aclassMila_1_1Dnn_1_1MultiHeadAttention_a8a27412f9f4f9e60fa2c6a569c59167f_cgraph" alt=""/></div>
<map name="aclassMila_1_1Dnn_1_1MultiHeadAttention_a8a27412f9f4f9e60fa2c6a569c59167f_cgraph" id="aclassMila_1_1Dnn_1_1MultiHeadAttention_a8a27412f9f4f9e60fa2c6a569c59167f_cgraph">
<area shape="rect" title="Gets the number of attention heads." alt="" coords="5,5,224,45"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a64daa00677b693962db37b76c563283d" title="Get the number of attention heads." alt="" coords="272,5,491,45"/>
<area shape="poly" title=" " alt="" coords="224,23,258,23,258,28,224,28"/>
</map>
</div>

</div>
</div>
<a id="aa2e09b883e547c95eee3b1f26b212c2f" name="aa2e09b883e547c95eee3b1f26b212c2f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa2e09b883e547c95eee3b1f26b212c2f">&#9670;&#160;</a></span>initializeTensors()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::initializeTensors </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">export</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Initializes the tensors needed for attention computation. </p>
<p>Creates and initializes intermediate tensors used during the attention computation, including attention weights and pre-softmax scores. </p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classMila_1_1Dnn_1_1MultiHeadAttention_aa2e09b883e547c95eee3b1f26b212c2f_cgraph.png" border="0" usemap="#aclassMila_1_1Dnn_1_1MultiHeadAttention_aa2e09b883e547c95eee3b1f26b212c2f_cgraph" alt=""/></div>
<map name="aclassMila_1_1Dnn_1_1MultiHeadAttention_aa2e09b883e547c95eee3b1f26b212c2f_cgraph" id="aclassMila_1_1Dnn_1_1MultiHeadAttention_aa2e09b883e547c95eee3b1f26b212c2f_cgraph">
<area shape="rect" title="Initializes the tensors needed for attention computation." alt="" coords="5,229,224,269"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a9d5e87b46522e0a8d423f4498d2bf184" title="Get the dropout rate." alt="" coords="275,5,493,45"/>
<area shape="poly" title=" " alt="" coords="125,228,147,191,179,144,221,96,270,55,281,49,283,54,274,60,225,100,184,147,151,194,129,230"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a568c2b5af5064ac8d83e0db4f5fe0187" title="Get the input shape." alt="" coords="275,69,493,109"/>
<area shape="poly" title=" " alt="" coords="133,227,192,173,230,144,271,119,285,112,288,117,273,124,233,149,195,178,137,231"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Module.html#a2c8e8735eaf75d6bad6d454f7d23b2ca" title="Get the name of the module." alt="" coords="310,133,458,173"/>
<area shape="poly" title=" " alt="" coords="160,227,271,183,296,175,297,180,273,188,162,232"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a64daa00677b693962db37b76c563283d" title="Get the number of attention heads." alt="" coords="275,197,493,237"/>
<area shape="poly" title=" " alt="" coords="224,234,261,229,261,235,224,239"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a2c0e9e41e04567dddcb4cc3660927518" title="Get the attention scaling factor." alt="" coords="275,261,493,301"/>
<area shape="poly" title=" " alt="" coords="224,260,261,264,261,269,224,265"/>
<area shape="rect" href="structMila_1_1Dnn_1_1Compute_1_1OperationAttributes.html#a77b49c21d0b585acf519138c166b6687" title="Helper method to set a value in the propsMap." alt="" coords="291,325,477,365"/>
<area shape="poly" title=" " alt="" coords="162,267,273,311,297,319,295,324,271,316,160,272"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a2bc9811ffcc719b67e1946331d363a36" title="Check if causal masking is enabled." alt="" coords="275,389,493,429"/>
<area shape="poly" title=" " alt="" coords="137,268,195,321,233,350,273,375,288,382,285,387,271,380,230,354,192,325,133,272"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#af1a67cdb792d19fb6c9720fa44c6fbff" title="Check if using separate projection matrices." alt="" coords="272,453,496,493"/>
<area shape="poly" title=" " alt="" coords="129,268,151,305,184,351,225,399,274,439,283,445,281,450,270,444,221,403,179,355,147,308,125,271"/>
<area shape="rect" href="classMila_1_1Dnn_1_1ComponentConfig.html#a35f7308c0a3de2579d0df7cdbb7ec268" title="Gets the configured component name." alt="" coords="544,133,752,173"/>
<area shape="poly" title=" " alt="" coords="458,151,530,151,530,156,458,156"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classMila_1_1Dnn_1_1MultiHeadAttention_aa2e09b883e547c95eee3b1f26b212c2f_icgraph.png" border="0" usemap="#aclassMila_1_1Dnn_1_1MultiHeadAttention_aa2e09b883e547c95eee3b1f26b212c2f_icgraph" alt=""/></div>
<map name="aclassMila_1_1Dnn_1_1MultiHeadAttention_aa2e09b883e547c95eee3b1f26b212c2f_icgraph" id="aclassMila_1_1Dnn_1_1MultiHeadAttention_aa2e09b883e547c95eee3b1f26b212c2f_icgraph">
<area shape="rect" title="Initializes the tensors needed for attention computation." alt="" coords="272,37,491,77"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a205a226fb09b4c4b083e60e1d4b4311a" title="Constructs a new MultiHeadAttention module with a device name." alt="" coords="5,5,224,45"/>
<area shape="poly" title=" " alt="" coords="258,45,224,41,225,36,259,40"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a2184c5fdc3dffb5dbbe2ba3f00ed48a9" title="Constructs a new MultiHeadAttention module with a provided device context." alt="" coords="5,69,224,109"/>
<area shape="poly" title=" " alt="" coords="259,75,225,79,224,74,258,69"/>
</map>
</div>

</div>
</div>
<a id="ab4c16e1be1d56f6eebb1b969e5bbc6ca" name="ab4c16e1be1d56f6eebb1b969e5bbc6ca"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab4c16e1be1d56f6eebb1b969e5bbc6ca">&#9670;&#160;</a></span>load()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::load </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classMila_1_1Dnn_1_1Serialization_1_1ModelArchive.html">ModelArchive</a> &amp;&#160;</td>
          <td class="paramname"><em>archive</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">override</span><span class="mlabel">export</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Loads the module state from a ZIP archive. </p>
<p>Implementation of the <a class="el" href="classMila_1_1Dnn_1_1Module.html" title="Abstract base class for all modules in the Mila DNN framework.">Module</a> interface for deserialization. Currently a no-op in the base implementation as there are no parameters to load.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">zip</td><td>ZIP archive for deserialization </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classMila_1_1Dnn_1_1Module.html#a79dd1f9148ec935bc9bdf1a1f062019b">Mila::Dnn::Module&lt; TDeviceType, TInput, TOutput &gt;</a>.</p>

</div>
</div>
<a id="a7d7f1415090f6ce3f84a492d72a93504" name="a7d7f1415090f6ce3f84a492d72a93504"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7d7f1415090f6ce3f84a492d72a93504">&#9670;&#160;</a></span>parameterCount()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::parameterCount </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">override</span><span class="mlabel">export</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the number of trainable parameters in this module. </p>
<dl class="section return"><dt>Returns</dt><dd>size_t The total number of parameters. </dd></dl>

<p>Implements <a class="el" href="classMila_1_1Dnn_1_1Module.html#ae1d548970ec07a9850fdad0dc1e4c1c2">Mila::Dnn::Module&lt; TDeviceType, TInput, TOutput &gt;</a>.</p>

</div>
</div>
<a id="aae30a0f8075da1f957316a0a0c0643d7" name="aae30a0f8075da1f957316a0a0c0643d7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aae30a0f8075da1f957316a0a0c0643d7">&#9670;&#160;</a></span>save()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::save </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classMila_1_1Dnn_1_1Serialization_1_1ModelArchive.html">ModelArchive</a> &amp;&#160;</td>
          <td class="paramname"><em>zip</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">override</span><span class="mlabel">export</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Saves the module state to a ZIP archive. </p>
<p>Implementation of the <a class="el" href="classMila_1_1Dnn_1_1Module.html" title="Abstract base class for all modules in the Mila DNN framework.">Module</a> interface for serialization. Currently a no-op in the base implementation as there are no parameters to save.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">zip</td><td>ZIP archive for serialization </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classMila_1_1Dnn_1_1Module.html#a20d60df81d5e0f1db4e56aa0fb8d1319">Mila::Dnn::Module&lt; TDeviceType, TInput, TOutput &gt;</a>.</p>

</div>
</div>
<a id="a91762121adfdf91a746f16619b26fb98" name="a91762121adfdf91a746f16619b26fb98"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a91762121adfdf91a746f16619b26fb98">&#9670;&#160;</a></span>toString()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::string <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::toString </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">override</span><span class="mlabel">export</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Generates a string representation of this module's configuration. </p>
<dl class="section return"><dt>Returns</dt><dd>std::string A formatted string with module information </dd></dl>

<p>Implements <a class="el" href="classMila_1_1Dnn_1_1Module.html#a594cb38f73a3f8df511b582b3ec6c0ab">Mila::Dnn::Module&lt; TDeviceType, TInput, TOutput &gt;</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classMila_1_1Dnn_1_1MultiHeadAttention_a91762121adfdf91a746f16619b26fb98_cgraph.png" border="0" usemap="#aclassMila_1_1Dnn_1_1MultiHeadAttention_a91762121adfdf91a746f16619b26fb98_cgraph" alt=""/></div>
<map name="aclassMila_1_1Dnn_1_1MultiHeadAttention_a91762121adfdf91a746f16619b26fb98_cgraph" id="aclassMila_1_1Dnn_1_1MultiHeadAttention_a91762121adfdf91a746f16619b26fb98_cgraph">
<area shape="rect" title="Generates a string representation of this module&#39;s configuration." alt="" coords="5,325,224,365"/>
<area shape="rect" href="namespaceMila_1_1Dnn_1_1Compute.html#abc57784bcbd77f21ea2524f0161e7e4f" title="Converts a DeviceType to its string representation." alt="" coords="309,5,459,45"/>
<area shape="poly" title=" " alt="" coords="119,324,135,270,165,198,186,159,210,121,238,86,270,55,294,41,297,45,274,59,242,90,214,124,190,162,170,200,140,272,124,326"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Module.html#a1163624b16a6518b2ed573f51827759d" title="Get the device context for this module." alt="" coords="310,69,458,109"/>
<area shape="poly" title=" " alt="" coords="122,324,142,281,174,226,217,168,243,142,271,119,295,105,298,110,273,124,246,146,221,172,179,229,147,284,127,326"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Module.html#a94b3a479c6e9c49879ef2079d34df471" title="Get the device type of the current device context." alt="" coords="310,133,458,173"/>
<area shape="poly" title=" " alt="" coords="128,323,185,254,225,216,271,183,296,171,298,176,273,188,229,220,189,258,132,327"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a9d5e87b46522e0a8d423f4498d2bf184" title="Get the dropout rate." alt="" coords="275,197,493,237"/>
<area shape="poly" title=" " alt="" coords="142,323,200,285,271,247,289,240,291,244,273,252,203,289,145,327"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a926d9fe05b112e67fce76f47fd437fd6" title="Get the embedding dimension." alt="" coords="275,261,493,301"/>
<area shape="poly" title=" " alt="" coords="199,323,285,302,287,307,200,328"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a568c2b5af5064ac8d83e0db4f5fe0187" title="Get the input shape." alt="" coords="275,325,493,365"/>
<area shape="poly" title=" " alt="" coords="224,343,261,343,261,348,224,348"/>
<area shape="rect" href="classMila_1_1Dnn_1_1Module.html#a2c8e8735eaf75d6bad6d454f7d23b2ca" title="Get the name of the module." alt="" coords="310,389,458,429"/>
<area shape="poly" title=" " alt="" coords="200,363,297,386,296,391,199,368"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a64daa00677b693962db37b76c563283d" title="Get the number of attention heads." alt="" coords="275,453,493,493"/>
<area shape="poly" title=" " alt="" coords="145,363,203,401,273,439,291,446,289,451,271,444,200,406,142,368"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a2c0e9e41e04567dddcb4cc3660927518" title="Get the attention scaling factor." alt="" coords="275,517,493,557"/>
<area shape="poly" title=" " alt="" coords="132,364,189,433,229,471,273,503,285,509,283,514,271,508,225,475,185,436,128,368"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a2bc9811ffcc719b67e1946331d363a36" title="Check if causal masking is enabled." alt="" coords="275,581,493,621"/>
<area shape="poly" title=" " alt="" coords="127,364,147,407,179,462,221,519,246,545,274,567,282,573,279,577,270,571,243,549,217,522,174,465,142,409,122,367"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#af1a67cdb792d19fb6c9720fa44c6fbff" title="Check if using separate projection matrices." alt="" coords="272,645,496,685"/>
<area shape="poly" title=" " alt="" coords="124,365,140,418,170,490,190,529,214,566,242,601,274,631,280,636,277,640,270,635,238,605,210,569,186,532,165,493,135,420,119,366"/>
<area shape="rect" href="classMila_1_1Dnn_1_1ComponentConfig.html#a35f7308c0a3de2579d0df7cdbb7ec268" title="Gets the configured component name." alt="" coords="544,389,752,429"/>
<area shape="poly" title=" " alt="" coords="458,407,530,407,530,412,458,412"/>
</map>
</div>

</div>
</div>
<a id="ac0b829536527ba668c4180f67aa0f874" name="ac0b829536527ba668c4180f67aa0f874"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac0b829536527ba668c4180f67aa0f874">&#9670;&#160;</a></span>useCausalMask()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::useCausalMask </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">export</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Checks if causal masking is enabled. </p>
<dl class="section return"><dt>Returns</dt><dd>bool True if causal masking is enabled, false otherwise. </dd></dl>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classMila_1_1Dnn_1_1MultiHeadAttention_ac0b829536527ba668c4180f67aa0f874_cgraph.png" border="0" usemap="#aclassMila_1_1Dnn_1_1MultiHeadAttention_ac0b829536527ba668c4180f67aa0f874_cgraph" alt=""/></div>
<map name="aclassMila_1_1Dnn_1_1MultiHeadAttention_ac0b829536527ba668c4180f67aa0f874_cgraph" id="aclassMila_1_1Dnn_1_1MultiHeadAttention_ac0b829536527ba668c4180f67aa0f874_cgraph">
<area shape="rect" title="Checks if causal masking is enabled." alt="" coords="5,5,224,45"/>
<area shape="rect" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html#a2bc9811ffcc719b67e1946331d363a36" title="Check if causal masking is enabled." alt="" coords="272,5,491,45"/>
<area shape="poly" title=" " alt="" coords="224,23,258,23,258,28,224,28"/>
</map>
</div>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="ad6a96211088c452ecad01c26c4abf1ab" name="ad6a96211088c452ecad01c26c4abf1ab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad6a96211088c452ecad01c26c4abf1ab">&#9670;&#160;</a></span>attn_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt;<a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt;TOutput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a>&gt; &gt; <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::attn_ { nullptr }</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Attention weight tensor from the forward pass. </p>
<p>Shape: [batch_size, num_heads, sequence_length, sequence_length] Stores the attention weights between all token pairs. </p>

</div>
</div>
<a id="ad0fe952f1cba9b123c7ff402fb1f0e72" name="ad0fe952f1cba9b123c7ff402fb1f0e72"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad0fe952f1cba9b123c7ff402fb1f0e72">&#9670;&#160;</a></span>config_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttentionConfig.html">MultiHeadAttentionConfig</a> <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::config_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Configuration for the <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html" title="Multi-head attention module for transformer architectures.">MultiHeadAttention</a> module. </p>

</div>
</div>
<a id="ab3c4375367d92713af8837672b3c7780" name="ab3c4375367d92713af8837672b3c7780"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab3c4375367d92713af8837672b3c7780">&#9670;&#160;</a></span>operation_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt;<a class="el" href="classMila_1_1Dnn_1_1Compute_1_1UnaryOperation.html">UnaryOperation</a>&lt;TDeviceType, TInput, TOutput&gt; &gt; <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::operation_ { nullptr }</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The operation that implements the attention mechanism. </p>

</div>
</div>
<a id="ab56f25b08a4d71130c54e35b17a67690" name="ab56f25b08a4d71130c54e35b17a67690"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab56f25b08a4d71130c54e35b17a67690">&#9670;&#160;</a></span>output_state_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;std::shared_ptr&lt;<a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt;TOutput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a>&gt; &gt; &gt; <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::output_state_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Collection of output state tensors for caching. </p>

</div>
</div>
<a id="a54da4678bf30ea520cbf8070268cce18" name="a54da4678bf30ea520cbf8070268cce18"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a54da4678bf30ea520cbf8070268cce18">&#9670;&#160;</a></span>parameters_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;std::shared_ptr&lt;<a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt;TOutput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a>&gt; &gt; &gt; <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::parameters_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Collection of parameters for this module. </p>

</div>
</div>
<a id="ae5a3ffa78b72bf120232f11ece348c7a" name="ae5a3ffa78b72bf120232f11ece348c7a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae5a3ffa78b72bf120232f11ece348c7a">&#9670;&#160;</a></span>pre_attn_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt;<a class="el" href="classMila_1_1Dnn_1_1Tensor.html">Tensor</a>&lt;TOutput, <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html#a44c10df27cce6d2a46dbb81e455d5d4a">MR</a>&gt; &gt; <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::pre_attn_ { nullptr }</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Pre-softmax attention scores from the forward pass. </p>
<p>Shape: [batch_size, num_heads, sequence_length, sequence_length] Stores the raw attention scores before softmax normalization. </p>

</div>
</div>
<a id="a62af7179a0cced02ded53601d4b50ce1" name="a62af7179a0cced02ded53601d4b50ce1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a62af7179a0cced02ded53601d4b50ce1">&#9670;&#160;</a></span>properties_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;<a class="el" href="namespaceMila_1_1Dnn_1_1Compute.html#a393d2d886886aa0215f25b307e4f71f4">DeviceType</a> TDeviceType = DeviceType::Cuda, typename TInput  = float, typename TOutput  = TInput&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="structMila_1_1Dnn_1_1Compute_1_1OperationAttributes.html">OperationAttributes</a> <a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">Mila::Dnn::MultiHeadAttention</a>&lt; TDeviceType, TInput, TOutput &gt;::properties_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">export</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Operation attributes and configuration. </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/home/runner/work/Mila/Mila/Mila/Src/Dnn/Modules/Layers/<a class="el" href="MultiHeadAttention_8ixx.html">MultiHeadAttention.ixx</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespaceMila.html">Mila</a></li><li class="navelem"><a class="el" href="namespaceMila_1_1Dnn.html">Dnn</a></li><li class="navelem"><a class="el" href="classMila_1_1Dnn_1_1MultiHeadAttention.html">MultiHeadAttention</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
